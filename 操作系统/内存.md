# 内存

## 问题

### 虚拟内存机制

* 为什么要虚拟内存，有什么用？
* 如何实现虚拟内存？
* 虚拟内存的代价
* 虚拟内存如何解决内存碎片等问题？
* 谈谈请求页式存储管理？
* 谈谈请求段式存储管理？
* 缺页中断的处理
* 如何降低缺页率
* 内存满了，会发生什么
	* 内存分配的过程是怎么样的？
	* 哪些内存可以被回收？
	* 回收内存带来的性能影响
	* 如何保护一个进程不被 OOM 杀掉

* 在 4 GB 物理内存的机器上，申请 8G 内存会怎么样

### TLB

https://cloud.tencent.com/developer/article/2008239

https://zhuanlan.zhihu.com/p/108425561

* 为什么要有 TLB
* TLB 的本质是什么
* TLB 和 Cache（访问内存的） 的区别？
* TLB 的特殊
* TLB 的别名问题
* TLB 的歧义问题
* 如何尽可能的避免 flush TLB
* 如何管理 ASID，
* 更上一层楼
* 什么时候应该 flush TLB





### malloc 和 free

* malloc() 如何分配内存？
* malloc() 分配的是物理内存吗？
* malloc(1) 会分配多大内存？
* malloc() 为什么不全部使用 mmap 来分配内存？
* malloc() 为什么不全部使用 brk 来分配内存？
* malloc() 如果没有成功，可能什么原因，计算机会做什么？
* malloc() 是线程安全的吗 ?是可重入的吗？
* free() 释放内存，会归还给操作系统吗？
* free() 函数只传入一个内存地址，为什么会知道要释放多大的内存？

### 连续存储管理

* 静态分区分配是什么？有什么优缺点？
* 动态分区分配是什么？有什么优缺点？
* 什么是内部碎片？什么是外部碎片？各自有什么解决方法？

* 首次适应算法？
* 最佳适应算法？
* 最差适应算法？
* 邻近适应算法？

* Buddy 伙伴算法
* Slab 算法？

### 非连续存储管理

* 谈谈内存分段？
  * 什么是内存分段
  * 分段机制下，虚拟地址和物理地址是如何映射的？
  * 分段的优点
  * 分段的缺点及解决方案
* 谈谈内存分页？
  * 什么是内存分页
  * 分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？
  * 分页机制下，虚拟地址和物理地址是如何映射的？
  * 分页的优点
  * 分页的缺点及解决方案
  * 多级页表
  * TLB
* 谈谈段页式内存管理

### 页面置换算法

* 谈谈系统抖动与工作集
* 谈谈 Belady 异常
* 谈谈最佳页面置换算法 OPT
* 谈谈先进先出置换算法 FIFO
* 谈谈第二次机会页面置换算法 SC
* 谈谈最近最久未使用置换算法 LRU
* 谈谈如何优化传统的 LRU（预读、缓存失效）
* 谈谈时钟页面置换算法 CLOCK（近似 LRU）
* 谈谈最不常用置换算法 LFU/NFU
* 谈谈老化算法
* 谈谈工作集页面置换算法
* 工作集时钟页面置换算法
* 谈谈随机算法
* Linux 内核页面置换算法

### Linux 虚拟内存

* Linux 进程虚拟内存空间
* Linux 进程虚拟内存空间管理
* 程序编译后的二进制文件如何映射到虚拟内存空间中
* 谈谈 Linux 内核虚拟内存空间
* 谈谈物理内存地址
* 谈谈 mmap 内存映射

## 回答

### 虚拟内存机制

#### 为什么要虚拟内存，有什么用？

单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。

另外，**单片机的 CPU 是直接操作内存的「物理地址」**。

![img](https://img-blog.csdnimg.cn/019f1f0d2d30469cbda2b8fe2cf5e622.png)

在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。

> 操作系统是如何解决这个问题呢？

这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。

我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。

![进程的中间层](https://img-blog.csdnimg.cn/img_convert/298fb68e3da94d767b02f2ed81ebf2c4.png)

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

* 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
* 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：

![img](https://img-blog.csdnimg.cn/72ab76ba697e470b8ceb14d5fc5688d9.png)

**虚拟内存的作用**

* 第一，虚拟内存可以使得进程的运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
* 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
* 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/9027b02a03b9fe83c6396b73a0004a39.png#pic_center)

在系统中所有的进程之间是共享CPU和主存这些内存资源的。当进程数量变多时，所需要的内存资源就会相应的增加。可能会导致部分程序没有主存空间可用。此外，由于资源是共享的，那么就有可能导致某个进程不小心写了另一个进程所使用的内存，进而导致程序运行不符合正常逻辑。

虚拟内存提供了三个重要的能力： **缓存，内存管理，内存保护**

1. 虚拟内存作为缓存的工具

* 虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。
* 虚拟内存利用DRAM缓存来自通常更大的虚拟地址空间的页面。

2. 虚拟内存作为内存管理的工具。操作系统为每个进程提供了一个独立的页表，也就是独立的虚拟地址空间。多个虚拟页面可以映射到同一个物理页面上。

* **简化链接**： 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。
  * 例如：一个给定的 linux 系统上的每个进程都是用类似的内存格式，对于64为地址空间，代码段总是从虚拟地址） 0x400000 开始，数据段，代码段，栈，堆等等。
* **简化加载**： 虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中.text和.data节加载到一个新创建的进程中，Linux加载器为代码和数据段分配虚拟页VP，把他们**标记为无效（未被缓存）** ，将页表条目指向目标文件的起始位置。
  * **加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页。**
* **简化共享**： 独立地址空间为OS提供了一个管理用户进程和操作系统自身之间共享的一致机制。
  * 一般：每个进程有各自私有的代码，数据，堆栈，是不和其他进程共享的，**这样OS创建页表，将虚拟页映射到不连续的物理页面。**
  * 某些情况下，需要进程来共享代码和数据。例如每个进程调用相同的操作系统内核代码，或者C标准库函数。**OS会把不同进程中适当的虚拟页面映射到相同的物理页面。**
* **简化内存分配**： 虚拟内存向用户提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如 malloc ），OS分配一个适当k大小个连续的虚拟内存页面，并且将他们映射到物理内存中任意位置的k个任意物理页面，**因此操作系统没有必要分配k个连续的物理内存页面，页面可以随机的分散在物理内存中**。

3. 虚拟内存作为**内存保护**的工具。不应该允许一个用户进程修改它的只读段，也不允许它修改任何内核代码和数据结构，不允许读写其他进程的私有内存，不允许修改任何与其他进程共享的虚拟页面。每次CPU生成一个地址时， MMU 会读一个 PTE ，通过在 PTE 上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。

4. 虚拟内存很适合在**多道程序设计系统**中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

#### 如何实现虚拟内存？

![img 123](https://img-blog.csdnimg.cn/img_convert/2cc579b599dc03c4534e813e049bf8cf.png)

#### 虚拟内存的代价

1. 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存

2. 虚拟地址到物理地址的转换，增加了指令的执行时间。

3. 页面的换入换出需要磁盘I/O，这是很耗时的

4. 如果一页中只有一部分数据，会浪费内存。

#### 虚拟内存如何解决内存碎片等问题？

**内存不足时**:

当向系统申请内存但内存不足时，系统会把根据置换算法把暂进不用的内存置换到硬盘里,更新映射关系到硬盘上，再更新新申请的内存映射关系，让我们产生无限内存的错觉。(交换到硬盘后会导致性能下降，硬盘读取速度比内存慢太多了)。例如下面这个例子，程序0,1,2分别加载了物理地址的0,1,2。此时程序3进来，也需要申请内存。然后就根据算法先把内存腾出来，腾出来的放到磁盘上，再把腾出来的空间给程序3。这样就可以解决内存不足的问题而不会导致崩溃。

![img](https://pic2.zhimg.com/v2-236c8318385ba78c963c2a8894c7c285_b.jpg)

**内存碎片:**

程序通过自身的映射表可以随意找到合适的物理内存,而不一定需要连续分配。

![img](https://pic2.zhimg.com/v2-0e4d8cbd83bb811670337e927e39f9c1_b.jpg)

**程序间相同的地址:**

即使程序的地址相同，但是每个程序通过自己的映射表映射到不同的物理内存而不会互相产生干扰。但是程序间相互独立一定是好的吗？并不是，因为有些内存是需要共享的。例如不同的程序会共享系统文件，系统选择框等。让程序间实现共享内存的方法是把地址指向相同的物理内存。

![img](https://pic1.zhimg.com/v2-110060ce2c809fe532919b765ed0f8cc_b.jpg)

#### 谈谈请求页式存储管理？

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020050718242973.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

**1.知识总览**

![在这里插入图片描述](https://img-blog.csdnimg.cn/2020050718275041.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

**2.页表机制—请求页表与基本页表的区别**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507183231700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

**3.缺页中断机构**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507185201230.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507184941487.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507185905607.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020050719010754.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507220913997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

**4.地址变换机构**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507221140511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/2020050722145316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507222657919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200507222739960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkxNDYwNA==,size_16,color_FFFFFF,t_70)

#### 谈谈请求段式存储管理？





#### 缺页中断的处理

1. 硬件陷入内核，在堆栈中保存程序计数器。大多数机器将当前的指令，各种状态信息保存在特殊的CPU寄存器中。

2. 启动一个汇编代码保存通用寄存器和其他易失信息，防止被操作系统破坏

3. 当操作系统收到缺页中断信号后，定位到需要的虚拟页面。

4. 找到发生缺页中断的虚拟地址，操作系统检查这个地址是否有效，并检查存取与保护是否一致。

	如果不一致则杀掉该进程

	如果地址有效且没有保护错误发生，系统会检查是否有空闲页框。如果没有空闲页框就执行页面置换算法淘汰一个页面。

5. 如果选择的页框对应的页面发生了修改，即为“脏页面”，需要写回磁盘，并发生一次上下文切换，挂起产生缺页中断的进程，让其他进程运行直至全部把内容写到磁盘。

6. 一旦页框是干净的，则OS会查找要发生置换的页面对应磁盘上的地址，通过磁盘操作将其装入。在装入该页面的时候，产生缺页中断的进程仍然被挂起，运行其他可运行的进程

7. 当发生磁盘中断时表明该页面已经被装入，页表已经更新可以反映其位置，页框也被标记为正常状态。

8. 恢复发生缺页中断指令以前的状态，程序计数器重新指向引起缺页中断的指令

9. 调度引发缺页中断的进程

10. 该进程恢复寄存器和其他状态信息，返回用户空间继续执行。



#### 如何降低缺页率



换页错误，一般称为缺页异常。每个进程都有一段自己的独立的虚拟内存空间（在32位的linux系统中为3G），但是这些虚拟内存区域并不会在创建的时候就和物理页框挂钩，由于程序的局部性原理，程序在一定时间内所访问的内存往往是有限的，因此内核只会在进程确确实实需要访问物理内存时才会将相应的虚拟内存区域与物理内存进行关联(为相应的地址分配页表项，并将页表项映射到物理内存)当一个程序试图访问没有映射到物理内存的地方时，就会出现缺页异常，这时操作系统要做的是要将这段虚拟内存映射到物理内存上，使其真正“可用”。
 
 减少换页错误的方法，即降低缺页中断率：
 1、内存页框数。增加作业分得的内存块数。
 2、页面大小。页面划分越大，中断率越低。
 3、页面零星换算法。替换算法的优劣影响缺页中断次数
 4、程序局部性。程序局部性好可减少缺页中断。

#### 内存满了，会发生什么

##### **内存分配的过程是怎样的？**

应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。

当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生**缺页中断**，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。

缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。

如果没有空闲的物理内存，那么内核就会开始进行**回收内存**的工作，回收的方式主要是两种：直接内存回收和后台内存回收。

- **后台内存回收**（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程**异步**的，不会阻塞进程的执行。
- **直接内存回收**（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是**同步**的，会阻塞进程的执行。

如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——**触发 OOM （Out of Memory）机制**。

OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。

申请物理内存的过程如下图：

![img](https://img-blog.csdnimg.cn/2f61b0822b3c4a359f99770231981b07.png)



##### **哪些内存可以被回收？**

系统内存紧张的时候，就会进行回收内存的工作，那具体哪些内存是可以被回收的呢？

主要有两类内存可以被回收，而且它们的回收方式也不同。

- **文件页**（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，**回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存**。
- **匿名页**（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们**回收的方式是通过 Linux 的 Swap 机制**，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：

- **active_list** 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
- **inactive_list** 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；

越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。

活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页。可以从 /proc/meminfo 中，查询它们的大小，比如：

```shell
# grep表示只保留包含active的指标（忽略大小写）
# sort表示按照字母顺序排序
[root@xiaolin ~]# cat /proc/meminfo | grep -i active | sort
Active:           901456 kB
Active(anon):     227252 kB
Active(file):     674204 kB
Inactive:         226232 kB
Inactive(anon):    41948 kB
Inactive(file):   184284 kB
```



##### **回收内存带来的性能影响？**

在前面我们知道了回收内存有两种方式。

- 一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。
- 一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。

可被回收的内存类型有文件页和匿名页：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

可以看到，回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。

下面针对回收内存导致的性能影响，说说常见的解决方式。

**调整文件页和匿名页的回收倾向**

从文件页和匿名页的回收操作来看，文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I/O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。

Linux 提供了一个 `/proc/sys/vm/swappiness` 选项，用来调整文件页和匿名页的回收倾向。

swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。

```shell
[root@xiaolin ~]# cat /proc/sys/vm/swappiness
0
```

一般建议 swappiness 设置为 0（默认值是 60），这样在回收内存的时候，会更倾向于文件页的回收，但是并不代表不会回收匿名页。



**尽早触发 kswapd 内核线程异步回收内存**

> 如何查看系统的直接内存回收和后台内存回收的指标？

我们可以使用 `sar -B 1` 命令来观察：

![img](https://img-blog.csdnimg.cn/8acb6b28d0fc4858bd57be147d087def.png)

图中红色框住的就是后台内存回收和直接内存回收的指标，它们分别表示：

- pgscank/s : kswapd(后台回收线程) 每秒扫描的 page 个数。
- pgscand/s: 应用程序在内存申请过程中每秒直接扫描的 page 个数。
- pgsteal/s: 扫描的 page 中每秒被回收的个数（pgscank+pgscand）。

如果系统时不时发生抖动，并且在抖动的时间段里如果通过 sar -B 观察到 pgscand 数值很大，那大概率是因为「直接内存回收」导致的。

针对这个问题，解决的办法就是，可以通过尽早的触发「后台内存回收」来避免应用程序进行直接内存回收。

> 什么条件下才能触发 kswapd 内核线程回收内存呢？

内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：

- 页最小阈值（pages_min）；
- 页低阈值（pages_low）；
- 页高阈值（pages_high）；

这三个内存阈值会划分为四种内存使用情况，如下图：

![img](https://img-blog.csdnimg.cn/166bc9f5b7c545d89f1e36ab8dd772cf.png)

kswapd 会定期扫描内存的使用情况，根据剩余内存（pages_free）的情况来进行内存回收的工作。

- 图中绿色部分：如果剩余内存（pages_free）大于 页高阈值（pages_high），说明剩余内存是充足的；
- 图中蓝色部分：如果剩余内存（pages_free）在页高阈值（pages_high）和页低阈值（pages_low）之间，说明内存有一定压力，但还可以满足应用程序申请内存的请求；
- 图中橙色部分：如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。**这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止**。虽然会触发内存回收，但是不会阻塞应用程序，因为两者关系是异步的。
- 图中红色部分：如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会**触发直接内存回收**，这时应用程序就会被阻塞，因为两者关系是同步的。

可以看到，当剩余内存页（pages_free）小于页低阈值（pages_low），就会触发 kswapd 进行后台回收，然后 kswapd 会一直回收到剩余内存页（pages_free）大于页高阈值（pages_high）。

也就是说 kswapd 的活动空间只有 pages_low 与 pages_min 之间的这段区域，如果剩余内存低于了 pages_min 会触发直接内存回收，高于了 pages_high 又不会唤醒 kswapd。

页低阈值（pages_low）可以通过内核选项 `/proc/sys/vm/min_free_kbytes` （该参数代表系统所保留空闲内存的最低限）来间接设置。

min_free_kbytes 虽然设置的是页最小阈值（pages_min），但是页高阈值（pages_high）和页低阈值（pages_low）都是根据页最小阈值（pages_min）计算生成的，它们之间的计算关系如下：

```text
pages_min = min_free_kbytes
pages_low = pages_min*5/4
pages_high = pages_min*3/2
```

如果系统时不时发生抖动，并且通过 sar -B 观察到 pgscand 数值很大，那大概率是因为直接内存回收导致的，这时可以增大 min_free_kbytes 这个配置选项来及早地触发后台回收，然后继续观察 pgscand 是否会降为 0。

增大了 min_free_kbytes 配置后，这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量，这在一定程度上浪费了内存。极端情况下设置 min_free_kbytes 接近实际物理内存大小时，留给应用程序的内存就会太少而可能会频繁地导致 OOM 的发生。

所以在调整 min_free_kbytes 之前，需要先思考一下，应用程序更加关注什么，如果关注延迟那就适当地增大 min_free_kbytes，如果关注内存的使用量那就适当地调小 min_free_kbytes。



**NUMA 架构下的内存回收策略**

> 什么是 NUMA 架构？

再说 NUMA 架构前，先给大家说说 SMP 架构，这两个架构都是针对 CPU 的。

SMP 指的是一种**多个 CPU 处理器共享资源的电脑硬件架构**，也就是说每个 CPU 地位平等，它们共享相同的物理资源，包括总线、内存、IO、操作系统等。每个 CPU 访问内存所用时间都是相同的，因此，这种系统也被称为一致存储访问结构（UMA，Uniform Memory Access）。

随着 CPU 处理器核数的增多，多个 CPU 都通过一个总线访问内存，这样总线的带宽压力会越来越大，同时每个 CPU 可用带宽会减少，这也就是 SMP 架构的问题。

![SMP 与 NUMA 架构](https://img-blog.csdnimg.cn/img_convert/feec409868070d8cd79aecad2895b531.png)

为了解决 SMP 架构的问题，就研制出了 NUMA 结构，即非一致存储访问结构（Non-uniform memory access，NUMA）。

NUMA 架构将每个 CPU 进行了分组，每一组 CPU 用 Node 来表示，一个 Node 可能包含多个 CPU 。

**每个 Node 有自己独立的资源，包括内存、IO 等**，每个 Node 之间可以通过互联模块总线（QPI）进行通信，所以，也就意味着每个 Node 上的 CPU 都可以访问到整个系统中的所有内存。但是，访问远端 Node 的内存比访问本地内存要耗时很多。

> NUMA 架构跟回收内存有什么关系？

在 NUMA 架构下，当某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。

具体选哪种模式，可以通过 /proc/sys/vm/zone_reclaim_mode 来控制。它支持以下几个选项：

- 0 （默认值）：在回收本地内存之前，在其他 Node 寻找空闲内存；
- 1：只回收本地内存；
- 2：只回收本地内存，在本地回收内存时，可以将文件页中的脏页写回硬盘，以回收内存。
- 4：只回收本地内存，在本地回收内存时，可以用 swap 方式回收内存。

在使用 NUMA 架构的服务器，如果系统出现还有一半内存的时候，却发现系统频繁触发「直接内存回收」，导致了影响了系统性能，那么大概率是因为 zone_reclaim_mode 没有设置为 0 ，导致当本地内存不足的时候，只选择回收本地内存的方式，而不去使用其他 Node 的空闲内存。

虽然说访问远端 Node 的内存比访问本地内存要耗时很多，但是相比内存回收的危害而言，访问远端 Node 的内存带来的性能影响还是比较小的。因此，zone_reclaim_mode 一般建议设置为 0。



##### **如何保护一个进程不被 OOM 杀掉呢？**

在系统空闲内存不足的情况，进程申请了一个很大的内存，如果直接内存回收都无法回收出足够大的空闲内存，那么就会触发 OOM 机制，内核就会根据算法选择一个进程杀掉。

Linux 到底是根据什么标准来选择被杀的进程呢？这就要提到一个在 Linux 内核里有一个 `oom_badness()` 函数，它会把系统中可以被杀掉的进程扫描一遍，并对每个进程打分，得分最高的进程就会被首先杀掉。

进程得分的结果受下面这两个方面影响：

- 第一，进程已经使用的物理内存页面数。
- 第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 `/proc/[pid]/oom_score_adj` 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。

函数 oom_badness() 里的最终计算方法是这样的：

```c
// points 代表打分的结果
// process_pages 代表进程已经使用的物理内存页面数
// oom_score_adj 代表 OOM 校准值
// totalpages 代表系统总的可用页面数
points = process_pages + oom_score_adj*totalpages/1000
```

**用「系统总的可用页面数」乘以 「OOM 校准值 oom_score_adj」再除以 1000，最后再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大**。

每个进程的 oom_score_adj 默认值都为 0，所以最终得分跟进程自身消耗的内存有关，消耗的内存越大越容易被杀掉。我们可以通过调整 oom_score_adj 的数值，来改成进程的得分结果：

- 如果你不想某个进程被首先杀掉，那你可以调整该进程的 oom_score_adj，从而改变这个进程的得分结果，降低该进程被 OOM 杀死的概率。
- 如果你想某个进程无论如何都不能被杀掉，那你可以将 oom_score_adj 配置为 -1000。

我们最好将一些很重要的系统服务的 oom_score_adj 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。

但是，不建议将我们自己的业务程序的 oom_score_adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM killer 不停地被唤醒，从而把其他进程一个个给杀掉。

参考资料：

- https://time.geekbang.org/column/article/277358
- https://time.geekbang.org/column/article/75797
- https://www.jianshu.com/p/e40e8813842f

**总结**

内核在给应用程序分配物理内存的时候，如果空闲物理内存不够，那么就会进行内存回收的工作，主要有两种方式：

- 后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。
- 直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。

可被回收的内存类型有文件页和匿名页：

- 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
- 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。

文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能。

针对回收内存导致的性能影响，常见的解决方式。

- 设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页；
- 设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机；
- 设置 /proc/sys/vm/zone_reclaim_mode，调整 NUMA 架构下内存回收策略，建议设置为 0，这样在回收本地内存之前，会在其他 Node 寻找空闲内存，从而避免在系统还有很多空闲内存的情况下，因本地 Node 的本地内存不足，发生频繁直接内存回收导致性能下降的问题；

在经历完直接内存回收后，空闲的物理内存大小依然不够，那么就会触发 OOM 机制，OOM killer 就会根据每个进程的内存占用情况和 oom_score_adj 的值进行打分，得分最高的进程就会被首先杀掉。

我们可以通过调整进程的 /proc/[pid]/oom_score_adj 值，来降低被 OOM killer 杀掉的概率。







#### 在 4 GB 物理内存的机器上，申请 8G 内存会怎么样

其中，第一个问题「**在 4GB 物理内存的机器上，申请 8G 内存会怎么样？**」存在比较大的争议，有人说会申请失败，有的人说可以申请成功。

这个问题在没有前置条件下，就说出答案就是耍流氓。这个问题要考虑三个前置条件：

- 操作系统是 32 位的，还是 64 位的？
- 申请完 8G 内存后会不会被使用？
- 操作系统有没有使用 Swap 机制？

所以，我们要分场景讨论。

##### 操作系统虚拟内存大小

应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。

当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生**缺页中断**，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。

缺页中断处理函数会看是否有空闲的物理内存：

- 如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。
- 如果没有空闲的物理内存，那么内核就会开始进行[回收内存 (opens new window)](https://xiaolincoding.com/os/3_memory/mem_reclaim.html)的工作，如果回收内存工作结束后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了触发 OOM （Out of Memory）机制。

32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，如下所示：

![img](https://img-blog.csdnimg.cn/3a6cb4e3f27241d3b09b4766bb0b1124.png)

通过这里可以看出：

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

> 现在可以回答这个问题了：在 32 位操作系统、4GB 物理内存的机器上，申请 8GB 内存，会怎么样？

因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败（我手上没有 32 位操作系统测试，我估计失败的原因是 OOM）。

> 在 64 位操作系统、4GB 物理内存的机器上，申请 8G 内存，会怎么样？

64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。

我们可以简单做个测试，我的服务器是 64 位操作系统，但是物理内存只有 2 GB：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/2gb.png)

现在，我在机器上，连续申请 4 次 1 GB 内存，也就是一共申请了 4 GB 内存，注意下面代码只是单纯分配了虚拟内存，并没有使用该虚拟内存：

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>

#define MEM_SIZE 1024 * 1024 * 1024

int main() {
    char* addr[4];
    int i = 0;
    for(i = 0; i < 4; ++i) {
        addr[i] = (char*) malloc(MEM_SIZE);
        if(!addr[i]) {
            printf("执行 malloc 失败, 错误：%s\n",strerror(errno));
		        return -1;
        }
        printf("主线程调用malloc后，申请1gb大小得内存，此内存起始地址：0X%x\n", addr[i]);
    }
    
    //输入任意字符后，才结束
    getchar();
    return 0;
}
```

然后运行这个代码，可以看到，我的物理内存虽然只有 2GB，但是程序正常分配了 4GB 大小的虚拟内存：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%984g.png)

我们可以通过下面这条命令查看进程（test）的虚拟内存大小：

```shell
# ps aux | grep test
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root      7797  0.0  0.0 4198540  352 pts/1    S+   16:58   0:00 ./test
```

其中，VSZ 就代表进程使用的虚拟内存大小，RSS 代表进程使用的物理内存大小。可以看到，VSZ 大小为 4198540，也就是 4GB 的虚拟内存。

##### Swap 机制的作用

前面讨论在 32 位/64 位操作系统环境下，申请的虚拟内存超过物理内存后会怎么样？

- 在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。

程序申请的虚拟内存，如果没有被使用，它是不会占用物理空间的。当访问这块虚拟内存后，操作系统才会进行物理内存分配。

如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制：

- 如果没有开启 Swap 机制，程序就会直接 OOM；
- 如果有开启 Swap 机制，程序可以正常运行。

> 什么是 Swap 机制？

当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间会被临时保存到磁盘，等到那些程序要运行时，再从磁盘中恢复保存的数据到内存中。

另外，当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

这种，将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制负责的。

Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：

- **换出（Swap Out）** ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
- **换入（Swap In）**，是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；

Swap 换入换出的过程如下图：

![img](https://img-blog.csdnimg.cn/388a29f45fe947e5a49240e4eff13538.png)

使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。由于硬盘空间的价格远比内存要低，因此这种方式无疑是经济实惠的。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。

Linux 中的 Swap 机制会在内存不足和内存闲置的场景下触发：

- **内存不足**：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。
- **内存闲置**：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在[空闲内存低于一定水位 (opens new window)](https://xiaolincoding.com/os/3_memory/mem_reclaim.html#尽早触发-kSwapd-内核线程异步回收内存)时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。

Linux 提供了两种不同的方法启用 Swap，分别是 Swap 分区（Swap Partition）和 Swap 文件（Swapfile），开启方法可以看[这个资料 (opens new window)](https://support.huaweicloud.com/trouble-ecs/ecs_trouble_0322.html)：

- Swap 分区是硬盘上的独立区域，该区域只会用于交换分区，其他的文件不能存储在该区域上，我们可以使用 `swapon -s` 命令查看当前系统上的交换分区；
- Swap 文件是文件系统中的特殊文件，它与文件系统中的其他文件也没有太多的区别；

> Swap 换入换出的是什么类型的内存？

内核缓存的文件数据，因为都有对应的磁盘文件，所以在回收文件数据的时候， 直接写回到对应的文件就可以了。

但是像进程的堆、栈数据等，它们是没有实际载体，这部分内存被称为匿名页。而且这部分内存很可能还要再次被访问，所以不能直接释放内存，于是就需要有一个能保存匿名页的磁盘载体，这个载体就是 Swap 分区。

匿名页回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。

接下来，通过两个实验，看看申请的物理内存超过物理内存会怎样？

- 实验一：没有开启 Swap 机制
- 实验二：有开启 Swap 机制



**实验一：没有开启 Swap 机制**

我的服务器是 64 位操作系统，但是物理内存只有 2 GB，而且没有 Swap 分区：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/2gb.png)

我们改一下前面的代码，使得在申请完 4GB 虚拟内存后，通过 memset 函数访问这个虚拟内存，看看在没有 Swap 分区的情况下，会发生什么？

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>

#define MEM_SIZE 1024 * 1024 * 1024

int main() {
    char* addr[4];
    int i = 0;
    for(i = 0; i < 4; ++i) {
        addr[i] = (char*) malloc(MEM_SIZE);
        if(!addr[i]) {
            printf("执行 malloc 失败, 错误：%s\n",strerror(errno));
            return -1;
        }
        printf("主线程调用malloc后，申请1gb大小得内存，此内存起始地址：0X%x\n", addr[i]);
    }

    for(i = 0; i < 4; ++i) {
        printf("开始访问第 %d 块虚拟内存(每一块虚拟内存为 1 GB)\n", i + 1);
        memset(addr[i], 0, MEM_SIZE);
    }
    
    //输入任意字符后，才结束
    getchar();
    return 0;
}
```

运行结果：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%8F%91%E7%94%9Foom.png)

可以看到，在访问第 2 块虚拟内存（每一块虚拟内存是 1 GB）的时候，因为超过了机器的物理内存（2GB），进程（test）被操作系统杀掉了。

通过查看 message 系统日志，可以发现该进程是被操作系统 OOM killer 机制杀掉了，日志里报错了 Out of memory，也就是发生 OOM（内存溢出错误）。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/oom%E6%97%A5%E5%BF%97.png)

> 什么是 OOM?

内存溢出(Out Of Memory，简称OOM)是指应用系统中存在无法回收的内存或使用的内存过多，最终使得程序运行要用到的内存大于能提供的最大内存。此时程序就运行不了，系统会提示内存溢出。



**实验二：有开启 Swap 机制**

我用我的 mac book pro 笔记本做测试，我的笔记本是 64 位操作系统，物理内存是 8 GB， 目前 Swap 分区大小为 1 GB（注意这个大小不是固定不变的，Swap 分区总大小是会动态变化的，当没有使用 Swap 分区时，Swap 分区总大小是 0；当使用了 Swap 分区，Swap 分区总大小会增加至 1 GB；当 Swap 分区已使用的大小超过 1 GB 时；Swap 分区总大小就会增加到至 2 GB；当 Swap 分区已使用的大小超过 2 GB 时；Swap 分区总大小就增加至 3GB，如此往复。这个估计是 macos 自己实现的，Linux 的分区则是固定大小的，Swap 分区不会根据使用情况而自动增长）。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/swap%E5%88%86%E5%8C%BA%E5%A4%A7%E5%B0%8F.png)

为了方便观察磁盘 I/O 情况，我们改进一下前面的代码，分配完 32 GB虚拟内存后（笔记本物理内存是 8 GB），通过一个 while 循环频繁访问虚拟内存，代码如下：

```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define MEM_SIZE 32 * 1024 * 1024 * 1024

int main() {
    char* addr = (char*) malloc((long)MEM_SIZE);
    printf("主线程调用malloc后，目前共申请了 32gb 的虚拟内存\n");
    
    //循环频繁访问虚拟内存
    while(1) {
          printf("开始访问 32gb 大小的虚拟内存...\n");
          memset(addr, 0, (long)MEM_SIZE);
    }
    return 0;
}
```

运行结果如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E4%BB%A3%E7%A0%813%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png)

可以看到，在有 Swap 分区的情况下，即使笔记本物理内存是 8 GB，申请并使用 32 GB 内存是没问题，程序正常运行了，并没有发生 OOM。

从下图可以看到，进程的内存显示 32 GB（这个不要理解为占用的物理内存，理解为已被访问的虚拟内存大小，也就是在物理内存呆过的内存大小），系统已使用的 Swap 分区达到 2.3 GB。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/test%E8%BF%9B%E7%A8%8B%E5%86%85%E5%AD%98%E6%83%85%E5%86%B5.png)

此时我的笔记本电脑的磁盘开始出现“沙沙”的声音，通过查看磁盘的 I/O 情况，可以看到磁盘 I/O 达到了一个峰值，非常高：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98io.png)

> 有了 Swap 分区，是不是意味着进程可以使用的内存是无上限的？

当然不是，我把上面的代码改成了申请 64GB 内存后，当进程申请完 64GB 虚拟内存后，使用到 56 GB （这个不要理解为占用的物理内存，理解为已被访问的虚拟内存大小，也就是在物理内存呆过的内存大小）的时候，进程就被系统 kill 掉了，如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E8%A2%ABkill%E6%8E%89.png)

当系统多次尝试回收内存，还是无法满足所需使用的内存大小，进程就会被系统 kill 掉了，意味着发生了 OOM （*PS：我没有在 macos 系统找到像 linux 系统里的 /var/log/message 系统日志文件，所以无法通过查看日志确认是否发生了 OOM*）。

##### 总结

至此， 验证完成了。简单总结下：

- 在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
	- 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
	- 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

### TLB

#### 为什么要有 TLB ？

现在的内存分页都是多级页表的，这样虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

所以，TLB 是专门存放程序最常访问的页表项的 Cache，有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

每个进程的虚拟地址范围都是一样的，**那不同进程对应相同的虚拟地址，在 TLB 是如何区分的呢？**

我在网上看到一篇讲解 TLB 原理很好的文章，也说了上面这个问题，分享给大家，一起拜读。

> 作者：smcdef 原文：https://zhuanlan.zhihu.com/p/108425561

TLB是translation lookaside buffer的简称。首先，我们知道MMU的作用是把虚拟地址转换成物理地址。虚拟地址和物理地址的映射关系存储在页表中，而现在页表又是分级的。64位系统一般都是3~5级。

常见的配置是4级页表，就以4级页表为例说明。分别是PGD、PUD、PMD、PTE四级页表。在硬件上会有一个叫做页表基地址寄存器，它存储PGD页表的首地址。MMU就是根据页表基地址寄存器从PGD页表一路查到PTE，最终找到物理地址(PTE页表中存储物理地址)。

这就像在地图上显示你的家在哪一样，我为了找到你家的地址，先确定你是中国，再确定你是某个省，继续往下某个市，最后找到你家是一样的原理。一级一级找下去。这个过程你也看到了，非常繁琐。

如果第一次查到你家的具体位置，我如果记下来你的姓名和你家的地址。下次查找时，是不是只需要跟我说你的姓名是什么，我就直接能够告诉你地址，而不需要一级一级查找。四级页表查找过程需要四次内存访问。延时可想而知，非常影响性能。

页表查找过程的示例如下图所示。以后有机会详细展开，这里了解下即可。

![img](https://ask.qcloudimg.com/http-save/yehe-7134177/bc0e7ba661f1e1955131ab5b5b89a8c9.jpeg)

page table walk

#### **TLB的本质是什么**

TLB其实就是一块高速缓存。数据cache缓存地址(虚拟地址或者物理地址)和数据。TLB缓存虚拟地址和其映射的物理地址。

TLB根据虚拟地址查找cache，它没得选，只能根据虚拟地址查找。所以TLB是一个虚拟高速缓存。硬件存在TLB后，虚拟地址到物理地址的转换过程发生了变化。

虚拟地址首先发往TLB确认是否命中cache，如果cache hit直接可以得到物理地址。否则，一级一级查找页表获取物理地址。

并将虚拟地址和物理地址的映射关系缓存到TLB中。既然TLB是虚拟高速缓存（VIVT），是否存在别名和歧义问题呢？如果存在，软件和硬件是如何配合解决这些问题呢？



#### TLB 和 Cache（访问内存的） 的区别？





#### **TLB的特殊**

虚拟地址映射物理地址的最小单位是4KB。所以TLB其实不需要存储虚拟地址和物理地址的低12位(因为低12位是一样的，根本没必要存储)。

另外，我们如果命中cache，肯定是一次性从cache中拿出整个数据。所以虚拟地址不需要offset域。index域是否需要呢？这取决于cache的组织形式。

如果是全相连高速缓存。那么就不需要index。如果使用多路组相连高速缓存，依然需要index。下图就是一个四路组相连TLB的例子。

现如今64位CPU寻址范围并没有扩大到64位。64位地址空间很大，现如今还用不到那么大。因此硬件为了设计简单或者解决成本，实际虚拟地址位数只使用了一部分。这里以48位地址总线为了例说明。

![img](https://ask.qcloudimg.com/http-save/yehe-7134177/e354f2e0706cab1e06a126cbfdfc8eea.jpeg)

#### **TLB的别名问题**

我先来思考第一个问题，别名是否存在。我们知道PIPT的数据cache不存在别名问题。物理地址是唯一的，一个物理地址一定对应一个数据。

但是不同的物理地址可能存储相同的数据。也就是说，物理地址对应数据是一对一关系，反过来是多对一关系。由于TLB的特殊性，存储的是虚拟地址和物理地址的对应关系。

因此，对于单个进程来说，同一时间一个虚拟地址对应一个物理地址，一个物理地址可以被多个虚拟地址映射。将PIPT数据cache类比TLB，我们可以知道TLB不存在别名问题。

而VIVT Cache存在别名问题，原因是VA需要转换成PA，PA里面才存储着数据。中间多经传一手，所以引入了些问题。

#### **TLB的歧义问题**

我们知道不同的进程之间看到的虚拟地址范围是一样的，所以多个进程下，**不同进程的相同的虚拟地址可以映射不同的物理地址**。这就会造成歧义问题。

例如，进程A将地址0x2000映射物理地址0x4000。进程B将地址0x2000映射物理地址0x5000。当进程A执行的时候将0x2000对应0x4000的映射关系缓存到TLB中。当切换B进程的时候，B进程访问0x2000的数据，会由于命中TLB从物理地址0x4000取数据。这就造成了歧义。

如何消除这种歧义？我们可以借鉴VIVT数据cache的处理方式，在进程切换时将整个TLB无效。切换后的进程都不会命中TLB，但是会导致性能损失。

#### **如何尽可能的避免flush TLB**

首先需要说明的是，这里的flush理解成使无效的意思。我们知道进程切换的时候，为了避免歧义，我们需要主动flush整个TLB。如果我们能够区分不同的进程的TLB表项就可以避免flush TLB。

我们知道Linux如何区分不同的进程？每个进程拥有一个独一无二的进程ID。如果TLB在判断是否命中的时候，除了比较tag以外，再额外比较进程ID该多好呢！这样就可以区分不同进程的TLB表项。进程A和B虽然虚拟地址一样，但是进程ID不一样，自然就不会发生进程B命中进程A的TLB表项。

所以，**TLB添加一项ASID(Address Space ID)的匹配。ASID就类似进程ID一样，用来区分不同进程的TLB表项**。这样在进程切换的时候就不需要flush TLB。但是仍然需要软件管理和分配ASID。

![img](https://ask.qcloudimg.com/http-save/yehe-7134177/293136b0b9700d4b2a98edff70c318f8.jpeg)

#### **如何管理ASID**

ASID和进程ID肯定是不一样的，别混淆二者。进程ID取值范围很大。但是ASID一般是8或16 bit。所以只能区分256或65536个进程。

我们的例子就以8位ASID说明。所以我们不可能将进程ID和ASID一一对应，我们必须为每个进程分配一个ASID，进程ID和每个进程的ASID一般是不相等的。每创建一个新进程，就为之分配一个新的ASID。当ASID分配完后，flush所有TLB，重新分配ASID。所以，如果想完全避免flush TLB的话，理想情况下，运行的进程数目必须小于等于256。

管理ASID上需要软硬结合。**Linux kernel为了管理每个进程会有个task_struct结构体，我们可以把分配给当前进程的ASID存储在这里。页表基地址寄存器有空闲位也可以用来存储ASID**。

**当进程切换时，可以将页表基地址和ASID(可以从task_struct获得)共同存储在页表基地址寄存器中。当查找TLB时，硬件可以对比tag以及ASID是否相等(对比页表基地址寄存器存储的ASID和TLB表项存储的ASID)。**如果都相等，代表TLB hit。否则TLB miss。当TLB miss时，需要多级遍历页表，查找物理地址。然后缓存到TLB中，同时缓存当前的ASID。

#### **更上一层楼**

我们知道内核空间和用户空间是分开的，并且内核空间是所有进程共享。

既然内核空间是共享的，进程A切换进程B的时候，如果进程B访问的地址位于内核空间，完全可以使用进程A缓存的TLB。但是现在由于ASID不一样，导致TLB miss。

我们针对内核空间这种全局共享的映射关系称之为global映射。针对每个进程的映射称之为non-global映射。所以，我们在最后一级页表中引入一个bit(non-global (nG) bit)代表是不是global映射。

当虚拟地址映射物理地址关系缓存到TLB时，将nG bit也存储下来。当判断是否命中TLB时，当比较tag相等时，再判断是不是global映射，如果是的话，直接判断TLB hit，无需比较ASID。当不是global映射时，最后比较ASID判断是否TLB hit。

![img](https://ask.qcloudimg.com/http-save/yehe-7134177/fa8d12b4a568da0d2e9258b365dba8e6.jpeg)

#### **什么时候应该flush TLB**

我们再来最后的总结，什么时候应该flush TLB。

- 当ASID分配完的时候，需要flush全部TLB。ASID的管理可以使用bitmap管理，flush TLB后clear整个bitmap。
- 当我们建立页表映射的时候，就需要flush虚拟地址对应的TLB表项。第一印象可能是修改页表映射的时候才需要flush TLB，但是实际情况是只要建立映射就需要flush TLB。原因是，建立映射时你并不知道之前是否存在映射。例如，建立虚拟地址A到物理地址B的映射，我们并不知道之前是否存在虚拟地址A到物理地址C的映射情况。所以就统一在建立映射关系的时候flush TLB。



### malloc 和 free

#### malloc() 如何分配内存？

实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

* 方式一：通过 brk() 系统调用从堆分配内存
* 方式二：通过 mmap() 系统调用在文件映射区域分配内存；

方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

> 什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？

malloc() 源码里默认定义了一个阈值：

* 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
* 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

注意，不同的 glibc 版本定义的阈值也是不同的。

man 手册

> 通常，malloc () 从堆中分配内存，并调整使用sbrk(2)根据需要设置堆的大小。当分配
> 大于MMAP_THRESHOLD字节的内存块时，glibc malloc () 实现使用mmap(2)将内存分配为私有匿名映射。  MMAP_THRESHOLD默认为 128 kB ，但可以使用mallopt(3)进行调整。在 Linux 4.7 之前，使用 mmap(2)执行的分配不受 RLIMIT_DATA资源限制的影响；自 Linux 4.7 起，此限制也适用于使用 mmap(2) 执行的分配。

#### malloc() 分配的是物理内存吗？

不是的，**malloc() 分配的是虚拟内存**。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。

#### malloc(1) 会分配多大内存？

malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是**会预分配更大的空间作为内存池**。

具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系，我们就以 malloc 默认的内存管理器（Ptmalloc2）来分析。

接下里，我们做个实验，用下面这个代码，通过 malloc 申请 1 字节的内存时，看看操作系统实际分配了多大的内存空间。

```c
#include <stdio.h>
#include <malloc.h>

int main() {
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());
  
  //申请1字节的内存
  void *addr = malloc(1);
  printf("此1字节的内存起始地址：%x\n", addr);
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());
 
  //将程序阻塞，当输入任意字符时才往下执行
  getchar();

  //释放内存
  free(addr);
  printf("释放了1字节的内存，但heap堆并不会释放\n");
  
  getchar();
  return 0;
}
```

执行代码（**先提前说明，我使用的 glibc 库的版本是 2.17**）：

![图片](https://img-blog.csdnimg.cn/img_convert/080ee187c8c92db45092b6688774e8da.png)

我们可以通过 /proc//maps 文件查看进程的内存分布情况。我在 maps 文件通过此 1 字节的内存起始地址过滤出了内存地址的范围。

```shell
[root@xiaolin ~]# cat /proc/3191/maps | grep d730
00d73000-00d94000 rw-p 00000000 00:00 0                                  [heap]
```

这个例子分配的内存小于 128 KB，所以是通过 brk() 系统调用向堆空间申请的内存，因此可以看到最右边有 [heap] 的标识。

可以看到，堆空间的内存地址范围是 00d73000-00d94000，这个范围大小是 132KB，也就说明了 **malloc(1) 实际上预分配 132K 字节的内存**。

可能有的同学注意到了，程序里打印的内存起始地址是 `d73010`，而 maps 文件显示堆内存空间的起始地址是 `d73000`，为什么会多出来 `0x10` （16字节）呢？这个问题，我们先放着，后面会说。

#### malloc() 为什么不全部使用 mmap 来分配内存？

因为向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。

所以，申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用。

另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。

也就是说，**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。

为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。

**等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗**。

#### malloc() 为什么不全部使用 brk 来分配内存？

前面我们提到通过 brk 从堆空间分配的内存，并不会归还给操作系统，那么我们那考虑这样一个场景。

如果我们连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。

![图片](https://img-blog.csdnimg.cn/img_convert/75edee0cb75450e7987a8a482b975bda.png)

但是如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。

因此，随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

所以，malloc 实现中，充分考虑了 brk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。

#### malloc() 如果没有成功，可能什么原因，计算机会做什么？

* 内存不足。
* 在前面的程序中出现了内存的越界访问，导致malloc()分配函数所涉及的一些信息被破坏。下次再使用malloc()函数申请内存就会失败，返回空指针NULL(0)。

查看方式：

1、内存不足，使用free命令查看当前还有多少内存，看是否合理，之前是否有内存泄漏等。

2、按照流程查看malloc失败前的几次malloc、memcpy或字符串拷贝等，查看是否有内存越界。

man 手册

> 默认情况下，Linux 遵循乐观的内存分配策略。这意味着当malloc () 返回非 NULL 时，不能保证内存确实可用。如果 发现系统内存不足，OOM 杀手将杀死一个或多个进程。更多信息请参见proc(5)中/proc/sys/vm/overcommit_memory和 /proc/sys/vm/oom_adj的描述，以及 Linux 内核源文件 Documentation/vm/overcommit-accounting.rst。

#### malloc() 是线程安全的吗 ?是可重入的吗？

**线程安全**

man 手册

> 为了避免多线程应用程序中的损坏，内部使用互斥锁来保护这些函数使用的内存管理数据结构。在线程同时分配和释放内存的多线程应用程序中，可能存在对这些互斥体的争用。为了在多线程应用程序中可伸缩地处理内存分配，如果检测到互斥争用，glibc 会创建
> 额外的内存分配区域。每个 arena 都是由系统内部分配的大内存区域（使用brk(2)或mmap(2)），并且使用自己的互斥锁进行管理。

<https://blog.csdn.net/qq_40334837/article/details/96423711>

**malloc 可重入吗？**

在man手册中，与系统调用有关的函数都会说明该函数是否线程安全，所以这也是我们写代码需要关注的，而线程安全与函数是否可重入有很大关系，**函数可重入一定是线程安全的，线程安全不一定是可重入函数，比如maloc使用递归锁实现了线程安全，但它是不可重入函数**，所以不可重入函数可以通过内核锁实现线程安全（锁是系统调用，所以工作在内核态，也叫内核锁），还有很多函数也是这样实现线程安全的

**信号**

1、基本概念

软中断信号（signal，又简称为信号）用来**通知进程发生了异步事件**。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。注意，信号只是用来通知某进程发生了什么事件，并不给该进程传递任何数据。

收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类：

* 第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。
* 第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。
* 第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。

**内核对信号的基本处理方法**

**内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理**，比如线程中系统调用malloc申请内存，所以从用户态进入了内核态，现在信号发生，这时操作系统会从内核态跳转到用户态执行signal函数（signal函数本身是应用层的一行代码需要被运行，属于用户态，当执行到绑定的函数时，函数内部有系统调用函数，然后进入内核态）。进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数，而且执行用户定义的函数的方法很巧妙（这个函数时signal函数绑定的那个处理信号函数，比如里面出现malloc系统调用），内核是在用户栈上创建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时，才返回原先进入内核的地方（线程中调用malloc所在内核执行处）。这样做的原因是用户定义的处理函数不应该在内核态下执行，所以一般在信号处理函数中，最好仅仅用来打印一条信息，然后使用longjmp或者exit退出。

![img](https://img-blog.csdnimg.cn/20190718103716258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzM0ODM3,size_16,color_FFFFFF,t_70)

综上所述，如果信号被捕获，执行点从内核态返回用户态，在返回时，如果发现待执行进程存在被触发的signal，那么在离开内核态之后（也就是将CPU切换到用户模式），执行用户进程为该signal绑定的signal处理函数，从这一点上看，signal处理函数是在用户进程上下文中执行的。当执行完signal处理函数之后，再返回到用户进程被中断或者system call（软中断或者指令陷阱）打断的地方。

**如果signal处理函数使用系统调用，比如malloc，free**

信号处理函数中只能调用可重入函数，而不能调用不可重入函数。进程捕捉到信号并对其进行处理时，正在执行的正常指令序列就被信号处理程序临时中断，它首先执行该信号处理函数中的指令。如果从信号处理程序返回，则继续执行在捕捉到信号时正在执行的正常指令序列（这类似于发生硬件中断时所做的）。但在信号处理函数中，不能判断捕捉到信号时线程执行到何处。

 信号处理函数默认情况下是在进程的主线程调用的，这种情况下使用不可重入函数，有可能会造成不可预知的错误。比如调用了malloc函数，为了保证malloc是线程安全的，所以内部使用了锁，根据malloc中锁的不同处理方式，分别可能会导致以下情况的发生：

1) 如果是普通锁，在主线程中malloc函数获取锁之后被signal中断，在signal处理函数中继续调用malloc，因为主线程中的malloc已经获取到了锁，signal处理函数只能等待锁释放，而主线程中的malloc函数正在等待signal处理函数返回后继续执行，这样就造成了锁死；

2) 如果是递归锁，那么signal处理函数中的malloc函数获取锁后进行内存分配，因为上次的malloc操作还没完，可能成会造成内存数据混乱。

就定时而言，可不直接使用singal alarm，而使用posix定时器，通过通知线程的方式，将定时处理函数放到单独的线程中来处理。

**内核线程调度系统对malloc的处理方法**

多线程之前使用malloc是安全的，虽然它不可重入，但是用锁实现了

1) 如果是普通锁，A线程获取堆栈锁后，B线程必须等待A线程执行完成后，释放锁，然后B线程malloc才能申请内存。

2) 如果是递归锁，内核调度系统在线程之间调度时，如果线程A的malloc函数一旦开始了申请，它就不会交出CPU，而是等malloc完成后，才会根据情况是否交出CPU，如果没有特别重要的处理，调度器就会跳转到线程B中执行，如果B线程执行到malloc，同理。（调度器如何工作等我搞明白再修正这

**代码例子**

<https://zhuanlan.zhihu.com/p/371222679>

```c
#include <stdio.h>
#include <unistd.h>
#include <signal.h>
#include <string.h>
#include <stdlib.h>

void sig_handler(int signum)
{
    printf("\nInside handler function\n");
    char *p = NULL;
    p = (char *)malloc(sizeof(char) * 1024);
    if (NULL == p)
    {
        return;
    }
    free(p);
}


int main(int argc, char **argv)
{
    char *p = NULL;
    signal(SIGINT, sig_handler); // 初始化信号处理函数
    
    while (1)
    {
        p = (char *)malloc(sizeof(char) * 1024);
        if (NULL == p)
        {
            continue;
        }
        free(p);
    }

    return 0;
}
```

编译上述代码：

```text
gcc -g testsigint.c -o testsigint
```

运行代码，不停的按ctrl+c（要亿点点运气）

```text
[root@root]# ./testsigint
^C
Inside handler function
^C
Inside handler function
^C
Inside handler function
^C
Inside handler function
^C^C^C^C^C^C
```

当出现多个^C的时候，证明该进程已经锁死了。

新开一个窗口，获取该进程的堆栈打印。

```text
[root@root]# pstack `pidof testsigint`
#0  0x00007faae50275cc in __lll_lock_wait_private () from /lib64/libc.so.6
#1  0x00007faae4fa3b12 in _L_lock_16654 () from /lib64/libc.so.6
#2  0x00007faae4fa0753 in malloc () from /lib64/libc.so.6
#3  0x0000000000400634 in sig_handler (signum=2) at testsigint.c:11
#4  <signal handler called>
#5  0x00007faae4f9bf1b in _int_free () from /lib64/libc.so.6
#6  0x0000000000400699 in main (argc=1, argv=0x7fff29e79aa8) at testsigint.c:32
[root@localhost ~]# pstack `pidof testsigint`
#0  0x00007faae50275cc in __lll_lock_wait_private () from /lib64/libc.so.6
#1  0x00007faae4fa3b12 in _L_lock_16654 () from /lib64/libc.so.6
#2  0x00007faae4fa0753 in malloc () from /lib64/libc.so.6
#3  0x0000000000400634 in sig_handler (signum=2) at testsigint.c:11
#4  <signal handler called>
#5  0x00007faae4f9bf1b in _int_free () from /lib64/libc.so.6
#6  0x0000000000400699 in main (argc=1, argv=0x7fff29e79aa8) at testsigint.c:32
```

可以看到进程挂死在了malloc和free结对的地方，肯定是有内部资源互斥了。

在进程通过信号产生软中断进入用户自定义的信号处理函数，内核会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而用户态函数内部使用的一些全局变量、静态变量，锁等并不在保护之列，所以如果这些值在信号处理函数发生了改变，那么当函数回到用户原本的上下文继续执行时，其结果就不可预料了。

比如上面的malloc，将如一个进程此时正在执行malloc分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个malloc，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表和一些锁，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用可能回去获取同一把锁，也可能回去修改内存里面的值，这样造成的结果是不可预期的。

#### free() 释放内存，会立即归还给操作系统吗？

我们在上面的进程往下执行，看看通过 free() 函数释放内存后，堆内存还在吗？

![图片](https://img-blog.csdnimg.cn/img_convert/1a9337f8f6b83fbc186f257511b5ce67.png)

从下图可以看到，通过 free 释放内存后，堆内存还是存在的，并没有归还给操作系统。

![图片](https://img-blog.csdnimg.cn/img_convert/2b8f63892830553ec04c5f05f336ae8b.png)

这是因为与其把这 1 字节释放给操作系统，不如先缓存着放进 malloc 的内存池里，当进程再次申请 1 字节的内存时就可以直接复用，这样速度快了很多。

当然，当进程退出后，操作系统就会回收进程的所有资源。

上面说的 free 内存后堆内存还存在，是针对 malloc 通过 brk() 方式申请的内存的情况。

如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会归归还给操作系统。

我们做个实验验证下， 通过 malloc 申请 128 KB 字节的内存，来使得 malloc 通过 mmap 方式来分配内存。

```c
#include <stdio.h>
#include <malloc.h>

int main() {
  //申请1字节的内存
  void *addr = malloc(128*1024);
  printf("此128KB字节的内存起始地址：%x\n", addr);
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());

  //将程序阻塞，当输入任意字符时才往下执行
  getchar();

  //释放内存
  free(addr);
  printf("释放了128KB字节的内存，内存也归还给了操作系统\n");

  getchar();
  return 0;
}
```

执行代码：

![图片](https://img-blog.csdnimg.cn/img_convert/500fdc021d956f60963f308760f511d0.png)

查看进程的内存的分布情况，可以发现最右边没有 [head] 标志，说明是通过 mmap 以匿名映射的方式从文件映射区分配的匿名内存。

![图片](https://img-blog.csdnimg.cn/img_convert/501f458b8d35abe5e378a0f14c667797.png)

然后我们释放掉这个内存看看：

![图片](https://img-blog.csdnimg.cn/img_convert/fcdbe91cc03b6a2f6e93dd1971d1b438.png)

再次查看该 128 KB 内存的起始地址，可以发现已经不存在了，说明归还给了操作系统。

![图片](https://img-blog.csdnimg.cn/img_convert/3f63c56b131d92806b5aabca29d33a38.png)

对于 「malloc 申请的内存，free 释放内存会归还给操作系统吗？」这个问题，我们可以做个总结了：

* malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
* malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

#### free() 函数只传入一个内存地址，为什么会知道要释放多大的内存？

还记得，我前面提到， malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节吗？

这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

![图片](https://img-blog.csdnimg.cn/img_convert/cb6e3ce4532ff0a6bfd60fe3e52a806e.png)

这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。

### 连续存储管理

#### 静态分区分配是什么？有什么优缺点？

优点：简单，要求的硬件支持少，软件算法也简单

缺点：

* 内存利用率低，产生内部碎片
* 尺寸和分区数量难以确定
* 分区总数固定，限制了并发执行的程序数量

#### 动态分区分配是什么？有什么优缺点？

不预先划分内存，在程序装入内存时，根据进程的大小动态地建立分区，并使得分区的大小正好适合进程的需要，因此系统中分区的大小和数目是可变的。

在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略

优点：

* 没有内部碎片
* 能较有效利用内存空间，提高了多道程序系统对内存的共享

缺点：

* 容易产生外部碎片问题，为解决外部碎片问题，需要采用动态重定位，增加了计算机硬件成本，而紧凑工作又要花费大量处理机时间

#### 什么是内部碎片？什么是外部碎片？有什么解决方法？

**内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；**

内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。

**外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。**

外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请

**解决外部碎片 --> 紧缩：**

移动内存中的进程，将碎片集中起来，重新构成大的内存块。需要运行时的动态重定位，费时。

紧缩方向：

* 向一头紧缩
* 向两头紧缩。

紧缩时机：

* 在释放分区时，如果不能与空闲分区合并，则立刻进行紧缩。**好处是不存在外部碎片，坏处是费时。**
* 在内存分配时，如果剩余的空闲空间总量能满足要求但没有一个独立的空闲块能满足要求，则进行紧缩。**好处是减少紧缩次数**。

#### 首次适应算法？

思想：从头到尾寻找合适的分区

将所有空闲分区**按照地址递增的次序链接**，在申请内存分配时，从链首开始查找，**将满足需求的第一个**空闲分区分配给作业

优点：

* 综合看，首次适应算法性能最好。**算法开销小**，回收分区后，一般不需要对空闲分区队列重新排序
* 分区集中在内存的前部，大内存留在后面，便于释放后的合并

#### 最佳适应算法？

思想：优先使用更小的分区，以保留更多的大分区

将所有空闲分区按照**从小到大**的顺序形成空闲分区链，在申请内存分配时，总是把**满足需求的、最小的**空闲分区分配给作业

优点：会有更多的大分区被保留下来，更能满足大进程需求

缺点

* 会产生很多太小的、难以利用的外部碎片，需要频繁紧缩
* **算法开销大**，回收分区后可能需要对空闲分区队列重新排序

#### 最差适应算法？

思想：优先使用更大的分区，以防止产生太小的不可用碎片

将所有的空闲分区按照**从大到小**的顺序形成空闲分区链，在申请内存分配时，总是把**满足需求的、最大的**空闲分区分配给作业

优点：优先使用更大的分区，以防止产生太小的不可用碎片

缺点

* 大分区容易被用完，不利于大进程
* **算法开销大**，回收分区后可能需要对空闲分区队列重新排序

#### 邻近适应算法？（循环首次适应算法）

思想：由首次适应算法演变而来，每次从上次查找结束的位置开始查找

将所有空闲分区**按照地址递增的次序链接**（可排列成循环链表），在申请内存分配时，**总是从上次找到的空闲分区的下一个空闲分区开始查找**，将满足需求的第一个空闲分区分配给作业

优点：不用每次都从低地址的小分区开始检索**算法开销小**（原因同首次适应算法）

缺点：会使高地址的大分区也被用完

#### Buddy 伙伴算法？

伙伴算法：将动态分区的大小限定为 2^k  字节，分割方式限定为平分，分区就会变得较为规整，分割与合并会更容易，可以减少一些外部碎片。平分后的两块互称伙伴。

![img](https:////upload-images.jianshu.io/upload_images/5346502-c766de1d4facb6ee.png?imageMogr2/auto-orient/strip|imageView2/2/w/653/format/webp)

分配时可能要多次平分，释放时可能要多次合并。举例：

![img](https:////upload-images.jianshu.io/upload_images/5346502-937492787301e74a.png?imageMogr2/auto-orient/strip|imageView2/2/w/565/format/webp)

**伙伴的概念**，满足以下三个条件的称为伙伴：

* 两个块大小相同；
* 两个块地址连续；
* 两个块必须是同一个大块中分离出来的；

**关于位图**
Linux内核伙伴算法中每个order 的位图都表示所有的空闲块，位图的某位对应于两个伙伴块，为1就表示其中一块忙，为0表示两块都闲或都在使用。系统每次分配和回收伙伴块时都要对它们的伙伴位跟1进行[异或运算](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97)。所谓[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)是指刚开始时，两个伙伴块都空闲，它们的伙伴位为0，如果其中一块被使用，[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得1；如果另一块也被使用，[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得0；如果前面一块回收了[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得1；如果另一块也回收了[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得0。
**位图的主要用途是在回收算法中指示是否可以和伙伴块合并，分配时只要搜索空闲链表就足够了。当然，分配的同时还要对相应位异或一下，这是为回收算法服务**

**记录大小不同的空闲页**

![img](https:////upload-images.jianshu.io/upload_images/5346502-8d12e8a8d7d5d353.png?imageMogr2/auto-orient/strip|imageView2/2/w/550/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/5346502-b76497f021809357.png?imageMogr2/auto-orient/strip|imageView2/2/w/343/format/webp)

**分配和释放过程**

Buddy算法的分配原理：

　　假如系统需要$4(2^2)$个页面大小的内存块，该算法就到free_area[2]中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找free_area[3],如果free_area[3]中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入free_area[2]，后4个页面分配出去，free_area[3]中也没有，就再向上查找，如果free_area[4]中有，就将这$16(2^4)$个页面等分成两份，前一半挂如free_area[3]的链表头部，后一半的8个页等分成两等分，前一半挂free_area[2]
的链表中，后一半分配出去。假如free_area[4]也没有，则重复上面的过程，知道到达free_area数组的最后，如果还没有则放弃分配。

![image.png](https://s2.loli.net/2022/10/17/6IsoA937UebM1G8.png)

 Buddy算法的释放原理：

　　内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块($2^9$个页面)。

**伙伴算法是静态分区和动态分区法的折中，比静态分区法灵活，不受分区尺寸及个数的限制；比动态分区法规范，不易出现外部碎片。会产生内部碎片，但比静态分区的小。**

**优缺点**

伙伴算法的一大优势是它能够完全避免外部碎片的产生，申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。

**适合大小恰好为 $2^k$  大小的，否则会有比较大的内部碎片。（Linux C++ vector 2 倍扩容机制）**

优点：

* 较好的解决外部碎片问题
* 当需要分配若干个内存页面时，用于DMA的内存页面必须连续，伙伴算法很好的满足了这个要求
* 只要请求的块不超过512个页面(2K)，内核就尽量分配连续的页面
* 针对大内存分配设计

缺点：

* 合并的要求太过严格，只能是满足伙伴关系的块才能合并，比如第1块和第2块就不能合并。
* 碎片问题：一个连续的内存中仅仅一个页面被占用，导致整块内存区都不具备合并的条件
* 浪费问题：伙伴算法只能分配2的幂次方内存区，当需要8K（2页）时，好说，当需要9K时，那就需要分配16K（4页）的内存空间，但是实际只用到9K空间，多余的7K空间就被浪费掉。
* 算法的效率问题： 伙伴算法拆分和合并涉及了比较多的计算还有链表和位图的操作，开销还是比较大的，如果每次 $2^n$ 大小的伙伴块就会合并到  $2^{n+1}$ 的链表队列中，那么 $2^n$ 大小链表中的块就会因为合并操作而减少，但系统随后立即有可能又有对该大小块的需求，为此必须再从 $2^{n+1}$ 大小的链表中拆分，这样的合并又立即拆分的过程是无效率的。

**Linux针对大内存的物理地址分配**，采用伙伴算法，如果是针对小于一个page的内存，频繁的分配和释放，有更加适宜的解决方案，如slab和kmem_cache等

**优化?**

* 解决内部碎片过大问题（eg：申请5页，分配8页，浪费3页）：
  * ucore 在前部留下需要的页数，释放掉尾部各页。每次释放1页，先划分成页块，再逐个释放。
* 解决切分与合并过于频繁的问题：
  * 用得较多的是单个页。位于处理器Cache中页称为热页（hot page），其余页称为冷页（cold page）。处理器对热页的访问速度要快于冷页。可建一个热页队列（per_cpu_page），暂存刚释放的单个物理页，将合并工作向后推迟 Lazy。总是试图从热页队列中分配单个物理页。分配与释放都在热页队列的队头进行。
* 解决内存碎化(有足够多的空闲页，但是没有大页块)问题：
  * 将页块从一个物理位置移动到另一个物理位置，并保持移动前后逻辑地址不变（拷贝页块内容）
  * 逻辑内存管理器。
* 满足大内存的需求：

* 物理内存空间都耗尽的情况：
  * 在任何情况下，都应该预留一部分空闲的物理内存以备急需。定义两条基准线low和high，当空闲内存量小于low时，应立刻开始回收物理内存，直到空闲内存量大于high。

* 回收物理内存：
  * 法一：启动一个守护进程，专门用于回收物理内存。周期性启动，也可被唤醒。
  * 法二：申请者自己去回收内存。实际是由内存分配程序回收。回收的方法很多，如释放缓冲区、页面淘汰等。

#### Slab 算法？

slab是Linux操作系统的一种内存分配机制。其工作是针对一些**经常分配并释放的对象**，如进程描述符等，这些对象的**大小一般比较小**，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内部碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。

Linux 的slab 可有三种状态：

* 满的：slab 中的所有对象被标记为使用。
* 空的：slab 中的所有对象被标记为空闲。
* 部分：slab 中的对象有的被标记为使用，有的被标记为空闲。

slab 分配器首先从部分空闲的slab 进行分配。如没有，则从空的slab 进行分配。如没有，则从物理连续页上分配新的slab，并把它赋给一个cache ，然后再从新slab 分配空间。

与传统的内存管理模式相比， slab 缓存分配器提供了很多优点。
　　1、内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。
　　2、slab 缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。
　　3、slab 分配器还支持通用对象的初始化，从而避免了为同一目的而对一个对象重复进行初始化。
　　4、slab 分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。

### 非连续存储管理

#### 谈谈内存分段？

**什么是内存分段**

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。**

**分段机制下，虚拟地址和物理地址是如何映射的？**

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。

![img](https://img-blog.csdnimg.cn/a9ed979e2ed8414f9828767592aadc21.png)

段选择因子和段内偏移量：

* **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
* 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

在上面，知道了虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：

![img](https://img-blog.csdnimg.cn/c5e2ab63e6ee4c8db575f3c7c9c85962.png)

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

**分段的优点**

**分段的缺点及解决方案**

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

* 第一个就是**内存碎片**的问题。
* 第二个就是**内存交换的效率低**的问题。

接下来，说说为什么会有这两个问题。

> 我们先来看看，分段为什么会产生内存碎片的问题？

我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：

* 游戏占用了 512MB 内存
* 浏览器占用了 128MB 内存
* 音乐占用了 256 MB 内存。

这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。

![img](https://img-blog.csdnimg.cn/6142bc3c917e4a6298bdb62936e0d332.png)

> 内存分段会出现内存碎片吗？

内存碎片主要分为，内部内存碎片和外部内存碎片。

内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以**不会出现内部内存碎片**。

但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。

解决「外部内存碎片」的问题就是**内存交换**。

可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。

> 再来看看，分段为什么会导致内存交换效率低的问题？

对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页

#### 谈谈内存分页？

**什么是内存分页**

分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（*Paging*）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

虚拟地址与物理地址之间通过**页表**来映射，如下图：

![img](https://img-blog.csdnimg.cn/08a8e315fedc4a858060db5cb4a654af.png)

页表是存储在内存里的，**内存管理单元** （*MMU*）就做将虚拟内存地址转换成物理地址的工作。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

**分页是怎么解决分段的「外部内存碎片和内存交换效率低」的问题？**

内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而**采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。**

但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对**内存分页机制会有内部内存碎片**的现象。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

![img](https://img-blog.csdnimg.cn/388a29f45fe947e5a49240e4eff13538.png)

更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

**分页机制下，虚拟地址和物理地址是如何映射的？**

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。

![img](https://img-blog.csdnimg.cn/7884f4d8db4949f7a5bb4bbd0f452609.png)

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

* 把虚拟内存地址，切分成页号和偏移量；
* 根据页号，从页表里面，查询对应的物理页号；
* 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

下面举个例子，虚拟内存中的页通过页表映射为了物理内存中的页，如下图：

![img](https://img-blog.csdnimg.cn/8f187878c809414ca2486b0b71e8880e.png)

这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定是会有问题的。

**分页的优点**

**分页的缺点及解决方案**

有空间上的缺陷。

因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。

在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。

这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。

那么，`100` 个进程的话，就需要 `400MB` 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。

**多级页表**

要解决上面的问题，就需要采用一种叫作**多级页表**（*Multi-Level Page Table*）的解决方案。

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。如下图所示：

![img](https://img-blog.csdnimg.cn/19296e249b2240c29f9c52be70f611d5.png)

> 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？

当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。

其实我们应该换个角度来看问题，还记得计算机组成原理里面无处不在的**局部性原理**么？

每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。

如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= `0.804MB`，这对比单级页表的 `4MB` 是不是一个巨大的节约？

那么为什么不分级的页表就做不到这样节约内存呢？

我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。

对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：

* 全局页目录项 PGD（*Page Global Directory*）；
* 上层页目录项 PUD（*Page Upper Directory*）；
* 中间页目录项 PMD（*Page Middle Directory*）；
* 页表项 PTE（*Page Table Entry*）；

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png)

**TLB**

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。

程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

![img](https://img-blog.csdnimg.cn/edce58534d9342ff89f5261b1929c754.png)

我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

![img](https://img-blog.csdnimg.cn/a3cdf27646b24614a64cfc5d7ccffa35.png)

在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。

#### 段页式内存管理？

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

![img](https://img-blog.csdnimg.cn/f19ebd6f70f84083b0d87cc5e9dea8e3.png)

段页式内存管理实现的方式：

* 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
* 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![img](https://img-blog.csdnimg.cn/8904fb89ae0c49c4b0f2f7b5a0a7b099.png)

段页式地址变换中要得到物理地址须经过三次内存访问：

* 第一次访问段表，得到页表起始地址；
* 第二次访问页表，得到物理页号；
* 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

### 页面置换算法

#### 谈谈系统抖动与工作集

如果低优先级进程所分配的帧数低于计算机体系结构所需的最小数量，那么必须暂停该进程执行。然后，应调出它的所有剩余页面，以便释放所有分配的帧。这个规定引入了中级 CPU 调度的换进换出层。

事实上，需要研究一下没有“足够”帧的进程。如果进程没有需要支持活动使用页面的帧数，那么它会很快产生缺页错误。此时，必须置换某个页面。然而，由于它的所有页面都在使用中，所以必须立即置换需要再次使用的页面。因此，它会再次快速产生缺页错误，再一次置换必须立即返回的页面，如此快速进行。

这种高度的页面调度活动称为抖动。如果一个进程的调页时间多于它的执行时间，那么这个进程就在抖动。

**系统抖动的原因**

抖动导致严重的性能问题。考虑以下场景，这是基于早期调页系统的实际行为。

操作系统监视 CPU 利用率。如果 CPU 利用率太低，那么通过向系统引入新的进程来增加多道程度。采用全局置换算法会置换任何页面，而不管这些页面属于哪个进程。

现在假设进程在执行中进入一个新阶段，并且需要更多的帧。它开始出现缺页错误，并从其他进程那里获取帧。然而，这些进程也需要这些页面，因此它们也会出现缺页错误，并且从其他进程中获取帧。这些缺页错误进程必须使用调页设备以将页面换进和换出。当它们为调页设备排队时，就绪队列清空。随着进程等待调页设备，CPU 利用率会降低。

CPU 调度程序看到 CPU 利用率的降低，进而会增加多道程度。新进程试图从其他运行进程中获取帧来启动，从而导致更多的缺页错误和更长的调页设备队列。因此，CPU 利用率进一步下降，并且 CPU 调度程序试图再次增加多道程度。这样就出现了抖动，系统吞吐量陡降，缺页错误率显著增加。结果，有效内存访问时间增加，没有工作可以完成，因为进程总在忙于调页。

[![img](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-IOqZB0TN5f07263269538.gif)](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-IOqZB0TN5f07263269538.gif)
图 1 系统抖动

这种现象如图 1 所示，这里 CPU 利用率是按多道程度来绘制的。随着多道程度的增加，CPU 利用率也增加，虽然增加得更慢，直到达到最大值。如果多道程度还要进一步增加，那么系统抖动就开始了，并且 CPU 利用率急剧下降。此时，为了提高 CPU 利用率并停止抖动，必须降低多道程度。

通过局部置换算法或优先级置换算法，可以限制系统抖动。如果一个进程开始抖动，那么由于采用局部置换，它不能从另一个进程中获取帧，而且也不能导致后者抖动。然而，这个问题并没有完全解决。如果进程抖动，那么在大多数时间内会排队等待调页设备。由于调页设备的平均队列更长，缺页错误的平均等待时间也会增加。因此，即使对于不再抖动的进程，有效访问时间也会增加。

为了防止抖动，应为进程提供足够多的所需帧数。但是如何知道进程“需要”多少帧呢？有多种技术。工作集策略研究一个进程实际使用多少帧。这种方法定义了进程执行的局部性模型。

局部性模型指出，随着进程执行，它从一个局部移向另一个局部。局部性是最近使用页面的一个集合（图 2）。一个程序通常由多个不同的可能重叠的局部组成。

[![img](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-Sc3VCcce5f07263eced6b.gif)](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-Sc3VCcce5f07263eced6b.gif)
图 2 内存引用模式中的局部性

例如，当一个函数被调用时，它就定义了一个新的局部。在这个局部里，内存引用可针对函数调用的指令、它的局部变量以及全局变量的某个子集。当退出函数时，进程离开该局部，因为这个函数的局部变量和指令已不再处于活动使用状态。以后可能回到这个局部。

因此，可以看到局部是由程序结构和数据结构来定义的。局部性模型指出，所有程序都具有这种基本的内存引用结构。注意，局部性模型是目前为止缓存讨论的背后原理。如果对任何数据类型的访问是随机的而没有规律模式，那么缓存就没有用了。

假设为进程分配足够的帧以适应当前局部。该进程在其局部内会出现缺页错误，直到所有页面都在内存中；接着它不再会出现缺页错误，除非改变局部。如果没有能够分配到足够的帧来容纳当前局部，那么进程将会抖动，因为它不能在内存中保留正在使用的所有页面。

**工作集模型**

如上所述，工作集模型是基于局部性假设的。这个模型采用参数 △ 定义工作集窗口。它的思想是检查最近 △ 个页面引用。这最近 △ 个页面引用的页面集合称为工作集（如图 3 所示）。

[![img](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-KNJAFOxv5f07264c7c37a.gif)](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-KNJAFOxv5f07264c7c37a.gif)
图 3 工作集模型

如果一个页面处于活动使用状态，那么它处在工作集中。如果它不再使用，那么它在最后一次引用的 △ 时间单位后，会从工作集中删除。因此，工作集是程序局部的近似。

例如，给定如图 3 所示的内存引用序列，如果 △ 为 10 个内存引用，那么 t1 时的工作集为 {1，2, 5，6，7}。到 t2 时，工作集已经改变为 {3，4}。

工作集的精度取决于△的选择。如果 △ 太小，那么它不能包含整个局部；如果 △ 太大，那么它可能包含多个局部。在极端情况下，如果 △ 为无穷大，那么工作集为进程执行所需的所有页面的集合。

因此，最重要的工作集属性是它的大小。如果系统内的每个工作集通过计算为 WSS，那么就得到：
D=ΣWSSi

这里 D 为帧的总需求量。每个进程都使用其工作集内的页面。因此，进程 i 需要 WSSi 帧。如果总需求大于可用帧的总数（D>m），则将发生抖动，因此有些进程得不到足够的帧数。

一旦选中了 △，工作集模型的使用就很简单。操作系统监视每个进程的工作集，并为它分配大于其工作集的帧数。如果还有足够的额外帧，那么可启动另一进程。如果工作集大小的总和增加，以致超过可用帧的总数，则操作系统会选择一个进程来挂起。该进程的页面被写出（交换），并且其帧可分配给其他进程。挂起的进程以后可以重启。

这种工作集策略可防止抖动，同时保持尽可能高的多道程度。因此，它优化了 CPU 利用率。工作集模型的困难是跟踪工作集。工作集窗口是一个移动窗口。对于每次内存引用，新的引用出现在一端，最旧的引用离开另一端。如果一个页面在工作集窗口内的任何位置被引用过，那么它就在工作集窗口内。

通过定期时钟中断和引用位，我们能够近似工作集模型。

例如，假设 △ 为 10 000 个引用，而且每 5000 个引用引起定时器中断。当得到一个定时器中断时，复制并清除所有页面的引用位。如果发生缺页错误，那么可以检查当前的引用位和位于内存的两个位，这两位可以确定在过去的 10 000〜15 000 个引用之间该页面是否被使用过。如果使用过，那么这些位中至少有一位会被打开。如果没有使用过，那么这些位会被关闭。至少有一位打开的页面会被视为在工作集中。

注意，这种安排并不完全准确，这是因为并不知道在 5000 个引用内的什么位置出现了引用。通过增加历史位的数量和中断的频率（例如，10 位和每 1000 个引用中断一次），可以降低这一不确定性。然而，服务这些更为频繁中断的成本也会相应更高。

**缺页错误频率**

虽然工作集模型是成功的而且工作集的知识能够用于预先调页，但是用于控制抖动似乎有点笨拙。采用缺页错误频率（PFF）的策略是一种更为直接的方法。

这里的问题是防止抖动。抖动具有高缺页错误率。因此，需要控制缺页错误率。当缺页错误率太高时，我们知道该进程需要更多的帧。相反，如果缺页错误率太低，则该进程可能具有太多的帧。

[![img](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-K7Z1k6fU5f07265df03a1.gif)](http://bbs.yanzhishi.cn/image/show/attachments-2020-07-K7Z1k6fU5f07265df03a1.gif)
图 4 缺页错误频率

我们可以设置所需缺页错误率的上下限（图 4）。如果实际缺页错误率超过上限，则可为进程再分配一帧；如果实际缺页错误率低于下限，则可从进程中删除一帧。因此，可以直接测量和控制缺页错误率，以防止抖动。

与工作集策略一样，也可能不得不换出一个进程。如果缺页错误率增加并且没有空闲帧可用，那么必须选择某个进程并将其交换到后备存储。然后，再将释放的帧分配给具有高缺页错误率的进程。

实际上，抖动及其导致的交换对性能的负面影响很大。目前处理这一问题的最佳实践是，在可能的情况下提供足够物理内存以避免抖动和交换。从智能手机到大型机，提供足够内存，可以保持所有工作集都并发地处在内存中，并且提供最好的用户体验（除非在极端条件下）。

#### 谈谈 Belady 异常

在分页式虚拟存储器管理中，发生缺页时的置换算法采用**FIFO（先进先出）算法**时，如果对一个进程未分配它所要求的全部页面，有时就会出现**分配的页面数增多但缺页率反而提高**的异常现象。

#### 谈谈最佳页面置换算法 OPT

最佳页面置换算法基本思路是，**置换在「未来」最长时间不访问的页面**。

所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。

我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![最佳页面置换算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%9C%80%E4%BC%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

**这很理想，但是实际系统中无法实现**，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。

所以，最佳页面置换算法**作用是为了衡量你的算法的效率**，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

#### 谈谈先进先出置换算法 FIFO

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。

还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：

![先进先出置换算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/FIFO%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)

在这个请求的页面序列中，缺页共发生了 `10` 次，页面置换共发生了 `7` 次，跟最佳页面置换算法比较起来，性能明显差了很多

* 没有考虑局部性原则：**它可能会踢出一个重要的页，而这个页马上要被引用**
* 是基于队列的，而不是堆栈，可能会有Belady 异常：当进程分配到的页面数增加的时候，缺页中断的次数可能增加也可能减少

#### 谈谈第二次机会页面置换算法 SC

  对FIFO算法的改进，对FIFO算法做一个简单的修改：检查最老页面的R位。如果R位是0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是1，就将R位置0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入时间使它就像刚装入的一样，然后继续搜索。
       第二次机会（second chance）算法是寻找一个在最近的时钟间隔内没有被访问过的页面。如果所有的页面都被访问过了，该算法就简化为纯粹的FIFO算法。假设所有页面的R位都被设置了，操作系统将会一个接一个地把每个页面都移动到链表的尾部并清除被移动的页面的R位。最后又会回到原来的表头页面，此时它的R位已经被清除了，因此这个页面会被淘汰，所以这个算法总是可以结束的。

#### 谈谈最近最久未使用的置换算法 LRU

最近最久未使用（*LRU*）的置换算法的基本思路是，发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

![最近最久未使用的置换算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)

在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟先进先出置换算法比较起来，性能提高了一些。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

#### 谈谈如何优化传统的 LRU（预读、缓存失效）

传统的 LRU 算法存在这两个问题：

* **「预读失效」导致缓存命中率下降（对应第一个题目）**
* **「缓存污染」导致缓存命中率下降（对应第二个题目）**

**什么是预读机制？**

Linux 操作系统为基于 Page Cache 的读缓存机制提供**预读机制**，一个例子是：

* 应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
* 但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；

下图代表了操作系统的预读机制：

![img](https://img-blog.csdnimg.cn/img_convert/ae8252378169c8c14b8b9907983f7d8b.png)

上图中，应用程序利用 read 系统调动读取 4KB 数据，实际上内核使用预读机制（ReadaHead） 机制完成了 16KB 数据的读取，也就是通过一次磁盘顺序读将多个 Page 数据装入 Page Cache。

这样下次读取 4KB 数据后面的数据的时候，就不用从磁盘读取了，直接在 Page Cache 即可命中数据。因此，预读机制带来的好处就是**减少了 磁盘 I/O 次数，提高系统磁盘 I/O 吞吐量**。

MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO。

**预读失效会带来什么问题？**

如果**这些被提前加载进来的页，并没有被访问**，相当于这个预读工作是白做了，这个就是**预读失效**。

如果使用传统的 LRU 算法，就会把「预读页」放到 LRU 链表头部，而当内存空间不够的时候，还需要把末尾的页淘汰掉。

如果这些「预读页」如果一直不会被访问到，就会出现一个很奇怪的问题，**不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率** 。

**如何避免预读失效造成的影响**？

我们不能因为害怕预读失效，而将预读机制去掉，大部分情况下，空间局部性原理还是成立的。

要避免预读失效带来影响，最好就是**让预读页停留在内存里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在内存里的时间尽可能长**。

那到底怎么才能避免呢？

Linux 操作系统和 MySQL Innodb 通过改进传统 LRU 链表来避免预读失效带来的影响，具体的改进分别如下：

* Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）**；
* MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：**young 区域 和 old 区域**。

这两个改进方式，设计思想都是类似的，**都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法**。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。

接下来，具体聊聊 Linux 和 MySQL 是如何避免预读失效带来的影响？

> Linux 是如何避免预读失效带来的影响？

Linux 操作系统实现两个了 LRU 链表：**活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）**。

* **active list** 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；
* **inactive list** 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；

有了这两个 LRU 链表后，**预读页就只需要加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部**。如果预读的页一直没有被访问，就会从 inactive list 移除，这样就不会影响 active list 中的热点数据。

接下来，给大家举个例子。

假设 active list 和 inactive list 的长度为 5，目前内存中已经有如下 10 个页：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BC%93%E5%AD%98/active_inactive_list.drawio.png)

现在有个编号为 20 的页被预读了，这个页只会被插入到 inactive list 的头部，而 inactive list 末尾的页（10号）会被淘汰掉。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BC%93%E5%AD%98/active_inactive_list1.drawio.png)

**即使编号为 20 的预读页一直不会被访问，它也没有占用到 active list 的位置**，而且还会比 active list 中的页更早被淘汰出去。

如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 active list 的头部， active list 末尾的页（5号），会被**降级**到 inactive list ，作为 inactive list 的头部，这个过程并不会有数据被淘汰。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BC%93%E5%AD%98/active_inactive_list2.drawio.png)

> MySQL 是如何避免预读失效带来的影响？

MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域，**young 区域 和 old 区域**。

young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，这两个区域都有各自的头和尾节点，如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/young%2Bold.png)

young 区域与 old 区域在 LRU 链表中的占比关系并不是一比一的关系，而是是 7 比 3 （默认比例）的关系。

**划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。

接下来，给大家举个例子。

假设有一个长度为 10 的 LRU 链表，其中 young 区域占比 70 %，old 区域占比 30 %。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lrutwo.drawio.png)

现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lrutwo2.png)

如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。

如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lrutwo3.png)

**什么是缓存污染？**

虽然 Linux （实现两个 LRU 链表）和 MySQL （划分两个区域）通过改进传统的 LRU 数据结构，避免了预读失效带来的影响。

但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么**还存在缓存污染的问题**。

当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，**如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了**。

**缓存污染会带来什么问题**？

缓存污染带来的影响就是很致命的，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，系统性能就会急剧下降。

我以 MySQL 举例子，Linux 发生缓存污染的现象也是类似。

当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，MySQL 性能就会急剧下降。

注意， 缓存污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成缓存污染。

比如，在一个数据量非常大的表，执行了这条语句：

```sql
select * from t_user where name like "%xiaolin%";
```

可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：

* 从磁盘读到的页加入到 LRU 链表的 old 区域头部；
* 当从页里读取行记录时，也就是**页被访问的时候，就要将该页放到 young 区域头部**；
* 接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；
* 如此往复，直到扫描完表中的所有记录。

经过这一番折腾，由于这条 SQL 语句访问的页非常多，每访问一个页，都会将其加入 young 区域头部，那么**原本 young 区域的热点数据都会被替换掉，导致缓存命中率下降**。那些在批量扫描时，而被加入到 young 区域的页，如果在很长一段时间都不会再被访问的话，那么就污染了 young 区域。

举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lruthree.drawio.png)

在批量访问这些页的时候，会被逐一插入到 young 区域头部。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/innodb/lruthree1.png)

可以看到，原本在 young 区域的 6 和 7 号页都被淘汰了，而批量扫描的页基本占满了 young 区域，如果这些页在很长一段时间都不会被访问，那么就对 young 区域造成了污染。

如果 6 和 7 号页是热点数据，那么在被淘汰后，后续有 SQL 再次读取 6 和 7 号页时，由于缓存未命中，就要从磁盘中读取了，降低了 MySQL 的性能，这就是缓存污染带来的影响。

**怎么避免缓存污染造成的影响**？

前面的 LRU 算法只要数据被访问一次，就将数据加入活跃 LRU 链表（或者 young 区域），**这种 LRU 算法进入活跃 LRU 链表的门槛太低了**！正式因为门槛太低，才导致在发生缓存污染的时候，很容就将原本在活跃 LRU 链表里的热点数据淘汰了。

所以，**只要我们提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉**。

Linux 操作系统和 MySQL Innodb 存储引擎分别是这样提高门槛的：

* **Linux 操作系统**：在内存页被访问**第二次**的时候，才将页从 inactive list 升级到 active list 里。

* MySQL Innodb

 ：在内存页被访问

 第二次

 的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行

 停留在 old 区域的时间判断

 ：

* 如果第二次的访问时间与第一次访问的时间**在 1 秒内**（默认值），那么该页就**不会**被从 old 区域升级到 young 区域；
* 如果第二次的访问时间与第一次访问的时间**超过 1 秒**，那么该页就**会**从 old 区域升级到 young 区域；

提高了进入活跃 LRU 链表（或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。

在批量读取数据时候，**如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表（或者 young 区域）**，也就不会把热点数据淘汰，只会待在非活跃 LRU 链表（或者 old 区域）中，后续很快也会被淘汰。

#### 谈谈时钟页面置换算法 CLOCK （近似 LRU）

从计算开销的角度来看，**近似 LRU 更为可行，实际上这也是许多现代系统的做法**。这个想法需要硬件增加一个使用位（use bit，有时称为引用位，reference bit），这种做法在第一个支持分页的系统 Atlas one-level store 中实现。系统的每个页有一个使用位，然后这些使用位存储在某个地方（例如，它们可能在每个进程的页表中，或者只在某个数组中）。**每当页被引用（即读或写）时，硬件将使用位设置为 1**。但是，硬件不会清除该位（即将其设置为0），这由操作系统负责。

操作系统如何利用使用位来实现近似 LRU？可以有很多方法，有一个简单的方法称作**时钟算法**。想象一下，系统中的所有页都放在一个循环列表中。时钟指针开始时指向某个特定的页（哪个页不重要）。**当必须进行页替换时，操作系统检查当前指向的页 P 的使用位是 1 还是 0。如果是 1，则意味着页面 P 最近被使用，因此不适合被替换。然后，P 的使用位设置为0，时钟指针递增到下一页（P + 1）。该算法一直持续到找到一个使用位为 0 的页**。**使用位为0意味着这个页最近没有被使用过**（在最坏的情况下，所有的页都已经被使用了，那么就将所有页的使用位都设置为 0）。

请注意，这种方法不是通过使用位来实现近似 LRU 的唯一方法。实际上，任何**周期性地清除使用位，然后通过区分使用位是 1 和 0 来判定该替换哪个页的方法都是可以的**。Corbato 的时钟算法只是一个早期成熟的算法，并且具有不重复扫描内存来寻找未使用页的特点，也就是它在最差情况下，只会遍历一次所有内存。

下图展示了时钟算法的一个变种的行为。该变种在需要进行页替换时随机扫描各页，如果遇到一个页的引用位为 1，就清除该位（即将它设置为 0）。直到找到一个使用位为 0 的页，将这个页进行替换。如你所见，虽然**时钟算法不如完美的 LRU 做得好，但它比不考虑历史访问的方法要好**。

![img](https://pic.taifua.com/Picture/website/ostep/c22/9.png)

那有没有一种即能优化置换的次数，也能方便实现的算法呢？

时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。

该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

当发生缺页中断时，算法首先检查表针指向的页面：

* 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
* 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：

![时钟页面置换算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%97%B6%E9%92%9F%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)

了解了这个算法的工作方式，就明白为什么它被称为时钟（*Clock*）算法了。

#### 谈谈最不常用置换算法 LFU/NEU

最不常用（*LFU*）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。

它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。

#### 谈谈老化算法

在NFU/LFU 基础上加入频度老化，实现了“最近”，越久的使用次数权重越

   老化算法是对LFU算法的修改，其修改包括两个部分，首先，在R位被加进之前将计数器右移一位，其次，将R位加到计数器最左端的位而不是最右端的位。
       老化算法中的计数器只有有限位数，如果时钟滴答是20ms，8位一般是够用的。假如一个页面160ms没有被访问过，那么它很可能并不重要。

#### 谈谈工作集页面置换算法

由于不可能精确地确定哪个页面是最近最少使用的，那就干脆不用花费这个力气，只维持少量的信息使得我们选出的替换页面不太可能是马上又会使用的页面即可。这种少量的信息就是工作集信息。

工作集概念来源于程序访问的时空局域性。即在一段时间内，程序访问的页面将局限在一组页面集合上。例如，最近k次访问均发生在某m个页面上，那么m就是参数为k时的工作集。我们用w（k，t）来表示在时间t时k次访问所涉及的页面数量。显然，随着k的增长，w（k，t）的值也随着增长；但在k增长到某个数值后，w（k，t）的值将增长极其缓慢甚至接近停滞，并维持一段时间的稳定。

![img](https:////upload-images.jianshu.io/upload_images/13572136-9db4c4d0ad5388a2.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/1152/format/webp)

由此可以看出，如果一个程序在内存里面的页面数与其工作集大小相等或超过工作集，则该程序可在一段时间内不会发生缺页中断。如果其在内存的页面数小于工作集，则发生缺页中断的频率将增加，甚至发生内存抖动。

工作集算法的实现如下：

为页表的每个记录增加一项信息用来记录该页面最后一次被访问的时间。这个时间不必是真实时间，只要是按规律递增的一个虚拟时间即可。同时我们设置一个时间值T，如果一个页面的最后一次访问在当前时间减去T之前，则视为在工作集外，否则视为在工作集内。

**基于工作集的页面置换算法就是找出一个不在工作集中的页面并淘汰它。每个表项至少包含两条信息：上次使用该页面的近似时间和R（访问位）。**

过程：扫描所有的页面检查R位：

* 若（R == 1）：设置上次使用时间为当前实际时间，以表示缺页中断时该页面正在被使用
* 若（R == 0 且生存时间>τ）：移出这个页面，该页面在当前时钟滴答中未被访问，不在工作集中，用新的页面置换它。扫描会继续进行以更新剩余的表项。
* 若（R == 0 且生存时间≤τ）：记住最小时间。如果该页面R==0且生存时间小于或等于τ，则页面仍在工作集中。把页面临时保存下来，但是要记住生存时间最长（“上次使用时间”的最小值）。如果扫描完整个页表却没有找到合适的淘汰的页面，如果找到了一个或多个R == 0的页面，就淘汰生存时间最长的页面。

 在最坏的情况下，在当前时钟滴答中，所有的页面都被访问过了，也就是所有的R都为1，因此就随机选择一个页面淘汰，如果有的话最好选一个干净页面。

![img](https:////upload-images.jianshu.io/upload_images/13572136-bbe5368d856e4a20.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/779/format/webp)

如果在所有页面扫描后没有找到一个被替换的页面，则所有页面中最后一次访问时间最早的页面将被替换。这也是第b步记录当前最小值的原因。

优点：

* 工作集算法的优点是实现简单，只需在页表的每个记录增加一个虚拟时间域即可。因此，其空间成本不大。
* 该时间域不是每次发生访问时都需要修改，而是在需要更换页面时，页面更换算法对其进行修改，因此其时间成本也不大。

缺点：

* 是每次扫描页面进行替换时，有可能需要扫描整个页表。而我们知道，并不是所有页面都在内存里，因此扫描过程中的一大部分时间将是无用功。
* 由于其数据结构是线性的，造成每次都按同样的顺序进行扫描，这样就对某些页面不太公平。就好像评选优秀学生，如果大家的表现都同样优秀，就按照学号顺序来确定人选的话，那学号靠后的同学总是吃亏。

#### 工作集时钟页面置换算法

**在工作集页面置换算法中中，当缺页中断发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法是比较费时的。**

基于时钟算法，并且使用了工作集信息，被称为WSClock（工作集时钟）算法。由于它实现简单，性能较好，所以在实际工作中得到了广泛应用。与时钟算法一样，所需的数据结构是一个以页框为元素的循环表。最初，该表示空的，当装入第一个页面后，把它加到该表中。随着更多的页面加入，它们形成一个环。每个表项包含来自基本工作集算法的上次使用时间，以及R位和M位。

与时钟算法一样，每次缺页中断时，首先检查指针指向的页面。

* 如果R位是1，该页面在当前时钟滴答中就被使用过，那么该页面就不适合被淘汰。然后把该页面的R位置为0，指针指向下一个页面，并重复该算法。
* 如果R位是0，查看生存时间，如果生存时间大于τ并且该页面是干净的，它就不在工作集中，而且在磁盘上它有一个有效的副本。申请此页框，并把新页面放在其中。如果该页面已经被修改过，就不立即申请此页框，为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作，有可能存在一个旧的而且干净的页面可以立即使用。

原则上，所有的页面都有可能因为磁盘I/O在某个时钟周期被调度，为了降低磁盘阻塞，需要设置一个限制，即最大只允许写回n个页面。一旦达到该限制，就不允许调度新的写操作。

指针经过一圈返回它的起点，有两种情况：至少调用了一次写操作，没有调用过写操作

* 对于第一种情况，执行了写操作的页面已经不是干净的了，置换遇到的第一个干净页面，这个页面不一定是第一个被调度写操作的页面，因为硬盘驱动程序为了优化性能可能已经把写操作重排序了。
* 对于第二种情况，所有的页面都在工作集中，否则将至少执行了一个写操作。由于缺乏额外的信息，一个简单的方法就是随便置换一个干净的页面来使用，扫描中需要记录干净页面的位置。如果不存在干净页面，就选定当前页面并把它协会磁盘。

工作集时钟算法，即使用工作集算法的原理，但是将页面的扫描顺序按照时钟的形式组织起来。

**这样每次需要替换页面时，从指针指向的页面开始扫描，从而达到更加公平的状态。而且，按时钟组织的页面只是在内存里的页面，在内存外的页面不放在时钟圈里，从而提高实现效率。**

鉴于其时间和空间上的优势，工作集时钟算法被大多数商业操作系统所采纳。

#### 谈谈随机算法

另一个替换策略是**随机**，**在内存满的时候它随机选择一个页进行替换**。随机具有类似于 FIFO 的属性。实现起来很简单，但是它在挑选替换哪个页时不够智能。看看随机策略在上面例子上的引用流程。

![img](https://pic.taifua.com/Picture/website/ostep/c22/3.png)

当然，随机的表现完全取决于多幸运（或不幸）。在上面的例子中，随机比 FIFO 好一点，比最优的差一点。事实上，可以运行数千次的随机实验，求得一个平均的结果。下图显示了 10000 次试验后随机策略的平均命中率，每次试验都有不同的随机种子。正如所看到的，有些时候（仅仅 40% 的概率）随机和最优策略一样好，在上述例子中，命中内存的次数是 6 次。有时候情况会更糟糕，只有2次或更少。**随机策略取决于当时的运气**。

![img](https://pic.taifua.com/Picture/website/ostep/c22/4.png)

### Linux 虚拟内存

<https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247522087&idx=2&sn=fe8f4cd34d68e0a10658dee88bd337df&chksm=f98dd38dcefa5a9ba43a9d1ac96852532f53278915a6f6b9f5187b8c1c885c1e5848ebabbc86#rd>

#### Linux 进程虚拟内存空间

##### **32 位机器上进程虚拟内存空间分布**

在 32 位机器上，指针的寻址范围为 2^32，所能表达的虚拟内存空间为 4 GB。所以在 32 位机器上进程的虚拟内存地址范围为：0x0000 0000 - 0xFFFF FFFF。

其中用户态虚拟内存空间为 3 GB，虚拟内存地址范围为：0x0000 0000 - 0xC000 000 。

内核态虚拟内存空间为 1 GB，虚拟内存地址范围为：0xC000 000 - 0xFFFF FFFF。

![image.png](https://img-blog.csdnimg.cn/img_convert/ffb6e1727e2289f142f6a2a6291cd68c.png)

但是用户态虚拟内存空间中的代码段并不是从 0x0000 0000 地址开始的，而是从 0x0804 8000 地址开始。

0x0000 0000 到 0x0804 8000 这段虚拟内存地址是一段不可访问的保留区，因为在大多数操作系统中，数值比较小的地址通常被认为不是一个合法的地址，这块小地址是不允许访问的。比如在 C 语言中我们通常会将一些无效的指针设置为 NULL，指向这块不允许访问的地址。

保留区的上边就是代码段和数据段，它们是从程序的二进制文件中直接加载进内存中的，BSS 段中的数据也存在于二进制文件中，因为内核知道这些数据是没有初值的，所以在二进制文件中只会记录 BSS 段的大小，在加载进内存时会生成一段 0 填充的内存空间。

紧挨着 BSS 段的上边就是我们经常使用到的堆空间，从图中的红色箭头我们可以知道在堆空间中地址的增长方向是从低地址到高地址增长。

内核中使用 start_brk 标识堆的起始位置，brk 标识堆当前的结束位置。当堆申请新的内存空间时，只需要将 brk 指针增加对应的大小，回收地址时减少对应的大小即可。比如当我们通过 malloc 向内核申请很小的一块内存时（128K 之内），就是通过改变 brk 位置实现的。

堆空间的上边是一段待分配区域，用于扩展堆空间的使用。接下来就来到了文件映射与匿名映射区域。进程运行时所依赖的动态链接库中的代码段，数据段，BSS 段就加载在这里。还有我们调用 mmap 映射出来的一段虚拟内存空间也保存在这个区域。**注意：在文件映射与匿名映射区的地址增长方向是从高地址向低地址增长**。

接下来用户态虚拟内存空间的最后一块区域就是栈空间了，在这里会保存函数运行过程所需要的局部变量以及函数参数等函数调用信息。**栈空间中的地址增长方向是从高地址向低地址增长**。每次进程申请新的栈地址时，其地址值是在减少的。

在内核中使用 start_stack 标识栈的起始位置，RSP 寄存器中保存栈顶指针 stack pointer，RBP 寄存器中保存的是栈基地址。

在栈空间的下边也有一段待分配区域用于扩展栈空间，在栈空间的上边就是内核空间了，进程虽然可以看到这段内核空间地址，但是就是不能访问。这就好比我们在饭店里虽然可以看到厨房在哪里，但是厨房门上写着 “厨房重地，闲人免进” ，我们就是进不去。

![image.png](https://img-blog.csdnimg.cn/img_convert/fb9c102ac7a424b0aa1b8ba3a3bbbd54.png)

##### **64** **位机器上进程虚拟内存空间分布**

上小节中介绍的 32 位虚拟内存空间布局和本小节即将要介绍的 64 位虚拟内存空间布局都可以通过 `cat /proc/pid/maps` 或者 `pmap pid` 来查看某个进程的实际虚拟内存布局。

我们知道在 32 位机器上，指针的寻址范围为 2^32，所能表达的虚拟内存空间为 4 GB。

那么我们理所应当的会认为在 64 位机器上，指针的寻址范围为 2^64，所能表达的虚拟内存空间为 16 EB 。虚拟内存地址范围为：0x0000 0000 0000 0000 0000 - 0xFFFF FFFF FFFF FFFF 。

好家伙 !!! 16 EB 的内存空间，我都没见过这么大的磁盘，在现实情况中根本不会用到这么大范围的内存空间，

事实上在目前的 64 位系统下只使用了 48 位来描述虚拟内存空间，寻址范围为 2^48 ，所能表达的虚拟内存空间为 256TB。

其中低 128 T 表示用户态虚拟内存空间，虚拟内存地址范围为：0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000 。

高 128 T 表示内核态虚拟内存空间，虚拟内存地址范围为：0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 。

这样一来就在用户态虚拟内存空间与内核态虚拟内存空间之间形成了一段 0x0000 7FFF FFFF F000 - 0xFFFF 8000 0000 0000 的地址空洞，我们把这个空洞叫做 canonical address 空洞。

![image.png](https://img-blog.csdnimg.cn/img_convert/4956918c43e186d49df7b9802f080de8.png)

那么这个 canonical address 空洞是如何形成的呢？

我们都知道在 64 位机器上的指针寻址范围为 2^64，但是在实际使用中我们只使用了其中的低 48 位来表示虚拟内存地址，那么这多出的高 16 位就形成了这个地址空洞。

大家注意到在低 128T 的用户态地址空间：0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000 范围中，所以虚拟内存地址的高 16 位全部为 0 。

如果一个虚拟内存地址的高 16 位全部为 0 ，那么我们就可以直接判断出这是一个用户空间的虚拟内存地址。

同样的道理，在高 128T 的内核态虚拟内存空间：0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 范围中，所以虚拟内存地址的高 16 位全部为 1 。

也就是说内核态的虚拟内存地址的高 16 位全部为 1 ，如果一个试图访问内核的虚拟地址的高 16 位不全为 1 ，则可以快速判断这个访问是非法的。

这个高 16 位的空闲地址被称为 canonical 。如果虚拟内存地址中的高 16 位全部为 0 （表示用户空间虚拟内存地址）或者全部为 1 （表示内核空间虚拟内存地址），这种地址的形式我们叫做 canonical form，对应的地址我们称作 canonical address 。

那么处于 canonical address 空洞 ：0x0000 7FFF FFFF F000 - 0xFFFF 8000 0000 0000 范围内的地址的高 16 位 不全为 0 也不全为 1 。如果某个虚拟地址落在这段 canonical address 空洞区域中，那就是既不在用户空间，也不在内核空间，肯定是非法访问了。

未来我们也可以利用这块 canonical address 空洞，来扩展虚拟内存地址的范围，比如扩展到 56 位。

在我们理解了 canonical address 这个概念之后，我们再来看下 64 位 Linux 系统下的真实虚拟内存空间布局情况：

![image.png](https://img-blog.csdnimg.cn/img_convert/532e6cdf4899588f8b873b6435cba2d8.png)

从上图中我们可以看出 64 位系统中的虚拟内存布局和 32 位系统中的虚拟内存布局大体上是差不多的。主要不同的地方有三点：

1. 就是前边提到的由高 16 位空闲地址造成的 canonical address 空洞。在这段范围内的虚拟内存地址是不合法的，因为它的高 16 位既不全为 0 也不全为 1，不是一个 canonical address，所以称之为 canonical address 空洞。
2. 在代码段跟数据段的中间还有一段不可以读写的保护段，它的作用是防止程序在读写数据段的时候越界访问到代码段，这个保护段可以让越界访问行为直接崩溃，防止它继续往下运行。
3. 用户态虚拟内存空间与内核态虚拟内存空间分别占用 128T，其中低128T 分配给用户态虚拟内存空间，高 128T 分配给内核态虚拟内存空间。

#### Linux 进程虚拟内存空间管理

在上一小节中，我为大家介绍了 Linux 操作系统在 32 位机器上和 64 位机器上进程虚拟内存空间的布局分布，我们发现无论是在 32 位机器上还是在 64 位机器上，进程虚拟内存空间的核心区域分布的相对位置是不变的，它们都包含下图所示的这几个核心内存区域。

![image.png](https://img-blog.csdnimg.cn/img_convert/b1402bf81de260b86ce0cb4c19cd4330.png)

唯一不同的是这些核心内存区域在 32 位机器和 64 位机器上的绝对位置分布会有所不同。

那么在此基础之上，内核如何为进程管理这些虚拟内存区域呢？这将是本小节重点为大家介绍的内容~~

既然我们要介绍进程的虚拟内存空间管理，那就离不开进程在内核中的描述符 task_struct 结构。

```c
struct task_struct {
        // 进程id
     pid_t    pid;
        // 用于标识线程所属的进程 pid
     pid_t    tgid;
        // 进程打开的文件信息
        struct files_struct  *files;
        // 内存描述符表示进程虚拟地址空间
        struct mm_struct  *mm;

        .......... 省略 .......
}
```

在进程描述符 task_struct 结构中，有一个专门描述进程虚拟地址空间的内存描述符 mm_struct 结构，这个结构体中包含了前边几个小节中介绍的进程虚拟内存空间的全部信息。

每个进程都有唯一的 mm_struct 结构体，也就是前边提到的每个进程的虚拟地址空间都是独立，互不干扰的。

当我们调用 fork() 函数创建进程的时候，表示进程地址空间的 mm_struct 结构会随着进程描述符 task_struct 的创建而创建。

```c
long _do_fork(unsigned long clone_flags,
       unsigned long stack_start,
       unsigned long stack_size,
       int __user *parent_tidptr,
       int __user *child_tidptr,
       unsigned long tls)
{
        ......... 省略 ..........
 struct pid *pid;
 struct task_struct *p;

        ......... 省略 ..........
    // 为进程创建 task_struct 结构，用父进程的资源填充 task_struct 信息
 p = copy_process(clone_flags, stack_start, stack_size,
    child_tidptr, NULL, trace, tls, NUMA_NO_NODE);

         ......... 省略 ..........
}
```

随后会在 copy_process 函数中创建 task_struct 结构，并拷贝父进程的相关资源到新进程的 task_struct 结构里，其中就包括拷贝父进程的虚拟内存空间 mm_struct 结构。**这里可以看出子进程在新创建出来之后它的虚拟内存空间是和父进程的虚拟内存空间一模一样的，直接拷贝过来**。

```c
static __latent_entropy struct task_struct *copy_process(
     unsigned long clone_flags,
     unsigned long stack_start,
     unsigned long stack_size,
     int __user *child_tidptr,
     struct pid *pid,
     int trace,
     unsigned long tls,
     int node)
{

    struct task_struct *p;
    // 创建 task_struct 结构
    p = dup_task_struct(current, node);

        ....... 初始化子进程 ...........

        ....... 开始继承拷贝父进程资源  .......      
    // 继承父进程打开的文件描述符
 retval = copy_files(clone_flags, p);
    // 继承父进程所属的文件系统
 retval = copy_fs(clone_flags, p);
    // 继承父进程注册的信号以及信号处理函数
 retval = copy_sighand(clone_flags, p);
 retval = copy_signal(clone_flags, p);
    // 继承父进程的虚拟内存空间
 retval = copy_mm(clone_flags, p);
    // 继承父进程的 namespaces
 retval = copy_namespaces(clone_flags, p);
    // 继承父进程的 IO 信息
 retval = copy_io(clone_flags, p);

      ...........省略.........
    // 分配 CPU
    retval = sched_fork(clone_flags, p);
    // 分配 pid
    pid = alloc_pid(p->nsproxy->pid_ns_for_children);

.     ..........省略.........
}
```

这里我们重点关注 copy_mm 函数，正是在这里完成了子进程虚拟内存空间 mm_struct 结构的的创建以及初始化。

```c
static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
{
    // 子进程虚拟内存空间，父进程虚拟内存空间
 struct mm_struct *mm, *oldmm;
 int retval;

        ...... 省略 ......

 tsk->mm = NULL;
 tsk->active_mm = NULL;
    // 获取父进程虚拟内存空间
 oldmm = current->mm;
 if (!oldmm)
  return 0;

        ...... 省略 ......
    // 通过 vfork 或者 clone 系统调用创建出的子进程（线程）和父进程共享虚拟内存空间
 if (clone_flags & CLONE_VM) {
        // 增加父进程虚拟地址空间的引用计数
  mmget(oldmm);
        // 直接将父进程的虚拟内存空间赋值给子进程（线程）
        // 线程共享其所属进程的虚拟内存空间
  mm = oldmm;
  goto good_mm;
 }

 retval = -ENOMEM;
    // 如果是 fork 系统调用创建出的子进程，则将父进程的虚拟内存空间以及相关页表拷贝到子进程中的 mm_struct 结构中。
 mm = dup_mm(tsk);
 if (!mm)
  goto fail_nomem;

good_mm:
    // 将拷贝出来的父进程虚拟内存空间 mm_struct 赋值给子进程
 tsk->mm = mm;
 tsk->active_mm = mm;
 return 0;

        ...... 省略 ......
```

由于本小节中我们举的示例是通过 fork() 函数创建子进程的情形，所以这里大家先占时忽略 `if (clone_flags & CLONE_VM)` 这个条件判断逻辑，我们先跳过往后看~~

copy_mm 函数首先会将父进程的虚拟内存空间 current->mm 赋值给指针 oldmm。然后通过 dup_mm 函数将父进程的虚拟内存空间以及**相关页表**拷贝到子进程的 mm_struct 结构中。最后将拷贝出来的 mm_struct 赋值给子进程的 task_struct 结构。

> 通过 fork() 函数创建出的子进程，它的虚拟内存空间以及相关页表相当于父进程虚拟内存空间的一份拷贝，直接从父进程中拷贝到子进程中。

而当我们通过 vfork 或者 clone 系统调用创建出的子进程，首先会设置 CLONE_VM 标识，这样来到 copy_mm 函数中就会进入 `if (clone_flags & CLONE_VM)` 条件中，在这个分支中会将父进程的虚拟内存空间以及相关页表直接赋值给子进程。这样一来父进程和子进程的虚拟内存空间就变成共享的了。也就是说父子进程之间使用的虚拟内存空间是一样的，并不是一份拷贝。

子进程共享了父进程的虚拟内存空间，这样子进程就变成了我们熟悉的线程，**是否共享地址空间几乎是进程和线程之间的本质区别。Linux 内核并不区别对待它们，线程对于内核来说仅仅是一个共享特定资源的进程而已**。

内核线程和用户态线程的区别就是内核线程没有相关的内存描述符 mm_struct ，内核线程对应的 task_struct 结构中的 mm 域指向 Null，所以内核线程之间调度是不涉及地址空间切换的。

当一个内核线程被调度时，它会发现自己的虚拟地址空间为 Null，虽然它不会访问用户态的内存，但是它会访问内核内存，聪明的内核会将调度之前的上一个用户态进程的虚拟内存空间 mm_struct 直接赋值给内核线程，因为内核线程不会访问用户空间的内存，它仅仅只会访问内核空间的内存，所以直接复用上一个用户态进程的虚拟地址空间就可以避免为内核线程分配 mm_struct 和相关页表的开销，以及避免内核线程之间调度时地址空间的切换开销。

> 父进程与子进程的区别，进程与线程的区别，以及内核线程与用户态线程的区别其实都是围绕着这个 mm_struct 展开的。

现在我们知道了表示进程虚拟内存空间的 mm_struct 结构是如何被创建出来的相关背景，那么接下来我就带大家深入 mm_struct 结构内部，来看一下内核如何通过这么一个 mm_struct 结构体来管理进程的虚拟内存空间的。

##### 内核如何划分用户态和内核态虚拟内存空间

通过 《3. 进程虚拟内存空间》小节的介绍我们知道，进程的虚拟内存空间分为两个部分：一部分是用户态虚拟内存空间，另一部分是内核态虚拟内存空间。

![image.png](https://img-blog.csdnimg.cn/img_convert/b1402bf81de260b86ce0cb4c19cd4330.png)

那么用户态的地址空间和内核态的地址空间在内核中是如何被划分的呢？

这就用到了进程的内存描述符 mm_struct 结构体中的 task_size 变量，task_size 定义了用户态地址空间与内核态地址空间之间的分界线。

```c
struct mm_struct {
    unsigned long task_size; /* size of task vm space */
}
```

通过前边小节的内容介绍，我们知道在 32 位系统中用户态虚拟内存空间为 3 GB，虚拟内存地址范围为：0x0000 0000 - 0xC000 000 。

内核态虚拟内存空间为 1 GB，虚拟内存地址范围为：0xC000 000 - 0xFFFF FFFF。

![32位地址空间.png](https://img-blog.csdnimg.cn/img_convert/ffb6e1727e2289f142f6a2a6291cd68c.png)

32 位系统中用户地址空间和内核地址空间的分界线在 0xC000 000 地址处，那么自然进程的 mm_struct 结构中的 task_size 为 0xC000 000。

我们来看下内核在 `/arch/x86/include/asm/page_32_types.h` 文件中关于 TASK_SIZE 的定义。

```c
/*
 * User space process size: 3GB (default).
 */
#define TASK_SIZE  __PAGE_OFFSET
```

如下图所示：__PAGE_OFFSET 的值在 32 位系统下为 0xC000 000。

![/arch/arm/Kconfig.png](https://img-blog.csdnimg.cn/img_convert/445cb4fb8bfeff15d6350b278f370919.png)

而在 64 位系统中，只使用了其中的低 48 位来表示虚拟内存地址。其中用户态虚拟内存空间为低 128 T，虚拟内存地址范围为：0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000 。

内核态虚拟内存空间为高 128 T，虚拟内存地址范围为：0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 。

![64位地址空间.png](https://img-blog.csdnimg.cn/img_convert/532e6cdf4899588f8b873b6435cba2d8.png)

64 位系统中用户地址空间和内核地址空间的分界线在 0x0000 7FFF FFFF F000 地址处，那么自然进程的 mm_struct 结构中的 task_size 为 0x0000 7FFF FFFF F000 。

我们来看下内核在 `/arch/x86/include/asm/page_64_types.h` 文件中关于 TASK_SIZE 的定义。

```c
#define TASK_SIZE  (test_thread_flag(TIF_ADDR32) ? \
     IA32_PAGE_OFFSET : TASK_SIZE_MAX)

#define TASK_SIZE_MAX  task_size_max()

#define task_size_max()  ((_AC(1,UL) << __VIRTUAL_MASK_SHIFT) - PAGE_SIZE)

#define __VIRTUAL_MASK_SHIFT 47
```

我们来看下在 64 位系统中内核如何来计算 TASK_SIZE，在 task_size_max() 的计算逻辑中 1 左移 47 位得到的地址是 0x0000800000000000，然后减去一个 PAGE_SIZE （默认为 4K），就是 0x00007FFFFFFFF000，共 128T。所以在 64 位系统中的 TASK_SIZE 为 0x00007FFFFFFFF000 。

> 这里我们可以看出，64 位虚拟内存空间的布局是和物理内存页 page 的大小有关的，物理内存页 page 默认大小 PAGE_SIZE 为 4K。

PAGE_SIZE 定义在 `/arch/x86/include/asm/page_types.h`文件中：

```c
/* PAGE_SHIFT determines the page size */
#define PAGE_SHIFT  12
#define PAGE_SIZE  (_AC(1,UL) << PAGE_SHIFT)
```

而内核空间的起始地址是 0xFFFF 8000 0000 0000 。在 0x00007FFFFFFFF000 - 0xFFFF 8000 0000 0000 之间的内存区域就是我们在 《4.2 64 位机器上进程虚拟内存空间分布》小节中介绍的 canonical address 空洞。

##### 内核如何布局进程虚拟内存空间

在我们理解了内核是如何划分进程虚拟内存空间和内核虚拟内存空间之后，那么在 《3. 进程虚拟内存空间》小节中介绍的那些虚拟内存区域在内核中又是如何划分的呢？

接下来我就为大家介绍下内核是如何划分进程虚拟内存空间中的这些内存区域的，本小节的示例图中，我只保留了进程虚拟内存空间中的核心区域，方便大家理解。

![image.png](https://img-blog.csdnimg.cn/img_convert/8e6efc5f2c39a39959c337077359a824.png)

前边我们提到，内核中采用了一个叫做内存描述符的 mm_struct 结构体来表示进程虚拟内存空间的全部信息。在本小节中我就带大家到 mm_struct 结构体内部去寻找下相关的线索。

```c
struct mm_struct {
    unsigned long task_size;    /* size of task vm space */
    unsigned long start_code, end_code, start_data, end_data;
    unsigned long start_brk, brk, start_stack;
    unsigned long arg_start, arg_end, env_start, env_end;
    unsigned long mmap_base;  /* base of mmap area */
    unsigned long total_vm;    /* Total pages mapped */
    unsigned long locked_vm;  /* Pages that have PG_mlocked set */
    unsigned long pinned_vm;  /* Refcount permanently increased */
    unsigned long data_vm;    /* VM_WRITE & ~VM_SHARED & ~VM_STACK */
    unsigned long exec_vm;    /* VM_EXEC & ~VM_WRITE & ~VM_STACK */
    unsigned long stack_vm;    /* VM_STACK */

       ...... 省略 ........
}
```

内核中用 mm_struct 结构体中的上述属性来定义上图中虚拟内存空间里的不同内存区域。

start_code 和 end_code 定义代码段的起始和结束位置，程序编译后的二进制文件中的机器码被加载进内存之后就存放在这里。

start_data 和 end_data 定义数据段的起始和结束位置，二进制文件中存放的全局变量和静态变量被加载进内存中就存放在这里。

后面紧挨着的是 BSS 段，用于存放未被初始化的全局变量和静态变量，这些变量在加载进内存时会生成一段 0 填充的内存区域 （BSS 段）， BSS 段的大小是固定的，

下面就是 OS 堆了，在堆中内存地址的增长方向是由低地址向高地址增长， start_brk 定义堆的起始位置，brk 定义堆当前的结束位置。

> 我们使用 malloc 申请小块内存时（低于 128K），就是通过改变 brk 位置调整堆大小实现的。

接下来就是内存映射区，在内存映射区内存地址的增长方向是由高地址向低地址增长，mmap_base 定义内存映射区的起始地址。进程运行时所依赖的动态链接库中的代码段，数据段，BSS 段以及我们调用 mmap 映射出来的一段虚拟内存空间就保存在这个区域。

start_stack 是栈的起始位置在 RBP 寄存器中存储，栈的结束位置也就是栈顶指针 stack pointer 在 RSP 寄存器中存储。在栈中内存地址的增长方向也是由高地址向低地址增长。

arg_start 和 arg_end 是参数列表的位置， env_start 和 env_end 是环境变量的位置。它们都位于栈中的最高地址处。

![image.png](https://img-blog.csdnimg.cn/img_convert/2b2dbb2b6ea19871152a3bf6566df205.png)

在 mm_struct 结构体中除了上述用于划分虚拟内存区域的变量之外，还定义了一些虚拟内存与物理内存映射内容相关的统计变量，操作系统会把物理内存划分成一页一页的区域来进行管理，所以物理内存到虚拟内存之间的映射也是按照页为单位进行的。这部分内容我会在后续的文章中详细介绍，大家这里只需要有个概念就行。

mm_struct 结构体中的 total_vm 表示在进程虚拟内存空间中总共与物理内存映射的页的总数。

> 注意映射这个概念，它表示只是将虚拟内存与物理内存建立关联关系，并不代表真正的分配物理内存。

当内存吃紧的时候，有些页可以换出到硬盘上，而有些页因为比较重要，不能换出。locked_vm 就是被锁定不能换出的内存页总数，pinned_vm 表示既不能换出，也不能移动的内存页总数。

data_vm 表示数据段中映射的内存页数目，exec_vm 是代码段中存放可执行文件的内存页数目，stack_vm 是栈中所映射的内存页数目，这些变量均是表示进程虚拟内存空间中的虚拟内存使用情况。

现在关于内核如何对进程虚拟内存空间进行布局的内容我们已经清楚了，那么布局之后划分出的这些虚拟内存区域在内核中又是如何被管理的呢？我们接着往下看~~~

##### 内核如何管理虚拟内存区域

在上小节的介绍中，我们知道内核是通过一个 mm_struct 结构的内存描述符来表示进程的虚拟内存空间的，并通过 task_size 域来划分用户态虚拟内存空间和内核态虚拟内存空间。

![image.png](https://img-blog.csdnimg.cn/img_convert/b1402bf81de260b86ce0cb4c19cd4330.png)

而在划分出的这些虚拟内存空间中如上图所示，里边又包含了许多特定的虚拟内存区域，比如：代码段，数据段，堆，内存映射区，栈。那么这些虚拟内存区域在内核中又是如何表示的呢？

本小节中，我将为大家介绍一个新的结构体 vm_area_struct，正是这个结构体描述了这些虚拟内存区域 VMA（virtual memory area）。

```c
struct vm_area_struct {

 unsigned long vm_start;  /* Our start address within vm_mm. */
 unsigned long vm_end;  /* The first byte after our end address
        within vm_mm. */
 /*
  * Access permissions of this VMA.
  */
 pgprot_t vm_page_prot;
 unsigned long vm_flags; 

 struct anon_vma *anon_vma; /* Serialized by page_table_lock */
    struct file * vm_file;  /* File we map to (can be NULL). */
 unsigned long vm_pgoff;  /* Offset (within vm_file) in PAGE_SIZE
        units */ 
 void * vm_private_data;  /* was vm_pte (shared mem) */
 /* Function pointers to deal with this struct. */
 const struct vm_operations_struct *vm_ops;
}
```

每个 vm_area_struct 结构对应于虚拟内存空间中的唯一虚拟内存区域 VMA，vm_start 指向了这块虚拟内存区域的起始地址（最低地址），vm_start 本身包含在这块虚拟内存区域内。vm_end 指向了这块虚拟内存区域的结束地址（最高地址），而 vm_end 本身包含在这块虚拟内存区域之外，所以 vm_area_struct 结构描述的是 [vm_start，vm_end) 这样一段左闭右开的虚拟内存区域。

![image.png](https://img-blog.csdnimg.cn/img_convert/4956390184c51584798be1e5aaabedd1.png)

##### 定义虚拟内存区域的访问权限和行为规范定义虚拟内存区域的访问权限和行为规范

vm_page_prot 和 vm_flags 都是用来标记 vm_area_struct 结构表示的这块虚拟内存区域的访问权限和行为规范。

上边小节中我们也提到，内核会将整块物理内存划分为一页一页大小的区域，以页为单位来管理这些物理内存，每页大小默认 4K 。而虚拟内存最终也是要和物理内存一一映射起来的，所以在虚拟内存空间中也有虚拟页的概念与之对应，虚拟内存中的虚拟页映射到物理内存中的物理页。无论是在虚拟内存空间中还是在物理内存中，内核管理内存的最小单位都是页。

vm_page_prot 偏向于定义底层内存管理架构中页这一级别的访问控制权限，它可以直接应用在底层页表中，它是一个具体的概念。

> 页表用于管理虚拟内存到物理内存之间的映射关系，这部分内容我后续会详细讲解，这里大家有个初步的概念就行。

虚拟内存区域 VMA 由许多的虚拟页 (page) 组成，每个虚拟页需要经过页表的转换才能找到对应的物理页面。页表中关于内存页的访问权限就是由 vm_page_prot 决定的。

vm_flags 则偏向于定于整个虚拟内存区域的访问权限以及行为规范。描述的是虚拟内存区域中的整体信息，而不是虚拟内存区域中具体的某个独立页面。它是一个抽象的概念。可以通过 `vma->vm_page_prot = vm_get_page_prot(vma->vm_flags)` 实现到具体页面访问权限 vm_page_prot 的转换。

下面我列举一些常用到的 vm_flags 方便大家有一个直观的感受：

|   vm_flags   |        访问权限        |
| :----------: | :--------------------: |
|   VM_READ    |          可读          |
|   VM_WRITE   |          可写          |
|   VM_EXEC    |         可执行         |
|   VM_SHARD   |    可多进程之间共享    |
|    VM_IO     |  可映射至设备 IO 空间  |
| VM_RESERVED  |   内存区域不可被换出   |
| VM_SEQ_READ  | 内存区域可能被顺序访问 |
| VM_RAND_READ | 内存区域可能被随机访问 |

VM_READ，VM_WRITE，VM_EXEC 定义了虚拟内存区域是否可以被读取，写入，执行等权限。

比如代码段这块内存区域的权限是可读，可执行，但是不可写。数据段具有可读可写的权限但是不可执行。堆则具有可读可写，可执行的权限（Java 中的字节码存储在堆中，所以需要可执行权限），栈一般是可读可写的权限，一般很少有可执行权限。而文件映射与匿名映射区存放了共享链接库，所以也需要可执行的权限。

![image.png](https://img-blog.csdnimg.cn/img_convert/600ef23c454d9f3653ece44debaaf3a7.png)

VM_SHARD 用于指定这块虚拟内存区域映射的物理内存是否可以在多进程之间共享，以便完成进程间通讯。

> 设置这个值即为 mmap 的共享映射，不设置的话则为私有映射。这个等后面我们讲到 mmap 的相关实现时还会再次提起。

VM_IO 的设置表示这块虚拟内存区域可以映射至设备 IO 空间中。通常在设备驱动程序执行 mmap 进行 IO 空间映射时才会被设置。

VM_RESERVED 的设置表示在内存紧张的时候，这块虚拟内存区域非常重要，不能被换出到磁盘中。

VM_SEQ_READ 的设置用来暗示内核，应用程序对这块虚拟内存区域的读取是会采用顺序读的方式进行，内核会根据实际情况决定预读后续的内存页数，以便加快下次顺序访问速度。

VM_RAND_READ 的设置会暗示内核，应用程序会对这块虚拟内存区域进行随机读取，内核则会根据实际情况减少预读的内存页数甚至停止预读。

我们可以通过 posix_fadvise，madvise 系统调用来暗示内核是否对相关内存区域进行顺序读取或者随机读取。相关的详细内容，大家可以看下我上篇文章 [《从 Linux 内核角度探秘 JDK NIO 文件读写本质》 (opens new window)](https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247486623&idx=1&sn=0cafed9e89b60d678d8c88dc7689abda&chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&token=1276722624&lang=zh_CN#rd)中的第 9 小节文件页预读部分。

通过这一系列的介绍，我们可以看到 vm_flags 就是定义整个虚拟内存区域的访问权限以及行为规范，而内存区域中内存的最小单位为页（4K），虚拟内存区域中包含了很多这样的虚拟页，对于虚拟内存区域 VMA 设置的访问权限也会全部复制到区域中包含的内存页中。

##### 关联内存映射中的映射关系

接下来的三个属性 anon_vma，vm_file，vm_pgoff 分别和虚拟内存映射相关，虚拟内存区域可以映射到物理内存上，也可以映射到文件中，映射到物理内存上我们称之为匿名映射，映射到文件中我们称之为文件映射。

那么这个映射关系在内核中该如何表示呢？这就用到了 vm_area_struct 结构体中的上述三个属性。

![image.png](https://img-blog.csdnimg.cn/img_convert/020416146a97ca88b40ac9b5c0460375.png)

当我们调用 malloc 申请内存时，如果申请的是小块内存（低于 128K）则会使用 do_brk() 系统调用通过调整堆中的 brk 指针大小来增加或者回收堆内存。

如果申请的是比较大块的内存（超过 128K）时，则会调用 mmap 在上图虚拟内存空间中的文件映射与匿名映射区创建出一块 VMA 内存区域（这里是匿名映射）。这块匿名映射区域就用 struct anon_vma 结构表示。

当调用 mmap 进行文件映射时，vm_file 属性就用来关联被映射的文件。这样一来虚拟内存区域就与映射文件关联了起来。vm_pgoff 则表示映射进虚拟内存中的文件内容，在文件中的偏移。

> 当然在匿名映射中，vm_area_struct 结构中的 vm_file 就为 null，vm_pgoff 也就没有了意义。

vm_private_data 则用于存储 VMA 中的私有数据。具体的存储内容和内存映射的类型有关，我们暂不展开论述。

##### 针对虚拟内存区域的相关操作

struct vm_area_struct 结构中还有一个 vm_ops 用来指向针对虚拟内存区域 VMA 的相关操作的函数指针。

```c
struct vm_operations_struct {
 void (*open)(struct vm_area_struct * area);
 void (*close)(struct vm_area_struct * area);
    vm_fault_t (*fault)(struct vm_fault *vmf);
    vm_fault_t (*page_mkwrite)(struct vm_fault *vmf);

    ..... 省略 .......
}
```

* 当指定的虚拟内存区域被加入到进程虚拟内存空间中时，open 函数会被调用
* 当虚拟内存区域 VMA 从进程虚拟内存空间中被删除时，close 函数会被调用
* 当进程访问虚拟内存时，访问的页面不在物理内存中，可能是未分配物理内存也可能是被置换到磁盘中，这时就会产生缺页异常，fault 函数就会被调用。
* 当一个只读的页面将要变为可写时，page_mkwrite 函数会被调用。

struct vm_operations_struct 结构中定义的都是对虚拟内存区域 VMA 的相关操作函数指针。

内核中这种类似的用法其实有很多，在内核中每个特定领域的描述符都会定义相关的操作。比如在前边的文章 [《从 Linux 内核角度探秘 JDK NIO 文件读写本质》 (opens new window)](https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247486623&idx=1&sn=0cafed9e89b60d678d8c88dc7689abda&chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&token=1276722624&lang=zh_CN#rd)中我们介绍到内核中的文件描述符 struct file 中定义的 struct file_operations *f_op。里面定义了内核针对文件操作的函数指针，具体的实现根据不同的文件类型有所不同。

针对 Socket 文件类型，这里的 file_operations 指向的是 socket_file_ops。

![进程中管理文件列表结构.png](https://img-blog.csdnimg.cn/img_convert/962e5cee8366009b565796896f22ad77.png)

在 ext4 文件系统中管理的文件对应的 file_operations 指向 ext4_file_operations，专门用于操作 ext4 文件系统中的文件。还有针对 page cache 页高速缓存相关操作定义的 address_space_operations 。

![image.png](https://img-blog.csdnimg.cn/img_convert/aa5c53db83c9a49362dda5a006d2849b.png)

还有我们在 [《从 Linux 内核角度看 IO 模型的演变》 (opens new window)](https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247483737&idx=1&sn=7ef3afbb54289c6e839eed724bb8a9d6&chksm=ce77c71ef9004e08e3d164561e3a2708fc210c05408fa41f7fe338d8e85f39c1ad57519b614e&scene=21#wechat_redirect)一文中介绍到，socket 相关的操作接口定义在 inet_stream_ops 函数集合中，负责对上给用户提供接口。而 socket 与内核协议栈之间的操作接口定义在 struct sock 中的 sk_prot 指针上，这里指向 tcp_prot 协议操作函数集合。

![系统IO调用结构.png](https://img-blog.csdnimg.cn/img_convert/ce6e73b9fdee82cf39f364975aa14ad5.png)

对 socket 发起的系统 IO 调用时，在内核中首先会调用 socket 的文件结构 struct file 中的 file_operations 文件操作集合，然后调用 struct socket 中的 ops 指向的 inet_stream_opssocket 操作函数，最终调用到 struct sock 中 sk_prot 指针指向的 tcp_prot 内核协议栈操作函数接口集合。

##### 虚拟内存区域在内核中是如何被组织的

在上一小节中，我们介绍了内核中用来表示虚拟内存区域 VMA 的结构体 struct vm_area_struct ，并详细为大家剖析了 struct vm_area_struct 中的一些重要的关键属性。

现在我们已经熟悉了这些虚拟内存区域，那么接下来的问题就是在内核中这些虚拟内存区域是如何被组织的呢？

![image.png](https://img-blog.csdnimg.cn/img_convert/b1402bf81de260b86ce0cb4c19cd4330.png)

我们继续来到 struct vm_area_struct 结构中，来看一下与组织结构相关的一些属性：

```c
struct vm_area_struct {

 struct vm_area_struct *vm_next, *vm_prev;
 struct rb_node vm_rb;
    struct list_head anon_vma_chain; 
 struct mm_struct *vm_mm; /* The address space we belong to. */
 
    unsigned long vm_start;     /* Our start address within vm_mm. */
    unsigned long vm_end;       /* The first byte after our end address
                       within vm_mm. */
    /*
     * Access permissions of this VMA.
     */
    pgprot_t vm_page_prot;
    unsigned long vm_flags; 

    struct anon_vma *anon_vma;  /* Serialized by page_table_lock */
    struct file * vm_file;      /* File we map to (can be NULL). */
    unsigned long vm_pgoff;     /* Offset (within vm_file) in PAGE_SIZE
                       units */ 
    void * vm_private_data;     /* was vm_pte (shared mem) */
    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;
}
```

在内核中其实是通过一个 struct vm_area_struct 结构的双向链表将虚拟内存空间中的这些虚拟内存区域 VMA 串联起来的。

vm_area_struct 结构中的 vm_next ，vm_prev 指针分别指向 VMA 节点所在双向链表中的后继节点和前驱节点，内核中的这个 VMA 双向链表是有顺序的，所有 VMA 节点按照低地址到高地址的增长方向排序。

双向链表中的最后一个 VMA 节点的 vm_next 指针指向 NULL，双向链表的头指针存储在内存描述符 struct mm_struct 结构中的 mmap 中，正是这个 mmap 串联起了整个虚拟内存空间中的虚拟内存区域。

```c
struct mm_struct {
    struct vm_area_struct *mmap;  /* list of VMAs */
}
```

在每个虚拟内存区域 VMA 中又通过 struct vm_area_struct 中的 vm_mm 指针指向了所属的虚拟内存空间 mm_struct。

![image.png](https://img-blog.csdnimg.cn/img_convert/d1e65b91b67422c2cc08a04549c5f3ba.png)

我们可以通过 `cat /proc/pid/maps` 或者 `pmap pid` 查看进程的虚拟内存空间布局以及其中包含的所有内存区域。这两个命令背后的实现原理就是通过遍历内核中的这个 vm_area_struct 双向链表获取的。

内核中关于这些虚拟内存区域的操作除了遍历之外还有许多需要根据特定虚拟内存地址在虚拟内存空间中查找特定的虚拟内存区域。

尤其在进程虚拟内存空间中包含的内存区域 VMA 比较多的情况下，使用红黑树查找特定虚拟内存区域的时间复杂度是 O( logN ) ，可以显著减少查找所需的时间。

所以在内核中，同样的内存区域 vm_area_struct 会有两种组织形式，一种是双向链表用于高效的遍历，另一种就是红黑树用于高效的查找。

每个 VMA 区域都是红黑树中的一个节点，通过 struct vm_area_struct 结构中的 vm_rb 将自己连接到红黑树中。

而红黑树中的根节点存储在内存描述符 struct mm_struct 中的 mm_rb 中：

```c
struct mm_struct {
     struct rb_root mm_rb;
}
```

![image.png](https://img-blog.csdnimg.cn/img_convert/d945d22667c4ea56dbd2f19677306a91.png)

#### 程序编译后的二进制文件如何映射到虚拟内存空间中

经过前边这么多小节的内容介绍，现在我们已经熟悉了进程虚拟内存空间的布局，以及内核如何管理这些虚拟内存区域，并对进程的虚拟内存空间有了一个完整全面的认识。

现在我们再来回到最初的起点，进程的虚拟内存空间 mm_struct 以及这些虚拟内存区域 vm_area_struct 是如何被创建并初始化的呢？

![image.png](https://img-blog.csdnimg.cn/img_convert/2b2dbb2b6ea19871152a3bf6566df205.png)

在 《3. 进程虚拟内存空间》小节中，我们介绍进程的虚拟内存空间时提到，我们写的程序代码编译之后会生成一个 ELF 格式的二进制文件，这个二进制文件中包含了程序运行时所需要的元信息，比如程序的机器码，程序中的全局变量以及静态变量等。

这个 ELF 格式的二进制文件中的布局和我们前边讲的虚拟内存空间中的布局类似，也是一段一段的，每一段包含了不同的元数据。

> 磁盘文件中的段我们叫做 Section，内存中的段我们叫做 Segment，也就是内存区域。

磁盘文件中的这些 Section 会在进程运行之前加载到内存中并映射到内存中的 Segment。通常是多个 Section 映射到一个 Segment。

比如磁盘文件中的 .text，.rodata 等一些只读的 Section，会被映射到内存的一个只读可执行的 Segment 里（代码段）。而 .data，.bss 等一些可读写的 Section，则会被映射到内存的一个具有读写权限的 Segment 里（数据段，BSS 段）。

那么这些 ELF 格式的二进制文件中的 Section 是如何加载并映射进虚拟内存空间的呢？

内核中完成这个映射过程的函数是 load_elf_binary ，这个函数的作用很大，加载内核的是它，启动第一个用户态进程 init 的是它，fork 完了以后，调用 exec 运行一个二进制程序的也是它。当 exec 运行一个二进制程序的时候，除了解析 ELF 的格式之外，另外一个重要的事情就是建立上述提到的内存映射。

```c
static int load_elf_binary(struct linux_binprm *bprm)
{
      ...... 省略 ........
  // 设置虚拟内存空间中的内存映射区域起始地址 mmap_base
  setup_new_exec(bprm);

     ...... 省略 ........
  // 创建并初始化栈对应的 vm_area_struct 结构。
  // 设置 mm->start_stack 就是栈的起始地址也就是栈底，并将 mm->arg_start 是指向栈底的。
  retval = setup_arg_pages(bprm, randomize_stack_top(STACK_TOP),
         executable_stack);

     ...... 省略 ........
  // 将二进制文件中的代码部分映射到虚拟内存空间中
  error = elf_map(bprm->file, load_bias + vaddr, elf_ppnt,
        elf_prot, elf_flags, total_size);

     ...... 省略 ........
 // 创建并初始化堆对应的的 vm_area_struct 结构
 // 设置 current->mm->start_brk = current->mm->brk，设置堆的起始地址 start_brk，结束地址 brk。 起初两者相等表示堆是空的
  retval = set_brk(elf_bss, elf_brk, bss_prot);

     ...... 省略 ........
  // 将进程依赖的动态链接库 .so 文件映射到虚拟内存空间中的内存映射区域
  elf_entry = load_elf_interp(&loc->interp_elf_ex,
              interpreter,
              &interp_map_addr,
              load_bias, interp_elf_phdata);

     ...... 省略 ........
  // 初始化内存描述符 mm_struct
  current->mm->end_code = end_code;
  current->mm->start_code = start_code;
  current->mm->start_data = start_data;
  current->mm->end_data = end_data;
  current->mm->start_stack = bprm->p;

     ...... 省略 ........
}
```

* setup_new_exec 设置虚拟内存空间中的内存映射区域起始地址 mmap_base
* setup_arg_pages 创建并初始化栈对应的 vm_area_struct 结构。置 mm->start_stack 就是栈的起始地址也就是栈底，并将 mm->arg_start 是指向栈底的。
* elf_map 将 ELF 格式的二进制文件中.text ，.data，.bss 部分映射到虚拟内存空间中的代码段，数据段，BSS 段中。
* set_brk 创建并初始化堆对应的的 vm_area_struct 结构，设置 `current->mm->start_brk = current->mm->brk`，设置堆的起始地址 start_brk，结束地址 brk。 起初两者相等表示堆是空的。
* load_elf_interp 将进程依赖的动态链接库 .so 文件映射到虚拟内存空间中的内存映射区域
* 初始化内存描述符 mm_struct

#### 谈谈 Linux 内核虚拟内存空间

现在我们已经知道了进程虚拟内存空间在内核中的布局以及管理，那么内核态的虚拟内存空间又是什么样子的呢？本小节我就带大家来一层一层地拆开这个黑盒子。

之前在介绍进程虚拟内存空间的时候，我提到不同进程之间的虚拟内存空间是相互隔离的，彼此之间相互独立，相互感知不到其他进程的存在。使得进程以为自己拥有所有的内存资源。

![image.png](https://img-blog.csdnimg.cn/img_convert/fc1b281658bdf92edf7ef6421c85d2cc.png)

而内核态虚拟内存空间是所有进程共享的，不同进程进入内核态之后看到的虚拟内存空间全部是一样的。

什么意思呢？比如上图中的进程 a，进程 b，进程 c 分别在各自的用户态虚拟内存空间中访问虚拟地址 x 。由于进程之间的用户态虚拟内存空间是相互隔离相互独立的，虽然在进程a，进程b，进程c 访问的都是虚拟地址 x 但是看到的内容却是不一样的（背后可能映射到不同的物理内存中）。

但是当进程 a，进程 b，进程 c 进入到内核态之后情况就不一样了，由于内核虚拟内存空间是各个进程共享的，所以它们在内核空间中看到的内容全部是一样的，比如进程 a，进程 b，进程 c 在内核态都去访问虚拟地址 y。这时它们看到的内容就是一样的了。

> 这里我和大家澄清一个经常被误解的概念：由于内核会涉及到物理内存的管理，所以很多人会想当然地认为只要进入了内核态就开始使用物理地址了，这就大错特错了，千万不要这样理解，进程进入内核态之后使用的仍然是虚拟内存地址，只不过在内核中使用的虚拟内存地址被限制在了内核态虚拟内存空间范围中，这也是本小节我要为大家介绍的主题。

在清楚了这个基本概念之后，下面我分别从 32 位体系 和 64 位体系下为大家介绍内核态虚拟内存空间的布局。

##### 32 位体系内核虚拟内存空间布局

在前边《5.1 内核如何划分用户态和内核态虚拟内存空间》小节中我们提到，内核在 `/arch/x86/include/asm/page_32_types.h` 文件中通过 TASK_SIZE 将进程虚拟内存空间和内核虚拟内存空间分割开来。

```c
/*
 * User space process size: 3GB (default).
 */
#define TASK_SIZE       __PAGE_OFFSET
```

> __PAGE_OFFSET 的值在 32 位系统下为 0xC000 000

![image.png](https://img-blog.csdnimg.cn/img_convert/82d9552d0a8e772f45058d300dcf893a.png)

在 32 位体系结构下进程用户态虚拟内存空间为 3 GB，虚拟内存地址范围为：0x0000 0000 - 0xC000 000 。内核态虚拟内存空间为 1 GB，虚拟内存地址范围为：0xC000 000 - 0xFFFF FFFF。

本小节我们主要关注 0xC000 000 - 0xFFFF FFFF 这段虚拟内存地址区域也就是内核虚拟内存空间的布局情况。

##### 直接映射区

在总共大小 1G 的内核虚拟内存空间中，位于最前边有一块 896M 大小的区域，我们称之为直接映射区或者线性映射区，地址范围为 3G -- 3G + 896m 。

之所以这块 896M 大小的区域称为直接映射区或者线性映射区，是因为这块连续的虚拟内存地址会映射到 0 - 896M 这块连续的物理内存上。

也就是说 3G -- 3G + 896m 这块 896M 大小的虚拟内存会直接映射到 0 - 896M 这块 896M 大小的物理内存上，**这块区域中的虚拟内存地址直接减去 0xC000 0000 (3G) 就得到了物理内存地址**。所以我们称这块区域为直接映射区。

> 为了方便为大家解释，我们假设现在机器上的物理内存为 4G 大小

![image.png](https://img-blog.csdnimg.cn/img_convert/1d91dd17f2390c91f6693b9e686ccc13.png)

> 虽然这块区域中的虚拟地址是直接映射到物理地址上，但是内核在访问这段区域的时候还是走的虚拟内存地址，内核也会为这块空间建立映射页表。关于页表的概念我后续会为大家详细讲解，这里大家只需要简单理解为页表保存了虚拟地址到物理地址的映射关系即可。

**大家这里只需要记得内核态虚拟内存空间的前 896M 区域是直接映射到物理内存中的前 896M 区域中的，直接映射区中的映射关系是一比一映射。映射关系是固定的不会改变**。

明白了这个关系之后，我们接下来就看一下这块直接映射区域在物理内存中究竟存的是什么内容~~~

在这段 896M 大小的物理内存中，前 1M 已经在系统启动的时候被系统占用，1M 之后的物理内存存放的是内核代码段，数据段，BSS 段（这些信息起初存放在 ELF格式的二进制文件中，在系统启动的时候被加载进内存）。

> 我们可以通过 `cat /proc/iomem` 命令查看具体物理内存布局情况。

当我们使用 fork 系统调用创建进程的时候，内核会创建一系列进程相关的描述符，比如之前提到的进程的核心数据结构 task_struct，进程的内存空间描述符 mm_struct，以及虚拟内存区域描述符 vm_area_struct 等。

这些进程相关的数据结构也会存放在物理内存前 896M 的这段区域中，当然也会被直接映射至内核态虚拟内存空间中的 3G -- 3G + 896m 这段直接映射区域中。

![image.png](https://img-blog.csdnimg.cn/img_convert/d945d22667c4ea56dbd2f19677306a91.png)

当进程被创建完毕之后，在内核运行的过程中，会涉及内核栈的分配，内核会为每个进程分配一个固定大小的内核栈（一般是两个页大小，依赖具体的体系结构），每个进程的整个调用链必须放在自己的内核栈中，内核栈也是分配在直接映射区。

与进程用户空间中的栈不同的是，内核栈容量小而且是固定的，用户空间中的栈容量大而且可以动态扩展。内核栈的溢出危害非常巨大，它会直接悄无声息的覆盖相邻内存区域中的数据，破坏数据。

通过以上内容的介绍我们了解到内核虚拟内存空间最前边的这段 896M 大小的直接映射区如何与物理内存进行映射关联，并且清楚了直接映射区主要用来存放哪些内容。

写到这里，我觉得还是有必要再次从功能划分的角度为大家介绍下这块直接映射区域。

我们都知道内核对物理内存的管理都是以页为最小单位来管理的，每页默认 4K 大小，理想状况下任何种类的数据页都可以存放在任何页框中，没有什么限制。比如：存放内核数据，用户数据，缓冲磁盘数据等。

但是实际的计算机体系结构受到硬件方面的限制制约，间接导致限制了页框的使用方式。

比如在 X86 体系结构下，ISA 总线的 DMA （直接内存存取）控制器，只能对内存的前16M 进行寻址，这就导致了 ISA 设备不能在整个 32 位地址空间中执行 DMA，只能使用物理内存的前 16M 进行 DMA 操作。

因此直接映射区的前 16M 专门让内核用来为 DMA 分配内存，这块 16M 大小的内存区域我们称之为 ZONE_DMA。

> 用于 DMA 的内存必须从 ZONE_DMA 区域中分配。

而直接映射区中剩下的部分也就是从 16M 到 896M（不包含 896M）这段区域，我们称之为 ZONE_NORMAL。从字面意义上我们可以了解到，这块区域包含的就是正常的页框（使用没有任何限制）。

ZONE_NORMAL 由于也是属于直接映射区的一部分，对应的物理内存 16M 到 896M 这段区域也是被直接映射至内核态虚拟内存空间中的 3G + 16M 到 3G + 896M 这段虚拟内存上。

![image.png](https://img-blog.csdnimg.cn/img_convert/1cf5fc48692826d8446638bbc5dd0e0b.png)

> 注意这里的 ZONE_DMA 和 ZONE_NORMAL 是内核针对物理内存区域的划分。

现在物理内存中的前 896M 的区域也就是前边介绍的 ZONE_DMA 和 ZONE_NORMAL 区域到内核虚拟内存空间的映射我就为大家介绍完了，它们都是采用直接映射的方式，一比一就行映射。

##### ZONE_HIGHMEM 高端内存

而物理内存 896M 以上的区域被内核划分为 ZONE_HIGHMEM 区域，我们称之为高端内存。

本例中我们的物理内存假设为 4G，高端内存区域为 4G - 896M = 3200M，那么这块 3200M 大小的 ZONE_HIGHMEM 区域该如何映射到内核虚拟内存空间中呢？

**由于内核虚拟内存空间中的前 896M 虚拟内存已经被直接映射区所占用，而在 32 体系结构下内核虚拟内存空间总共也就 1G 的大小，这样一来内核剩余可用的虚拟内存空间就变为了 1G - 896M = 128M。**

**显然物理内存中 3200M 大小的 ZONE_HIGHMEM 区域无法继续通过直接映射的方式映射到这 128M 大小的虚拟内存空间中。**

**这样一来物理内存中的 ZONE_HIGHMEM 区域就只能采用动态映射的方式映射到 128M 大小的内核虚拟内存空间中，也就是说只能动态的一部分一部分的分批映射，先映射正在使用的这部分，使用完毕解除映射，接着映射其他部分。**（也就是为什么要动态映射区）

知道了 ZONE_HIGHMEM 区域的映射原理，我们接着往下看这 128M 大小的内核虚拟内存空间究竟是如何布局的？

![image.png](https://img-blog.csdnimg.cn/img_convert/42ac90617218ba33ce7fdd16bdaa0c5c.png)

内核虚拟内存空间中的 3G + 896M 这块地址在内核中定义为 high_memory，high_memory 往上有一段 8M 大小的内存空洞。空洞范围为：high_memory 到 VMALLOC_START 。

VMALLOC_START 定义在内核源码 `/arch/x86/include/asm/pgtable_32_areas.h` 文件中：

```c
#define VMALLOC_OFFSET (8 * 1024 * 1024)

#define VMALLOC_START ((unsigned long)high_memory + VMALLOC_OFFSET)
```

##### vmalloc 动态映射区

接下来 VMALLOC_START 到 VMALLOC_END 之间的这块区域成为动态映射区。采用动态映射的方式映射物理内存中的高端内存。

```c
#ifdef CONFIG_HIGHMEM
# define VMALLOC_END (PKMAP_BASE - 2 * PAGE_SIZE)
#else
# define VMALLOC_END (LDT_BASE_ADDR - 2 * PAGE_SIZE)
#endif
```

![image.png](https://img-blog.csdnimg.cn/img_convert/0bd4766b19d043bb4aebdd06bdf8e67c.png)

和用户态进程使用 malloc 申请内存一样，在这块动态映射区内核是使用 vmalloc 进行内存分配。由于之前介绍的动态映射的原因，vmalloc 分配的内存在虚拟内存上是连续的，但是物理内存是不连续的。通过页表来建立物理内存与虚拟内存之间的映射关系，从而可以将不连续的物理内存映射到连续的虚拟内存上。

> 由于 vmalloc 获得的物理内存页是不连续的，因此它只能将这些物理内存页一个一个地进行映射，在性能开销上会比直接映射大得多。

关于 vmalloc 分配内存的相关实现原理，我会在后面的文章中为大家讲解，这里大家只需要明白它在哪块虚拟内存区域中活动即可。

##### 永久映射区

![image.png](https://img-blog.csdnimg.cn/img_convert/8638152cae4ee85e8467128cb3ffec76.png)

而在 PKMAP_BASE 到 FIXADDR_START 之间的这段空间称为永久映射区。在内核的这段虚拟地址空间中允许建立与物理高端内存的长期映射关系。比如内核通过 alloc_pages() 函数在物理内存的高端内存中申请获取到的物理内存页，这些物理内存页可以通过调用 kmap 映射到永久映射区中。

> LAST_PKMAP 表示永久映射区可以映射的页数限制。

```c
#define PKMAP_BASE  \
 ((LDT_BASE_ADDR - PAGE_SIZE) & PMD_MASK)

#define LAST_PKMAP 1024
```

##### 固定映射区

![image.png](https://img-blog.csdnimg.cn/img_convert/0ea1b8d1d2e31c36001df7652f418e5e.png)

内核虚拟内存空间中的下一个区域为固定映射区，区域范围为：FIXADDR_START 到 FIXADDR_TOP。

FIXADDR_START 和 FIXADDR_TOP 定义在内核源码 `/arch/x86/include/asm/fixmap.h` 文件中：

```c
#define FIXADDR_START  (FIXADDR_TOP - FIXADDR_SIZE)

extern unsigned long __FIXADDR_TOP; // 0xFFFF F000
#define FIXADDR_TOP ((unsigned long)__FIXADDR_TOP)
```

在内核虚拟内存空间的直接映射区中，直接映射区中的虚拟内存地址与物理内存前 896M 的空间的映射关系都是预设好的，一比一映射。

在固定映射区中的虚拟内存地址可以自由映射到物理内存的高端地址上，但是与动态映射区以及永久映射区不同的是，在固定映射区中虚拟地址是固定的，而被映射的物理地址是可以改变的。也就是说，有些虚拟地址在编译的时候就固定下来了，是在内核启动过程中被确定的，而这些虚拟地址对应的物理地址不是固定的。采用固定虚拟地址的好处是它相当于一个指针常量（常量的值在编译时确定），指向物理地址，如果虚拟地址不固定，则相当于一个指针变量。

那为什么会有固定映射这个概念呢 ? 比如：在内核的启动过程中，有些模块需要使用虚拟内存并映射到指定的物理地址上，而且这些模块也没有办法等待完整的内存管理模块初始化之后再进行地址映射。因此，内核固定分配了一些虚拟地址，这些地址有固定的用途，使用该地址的模块在初始化的时候，将这些固定分配的虚拟地址映射到指定的物理地址上去。

##### 临时映射区

在内核虚拟内存空间中的最后一块区域为临时映射区，那么这块临时映射区是用来干什么的呢？

![image.png](https://img-blog.csdnimg.cn/img_convert/0d19dc439390c46612e31ee973f83145.png)

我在之前文章 [《从 Linux 内核角度探秘 JDK NIO 文件读写本质》 (opens new window)](https://mp.weixin.qq.com/s?__biz=Mzg2MzU3Mjc3Ng==&mid=2247486623&idx=1&sn=0cafed9e89b60d678d8c88dc7689abda&chksm=ce77cad8f90043ceaaca732aaaa7cb692c1d23eeb6c07de84f0ad690ab92d758945807239cee&token=1276722624&lang=zh_CN#rd)的 “ 12.3 iov_iter_copy_from_user_atomic ” 小节中介绍在 Buffered IO 模式下进行文件写入的时候，在下图中的第四步，内核会调用 iov_iter_copy_from_user_atomic 函数将用户空间缓冲区 DirectByteBuffer 中的待写入数据拷贝到 page cache 中。

![image.png](https://img-blog.csdnimg.cn/img_convert/fcb8b59a4b73a823603b6cbd4f720b5d.png)

但是内核又不能直接进行拷贝，因为此时从 page cache 中取出的缓存页 page 是物理地址，而在内核中是不能够直接操作物理地址的，只能操作虚拟地址。

那怎么办呢？所以就需要使用 kmap_atomic 将缓存页临时映射到内核空间的一段虚拟地址上，这段虚拟地址就位于内核虚拟内存空间中的临时映射区上，然后将用户空间缓存区 DirectByteBuffer 中的待写入数据通过这段映射的虚拟地址拷贝到 page cache 中的相应缓存页中。这时文件的写入操作就已经完成了。

由于是临时映射，所以在拷贝完成之后，调用 kunmap_atomic 将这段映射再解除掉。

```c
size_t iov_iter_copy_from_user_atomic(struct page *page,
    struct iov_iter *i, unsigned long offset, size_t bytes)
{
  // 将缓存页临时映射到内核虚拟地址空间的临时映射区中
  char *kaddr = kmap_atomic(page), 
  *p = kaddr + offset;
  // 将用户缓存区 DirectByteBuffer 中的待写入数据拷贝到文件缓存页中
  iterate_all_kinds(i, bytes, v,
    copyin((p += v.iov_len) - v.iov_len, v.iov_base, v.iov_len),
    memcpy_from_page((p += v.bv_len) - v.bv_len, v.bv_page,
         v.bv_offset, v.bv_len),
    memcpy((p += v.iov_len) - v.iov_len, v.iov_base, v.iov_len)
  )
  // 解除内核虚拟地址空间与缓存页之间的临时映射，这里映射只是为了临时拷贝数据用
  kunmap_atomic(kaddr);
  return bytes;
}
```

##### 32位体系结构下 Linux 虚拟内存空间整体布局

到现在为止，整个内核虚拟内存空间在 32 位体系下的布局，我就为大家详细介绍完毕了，我们再次结合前边《4.1 32 位机器上进程虚拟内存空间分布》小节中介绍的进程虚拟内存空间和本小节介绍的内核虚拟内存空间来整体回顾下 32 位体系结构 Linux 的整个虚拟内存空间的布局：

![image.png](https://img-blog.csdnimg.cn/img_convert/68763fe509b7adf5987a3ce96c9d12ee.png)

##### 64 位体系内核虚拟内存空间布局

内核虚拟内存空间在 32 位体系下只有 1G 大小，实在太小了，因此需要精细化的管理，于是按照功能分类划分除了很多内核虚拟内存区域，这样就显得非常复杂。

到了 64 位体系下，内核虚拟内存空间的布局和管理就变得容易多了，因为进程虚拟内存空间和内核虚拟内存空间各自占用 128T 的虚拟内存，实在是太大了，我们可以在这里边随意翱翔，随意挥霍。

因此在 64 位体系下的内核虚拟内存空间与物理内存的映射就变得非常简单，由于虚拟内存空间足够的大，即便是内核要访问全部的物理内存，直接映射就可以了，不在需要用到《7.1.2 ZONE_HIGHMEM 高端内存》小节中介绍的高端内存那种动态映射方式。

在前边《5.1 内核如何划分用户态和内核态虚拟内存空间》小节中我们提到，内核在 `/arch/x86/include/asm/page_64_types.h` 文件中通过 TASK_SIZE 将进程虚拟内存空间和内核虚拟内存空间分割开来。

```c
#define TASK_SIZE  (test_thread_flag(TIF_ADDR32) ? \
     IA32_PAGE_OFFSET : TASK_SIZE_MAX)

#define TASK_SIZE_MAX  task_size_max()

#define task_size_max()  ((_AC(1,UL) << __VIRTUAL_MASK_SHIFT) - PAGE_SIZE)

#define __VIRTUAL_MASK_SHIFT 47
```

> 64 位系统中的 TASK_SIZE 为 0x00007FFFFFFFF000

![64位地址空间.png](https://img-blog.csdnimg.cn/img_convert/532e6cdf4899588f8b873b6435cba2d8.png)

在 64 位系统中，只使用了其中的低 48 位来表示虚拟内存地址。其中用户态虚拟内存空间为低 128 T，虚拟内存地址范围为：0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000 。

内核态虚拟内存空间为高 128 T，虚拟内存地址范围为：0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 。

本小节我们主要关注 0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 这段内核虚拟内存空间的布局情况。

![image.png](https://img-blog.csdnimg.cn/img_convert/e1f2e689c2754b2af540c6d0b6ab327f.png)

64 位内核虚拟内存空间从 0xFFFF 8000 0000 0000 开始到 0xFFFF 8800 0000 0000 这段地址空间是一个 8T 大小的内存空洞区域。

紧着着 8T 大小的内存空洞下一个区域就是 64T 大小的直接映射区。这个区域中的虚拟内存地址减去 PAGE_OFFSET 就直接得到了物理内存地址。

PAGE_OFFSET 变量定义在 `/arch/x86/include/asm/page_64_types.h` 文件中：

```c
#define __PAGE_OFFSET_BASE      _AC(0xffff880000000000, UL)
#define __PAGE_OFFSET           __PAGE_OFFSET_BASE
```

从图中 VMALLOC_START 到 VMALLOC_END 的这段区域是 32T 大小的 vmalloc 映射区，这里类似用户空间中的堆，内核在这里使用 vmalloc 系统调用申请内存。

VMALLOC_START 和 VMALLOC_END 变量定义在 `/arch/x86/include/asm/pgtable_64_types.h` 文件中：

```c
#define __VMALLOC_BASE_L4 0xffffc90000000000UL

#define VMEMMAP_START  __VMEMMAP_BASE_L4

#define VMALLOC_END  (VMALLOC_START + (VMALLOC_SIZE_TB << 40) - 1)
```

从 VMEMMAP_START 开始是 1T 大小的虚拟内存映射区，用于存放物理页面的描述符 struct page 结构用来表示物理内存页。

VMEMMAP_START 变量定义在 `/arch/x86/include/asm/pgtable_64_types.h` 文件中：

```c
#define __VMEMMAP_BASE_L4 0xffffea0000000000UL

# define VMEMMAP_START  __VMEMMAP_BASE_L4
```

从 __START_KERNEL_map 开始是大小为 512M 的区域用于存放内核代码段、全局变量、BSS 等。这里对应到物理内存开始的位置，减去__START_KERNEL_map 就能得到物理内存的地址。这里和直接映射区有点像，但是不矛盾，因为直接映射区之前有 8T 的空洞区域，早就过了内核代码在物理内存中加载的位置。

__START_KERNEL_map 变量定义在 `/arch/x86/include/asm/page_64_types.h` 文件中：

```c
#define __START_KERNEL_map  _AC(0xffffffff80000000, UL)
```

##### 64位体系结构下 Linux 虚拟内存空间整体布局

到现在为止，整个内核虚拟内存空间在 64 位体系下的布局我就为大家详细介绍完毕了，我们再次结合前边《4.2 64 位机器上进程虚拟内存空间分布》小节介绍的进程虚拟内存空间和本小节介绍的内核虚拟内存空间来整体回顾下 64 位体系结构 Linux 的整个虚拟内存空间的布局：

![image.png](https://img-blog.csdnimg.cn/img_convert/84eb41fc42b790865eb8bc15d3a2892a.png)

#### 谈谈物理内存地址

聊完了虚拟内存，我们接着聊一下物理内存，我们平时所称的内存也叫随机访问存储器（ random-access memory ）也叫 RAM 。而 RAM 分为两类：

* 一类是静态 RAM（ `SRAM` ），这类 SRAM 用于 CPU 高速缓存 L1Cache，L2Cache，L3Cache。其特点是访问速度快，访问速度为 1 - 30 个时钟周期，但是容量小，造价高。

![CPU缓存结构.png](https://img-blog.csdnimg.cn/img_convert/560cee15346204f216f8b144a6c2a18c.png)

* 另一类则是动态 RAM ( `DRAM` )，这类 DRAM 用于我们常说的主存上，其特点的是访问速度慢（相对高速缓存），访问速度为 50 - 200 个时钟周期，但是容量大，造价便宜些（相对高速缓存）。

内存由一个一个的存储器模块（memory module）组成，它们插在主板的扩展槽上。常见的存储器模块通常以 64 位为单位（ 8 个字节）传输数据到存储控制器上或者从存储控制器传出数据。

![image.png](https://img-blog.csdnimg.cn/img_convert/647cd97d53cb7d2a67067c90996fa4e8.png)

如图所示内存条上黑色的元器件就是存储器模块（memory module）。多个存储器模块连接到存储控制器上，就聚合成了主存。

![内存结构.png](https://img-blog.csdnimg.cn/img_convert/9651fbd7b5a3b397f7a81acfcd49723c.png)

而 DRAM 芯片就包装在存储器模块中，每个存储器模块中包含 8 个 DRAM 芯片，依次编号为 0 - 7 。

![存储器模块.png](https://img-blog.csdnimg.cn/img_convert/a2112f84eed5dc53dd760cf6a5fdb538.png)

而每一个 DRAM 芯片的存储结构是一个二维矩阵，二维矩阵中存储的元素我们称为超单元（supercell），每个 supercell 大小为一个字节（8 bit）。每个 supercell 都由一个坐标地址（i，j）。

> i 表示二维矩阵中的行地址，在计算机中行地址称为 RAS (row access strobe，行访问选通脉冲)。 j 表示二维矩阵中的列地址，在计算机中列地址称为 CAS (column access strobe,列访问选通脉冲)。

下图中的 supercell 的 RAS = 2，CAS = 2。

![DRAM结构.png](https://img-blog.csdnimg.cn/img_convert/27a06c2b3f831d24e57c40b839bfc9e2.png)

DRAM 芯片中的信息通过引脚流入流出 DRAM 芯片。每个引脚携带 1 bit的信号。

图中 DRAM 芯片包含了两个地址引脚( `addr` )，因为我们要通过 RAS，CAS 来定位要获取的 supercell 。还有 8 个数据引脚（`data`），因为 DRAM 芯片的 IO 单位为一个字节（8 bit），所以需要 8 个 data 引脚从 DRAM 芯片传入传出数据。

> 注意这里只是为了解释地址引脚和数据引脚的概念，实际硬件中的引脚数量是不一定的。

##### DRAM 芯片的访问

我们现在就以读取上图中坐标地址为（2，2）的 supercell 为例，来说明访问 DRAM 芯片的过程。

![DRAM芯片访问.png](https://img-blog.csdnimg.cn/img_convert/fefc8d348414d2cd0ec09fdfa20daf9c.png)

1. 首先存储控制器将行地址 RAS = 2 通过地址引脚发送给 DRAM 芯片。
2. DRAM 芯片根据 RAS = 2 将二维矩阵中的第二行的全部内容拷贝到内部行缓冲区中。
3. 接下来存储控制器会通过地址引脚发送 CAS = 2 到 DRAM 芯片中。
4. DRAM芯片从内部行缓冲区中根据 CAS = 2 拷贝出第二列的 supercell 并通过数据引脚发送给存储控制器。

> DRAM 芯片的 IO 单位为一个 supercell ，也就是一个字节(8 bit)。

##### CPU 如何读写主存

前边我们介绍了内存的物理结构，以及如何访问内存中的 DRAM 芯片获取 supercell 中存储的数据（一个字节）。本小节我们来介绍下 CPU 是如何访问内存的：

![CPU与内存之间的总线结构.png](https://img-blog.csdnimg.cn/img_convert/efa862811f305ab0aa15c0422d8933e8.png)

CPU 与内存之间的数据交互是通过总线（bus）完成的，而数据在总线上的传送是通过一系列的步骤完成的，这些步骤称为总线事务（bus transaction）。

其中数据从内存传送到 CPU 称之为读事务（read transaction），数据从 CPU 传送到内存称之为写事务（write transaction）。

总线上传输的信号包括：地址信号，数据信号，控制信号。其中控制总线上传输的控制信号可以同步事务，并能够标识出当前正在被执行的事务信息：

* 当前这个事务是到内存的？还是到磁盘的？或者是到其他 IO 设备的？
* 这个事务是读还是写？
* 总线上传输的地址信号（物理内存地址），还是数据信号（数据）？。

> **这里大家需要注意总线上传输的地址均为物理内存地址**。比如：在 MESI 缓存一致性协议中当 CPU core0 修改字段 a 的值时，其他 CPU 核心会在总线上嗅探字段 a 的**物理内存地址**，如果嗅探到总线上出现字段 a 的**物理内存地址**，说明有人在修改字段 a，这样其他 CPU 核心就会失效字段 a 所在的 cache line 。

如上图所示，其中系统总线是连接 CPU 与 IO bridge 的，存储总线是来连接 IO bridge 和主存的。

IO bridge 负责将系统总线上的电子信号转换成存储总线上的电子信号。IO bridge 也会将系统总线和存储总线连接到IO总线（磁盘等IO设备）上。这里我们看到 IO bridge 其实起的作用就是转换不同总线上的电子信号。

##### CPU 从内存读取数据过程

假设 CPU 现在需要将物理内存地址为 A 的内容加载到寄存器中进行运算。

> 大家需要注意的是 CPU 只会访问虚拟内存，在操作总线之前，需要把虚拟内存地址转换为物理内存地址，总线上传输的都是物理内存地址，这里省略了虚拟内存地址到物理内存地址的转换过程，这部分内容我会在后续文章的相关章节详细为大家讲解，这里我们聚焦如果通过物理内存地址读取内存数据。

![CPU读取内存.png](https://img-blog.csdnimg.cn/img_convert/b4c3dc16dbfab2682d46772b787ae962.png)

首先 CPU 芯片中的总线接口会在总线上发起读事务（read transaction）。 该读事务分为以下步骤进行：

1. CPU 将物理内存地址 A 放到系统总线上。随后 IO bridge 将信号传递到存储总线上。
2. 主存感受到存储总线上的地址信号并通过存储控制器将存储总线上的物理内存地址 A 读取出来。
3. 存储控制器通过物理内存地址 A 定位到具体的存储器模块，从 DRAM 芯片中取出物理内存地址 A 对应的数据 X。
4. 存储控制器将读取到的数据 X 放到存储总线上，随后 IO bridge 将存储总线上的数据信号转换为系统总线上的数据信号，然后继续沿着系统总线传递。
5. CPU 芯片感受到系统总线上的数据信号，将数据从系统总线上读取出来并拷贝到寄存器中。

以上就是 CPU 读取内存数据到寄存器中的完整过程。

但是其中还涉及到一个重要的过程，这里我们还是需要摊开来介绍一下，那就是存储控制器如何通过物理内存地址 A 从主存中读取出对应的数据 X 的？

接下来我们结合前边介绍的内存结构以及从 DRAM 芯片读取数据的过程，来总体介绍下如何从主存中读取数据。

##### 如何根据物理内存地址从主存中读取数据

前边介绍到，当主存中的存储控制器感受到了存储总线上的地址信号时，会将内存地址从存储总线上读取出来。

随后会通过内存地址定位到具体的存储器模块。还记得内存结构中的存储器模块吗 ？

![内存结构.png](https://img-blog.csdnimg.cn/img_convert/b8c4e85c0bff05f7b26a42c246eec222.png)

而每个存储器模块中包含了 8 个 DRAM 芯片，编号从 0 - 7 。

![存储器模块.png](https://img-blog.csdnimg.cn/img_convert/1033fbb5b8e2d30c0271b2ad10ead27e.png)

存储控制器会将**物理内存地址**转换为 DRAM 芯片中 supercell 在二维矩阵中的坐标地址(RAS，CAS)。并将这个坐标地址发送给对应的存储器模块。随后存储器模块会将 RAS 和 CAS 广播到存储器模块中的所有 DRAM 芯片。依次通过 (RAS，CAS) 从 DRAM0 到 DRAM7 读取到相应的 supercell 。

![DRAM芯片访问.png](https://img-blog.csdnimg.cn/img_convert/9b841647ee906862636d257ce7064487.png)

我们知道一个 supercell 存储了一个字节（ 8 bit ） 数据，这里我们从 DRAM0 到 DRAM7 依次读取到了 8 个 supercell 也就是 8 个字节，然后将这 8 个字节返回给存储控制器，由存储控制器将数据放到存储总线上。

**CPU 总是以 word size 为单位从内存中读取数据，在 64 位处理器中的 word size 为 8 个字节。64 位的内存每次只能吞吐 8 个字节。**

> CPU 每次会向内存读写一个 cache line 大小的数据（ 64 个字节），但是内存一次只能吞吐 8 个字节。

所以在物理内存地址对应的存储器模块中，DRAM0 芯片存储第一个低位字节（ supercell ），DRAM1 芯片存储第二个字节，......依次类推 DRAM7 芯片存储最后一个高位字节。

![读取存储器模块数据.png](https://img-blog.csdnimg.cn/img_convert/78f3571fcb65ba401737e27d1fde89b9.png)

由于存储器模块中这种由 8 个 DRAM 芯片组成的物理存储结构的限制，内存读取数据只能是按照物理内存地址，8 个字节 8 个字节地顺序读取数据。所以说内存一次读取和写入的单位是 8 个字节。

![内存IO单位.png](https://img-blog.csdnimg.cn/img_convert/92c51229fbf868919e06d4426cada701.png)

而且在程序员眼里连续的物理内存地址实际上在物理上是不连续的。因为这连续的 8 个字节其实是存储于不同的 DRAM 芯片上的。每个 DRAM 芯片存储一个字节（supercell）

##### CPU 向内存写入数据过程

我们现在假设 CPU 要将寄存器中的数据 X 写到物理内存地址 A 中。同样的道理，CPU 芯片中的总线接口会向总线发起写事务（write transaction）。写事务步骤如下：

1. CPU 将要写入的物理内存地址 A 放入系统总线上。
2. 通过 IO bridge 的信号转换，将物理内存地址 A 传递到存储总线上。
3. 存储控制器感受到存储总线上的地址信号，将物理内存地址 A 从存储总线上读取出来，并等待数据的到达。
4. CPU 将寄存器中的数据拷贝到系统总线上，通过 IO bridge 的信号转换，将数据传递到存储总线上。
5. 存储控制器感受到存储总线上的数据信号，将数据从存储总线上读取出来。
6. 存储控制器通过内存地址 A 定位到具体的存储器模块，最后将数据写入存储器模块中的 8 个 DRAM 芯片中。

#### 源码视角

<https://blog.csdn.net/FF_programming/article/details/120963212>

##### 1、task_struct

每个进程在内核中都有一个进程控制块(PCB)来维护进程相关的信息，Linux内核的进程控制块是task_struct[结构体](https://so.csdn.net/so/search?q=结构体&spm=1001.2101.3001.7020)。

* 位置：<include\linux\sched.h> - 593行
* 部分代码如下：

```c
struct task_struct
{
    /*...*/
 struct mm_struct  *mm;
 struct mm_struct  *active_mm;

 /* Per-thread vma caching: */
 struct vmacache   vmacache;
    /*...*/
}

```

* `*mm`
 mm为mm_struct类型的指针，指向mm_struct结构，对于普通的用户进程来说mm字段指向他的虚拟地址空间的用户空间部分，对于内核线程来说这部分为NULL。
* `*active_mm`
 对于匿名进程，也可以理解为内核线程，它的mm字段为NULL，表示没有内存地址空间，可也并不是真正的没有，这是因为所有进程关于内核的映射都是一样的，内核线程可以使用任意进程的地址空间。
  **内核schedule在进程上下文切换的时候，会根据task->mm判断即将调度的进程是用户进程还是内核线程。**
  由于内核线程之前可能是任何用户层进程在执行，故用户空间部分的内容本质上是随机的，内核线程决不能修改其内容，故将mm设置为NULL。所以对于内核线程来说task_struct->mm == NULL，而task_struct->active_mm为某个进程的mm。
  如果切换出去的是用户进程，内核将原来进程的mm存放在新内核线程的active_mm中，因为某些时候内核必须知道用户空间当前包含了什么。
  而当内核线程离开的时候，会把借用的地址空间将会返还给原来的进程，并且清除这一字段。
* `vmcacahe`
 vmacache结构体定义在<include\linux\mm_types_task.h>的34行，如下：

```c
#define VMACACHE_BITS 2
#define VMACACHE_SIZE (1U << VMACACHE_BITS)

struct vmacache {
  u64 seqnum;
  struct vm_area_struct *vmas[VMACACHE_SIZE];
};

```

可以看到它是一个vm_area_struct类型的数组指针，表示指向几段vma。
这是由于为了提高vma的查找速度，由传统的链表式改为了红黑树管理，然而某些进程地址空间中的vma数量众多，而查找vma又是内核中非常频繁的操作，所以为了进一步加快查找速度，内核采取了一种缓存方式，就是把最近访问的几个vma保存起来。
VMACACHE_SIZE为左移2位的一个无符号整形数字，这里感觉大概是保存了4个最近访问的vma。

##### **2、mm_struct**

每一个进程都会有唯一的mm_struct结构体

* 位置：<include\linux\mm_types.h> - 340行
* 部分代码如下：

```c
struct mm_struct
{
    /*...*/
    struct vm_area_struct *mmap;  /* list of VMAs */
 struct rb_root mm_rb;
 u64 vmacache_seqnum;                /* per-thread vmacache */
    unsigned long mmap_base; /*映射基地址*/
 unsigned long mmap_legacy_base; /*不是很明白这里*/
    unsigned long task_size; /*该进程能够vma使用空间大小*/
 unsigned long highest_vm_end; /*该进程能够使用的vma结束地址*/
 pgd_t * pgd;
    atomic_t mm_users;
    atomic_t mm_count;
    int map_count;   /* vma的总个数 */
    unsigned long total_vm;    /* 映射的总页面数*/
    /*...*/
    unsigned long start_code, end_code, start_data, end_data;
 unsigned long start_brk, brk, start_stack;
 unsigned long arg_start, arg_end, env_start, env_end;
    /*...*/

```

* mmap
 该进程内已经使用的进程虚拟空间vm_are_struct结构，以双链表形式存储该指针指向vma链表的头节点。
* mm_rb
 红黑树组织形式，用于快速查找。
  rb_boot结构体定义在<include\linux\rbtree.h>的43行

```c
struct rb_root {
  struct rb_node *rb_node;
};
```

rb_node结构体定义在<include\linux\rbtree.h>的36行

```c
struct rb_node {
  unsigned long  __rb_parent_color;
  struct rb_node *rb_right;
  struct rb_node *rb_left;
  } __attribute__((aligned(sizeof(long))));
```

可以看到该数据结构包含了父节点颜色、左子树指针、右子树指针等字段

* vmacache_seqnum
 vma的缓存策略所使用的字段，表示每个进程都有的几个缓存vma，对应task_struct->vmacache->seqnum。
* *pgd
 **该进程页目录表，把新进程mm_struct的PGD字段填充到CR3中就完成了页表的切换。**
* mm_users、mm_count
 为了支持mm与active_mm，在这里设置了两个计数器，mm_users主要用来记录共用此命名空间的线程数量，mm_count则主要记录对此mm_struct结构体的引用情况。
  也就是说mm_users表示有多少真正使用地址空间的进程，当copy_mm函数在创建进程的时候，遇到CLONE_VM字段的话就再到需要让父子进程共享同一个地址空间，这时会把mm_users加1。而mm_count则表示有多少内核线程引用了这个地址空间。
  当mm_users为0时就会释放mm_count，当mm_count为0时结构体mm_struct将会被释放。

##### **3、vm_area_struct**

内核每次为用户空间中分配一个空间使用时，都会生成一个vm_area_struct结构用于记录跟踪分配情况，一个vm_area_struct就代表一段虚拟内存空间。

位置：<include\linux\mm_types.h> - 264行
全部代码如下：

```c
struct vm_area_struct {
 unsigned long vm_start; //虚存区起始
 unsigned long vm_end;   //虚存区结束
 struct vm_area_struct *vm_next, *vm_prev;   //前后指针
 struct rb_node vm_rb;   //红黑树中的位置
 unsigned long rb_subtree_gap;
 struct mm_struct *vm_mm;    //所属的 mm_struct
 pgprot_t vm_page_prot;      
 unsigned long vm_flags;     //标志位
 struct {
  struct rb_node rb;
  unsigned long rb_subtree_last;
 } shared; 
 struct list_head anon_vma_chain;
 struct anon_vma *anon_vma;
 const struct vm_operations_struct *vm_ops;  //vma对应的实际操作
 unsigned long vm_pgoff;     //文件映射偏移量
 struct file * vm_file;      //映射的文件
 void * vm_private_data;     //私有数据
 atomic_long_t swap_readahead_info;
#ifndef CONFIG_MMU
 struct vm_region *vm_region; /* NOMMU mapping region */
#endif
#ifdef CONFIG_NUMA
 struct mempolicy *vm_policy; /* NUMA policy for the VMA */
#endif
 struct vm_userfaultfd_ctx vm_userfaultfd_ctx;
} __randomize_layout;

```

***vm_ops**
**vm_operations_struct**结构体定义在<include\linux\mm.h>的393行

```c
struct vm_operations_struct {
  void (*open)(struct vm_area_struct * area);
  void (*close)(struct vm_area_struct * area);
  int (*split)(struct vm_area_struct * area, unsigned long addr);
  int (*mremap)(struct vm_area_struct * area);
  vm_fault_t (*fault)(struct vm_fault *vmf);
  vm_fault_t (*huge_fault)(struct vm_fault *vmf,
    enum page_entry_size pe_size);
  void (*map_pages)(struct vm_fault *vmf,
    pgoff_t start_pgoff, pgoff_t end_pgoff);
  unsigned long (*pagesize)(struct vm_area_struct * area);

  /* notification that a previously read-only page is about to become
   * writable, if an error is returned it will cause a SIGBUS */
  vm_fault_t (*page_mkwrite)(struct vm_fault *vmf);

  /* same as page_mkwrite when using VM_PFNMAP|VM_MIXEDMAP */
  vm_fault_t (*pfn_mkwrite)(struct vm_fault *vmf);

  /* called by access_process_vm when get_user_pages() fails, typically
   * for use by special VMAs that can switch between memory and hardware
   */
  int (*access)(struct vm_area_struct *vma, unsigned long addr,
         void *buf, int len, int write);

  /* Called by the /proc/PID/maps code to ask the vma whether it
   * has a special name.  Returning non-NULL will also cause this
   * vma to be dumped unconditionally. */
  const char *(*name)(struct vm_area_struct *vma);

  #ifdef CONFIG_NUMA
  /*
   * set_policy() op must add a reference to any non-NULL @new mempolicy
   * to hold the policy upon return.  Caller should pass NULL @new to
   * remove a policy and fall back to surrounding context--i.e. do not
   * install a MPOL_DEFAULT policy, nor the task or system default
   * mempolicy.
   */
  int (*set_policy)(struct vm_area_struct *vma, struct mempolicy *new);

  /*
   * get_policy() op must add reference [mpol_get()] to any policy at
   * (vma,addr) marked as MPOL_SHARED.  The shared policy infrastructure
   * in mm/mempolicy.c will do this automatically.
   * get_policy() must NOT add a ref if the policy at (vma,addr) is not
   * marked as MPOL_SHARED. vma policies are protected by the mmap_sem.
   * If no [shared/vma] mempolicy exists at the addr, get_policy() op
   * must return NULL--i.e., do not "fallback" to task or system default
   * policy.
   */
  struct mempolicy *(*get_policy)(struct vm_area_struct *vma,
      unsigned long addr);
  #endif
  /*
   * Called by vm_normal_page() for special PTEs to find the
   * page for @addr.  This is useful if the default behavior
   * (using pte_page()) would not find the correct page.
   */
  struct page *(*find_special_page)(struct vm_area_struct *vma,
        unsigned long addr);
  };


```

vm_operations结构中包含的是函数指针，其中open为虚存区的打开，close用于虚存区的关闭，另外还有split、mremap、acess等操作。

shared
对于具有地址空间和后备存储的区域，链接到地址空间的i_mmap间隔树。

rb_subtree_gap
该vma子树最大可用内存间隔（以字节为单位），具体为与vma和vma->vm_prev之间，或子vma和它的vma->vm_prev之间的内存间隙，有助于找到大小合适的空闲区域。

vm_flags
描述该区域的一段标志，包括其读写属性等，采用bit位方式，状态标志位定义在<include\linux\mm.h>文件173行中：

```c
  #define VM_NONE  0x00000000  //无标志

  #define VM_READ  0x00000001 //可读
  #define VM_WRITE 0x00000002  //可写
  #define VM_EXEC  0x00000004  //可操作
  #define VM_SHARED 0x00000008  //允许被多个线程访问

  /* mprotect() hardcodes VM_MAYREAD >> 4 == VM_READ, and so for r/w/x bits. */
  #define VM_MAYREAD 0x00000010 //允许设置可读
  #define VM_MAYWRITE 0x00000020 //允许设置可写  
  #define VM_MAYEXEC 0x00000040 //允许设置可操作
  #define VM_MAYSHARE 0x00000080 //允许设置可共享

  #define VM_GROWSDOWN 0x00000100 //向低地址增长
  #define VM_UFFD_MISSING 0x00000200 
  #define VM_PFNMAP 0x00000400 
  #define VM_DENYWRITE 0x00000800 //不允许写入
  #define VM_UFFD_WP 0x00001000 
  #define VM_LOCKED 0x00002000 //VMA被锁定，不会被交换到交换分区
  #define VM_IO           0x00004000 //该VMA用于IO 映射

  #define VM_SEQ_READ 0x0000800 //应用程序会顺序读该VMA的内容
  #define VM_RAND_READ 0x00010000 //应用程序会随机读取该VMA内存
  #define VM_DONTCOPY 0x00020000 //fork时不会复制该VMA
  #define VM_DONTEXPAND 0x00040000 
  #define VM_LOCKONFAULT 0x00080000 //当处于page fault时锁定该VMA 对应的物理页
  #define VM_ACCOUNT 0x00100000 
  #define VM_NORESERVE 0x00200000 //不做保留
  #define VM_HUGETLB 0x00400000 //huge TLB page对应的VM
  #define VM_SYNC  0x00800000 //page fault时同步映射
  #define VM_ARCH_1 0x01000000 
  #define VM_WIPEONFORK 0x02000000 //不会从父进程相应的VMA中复制页表到子进程的VMA中
  #define VM_DONTDUMP 0x04000000 //VMA不会被包含到core dump中

  #ifdef CONFIG_MEM_SOFT_DIRTY
  # define VM_SOFTDIRTY 0x08000000 
  #else
  # define VM_SOFTDIRTY 0
  #endif

  #define VM_MIXEDMAP 0x10000000 
  #define VM_HUGEPAGE 0x20000000 
  #define VM_NOHUGEPAGE 0x40000000 
  #define VM_MERGEABLE 0x80000000 

```

* **vm_page_prot**
 vm_flags代表VMA的状态位，但是相应的状态位最后要转化成实际内存的下发到硬件状态位，而pgprot则是代表实际物理页状态位。

##### **4、关系图**![在这里插入图片描述](https://img-blog.csdnimg.cn/703ddd089fd643f481d7d41c2a91531e.jpg?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBARkZfcHJvZ3JhbW1pbmc=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

CSAPP 虚拟内存章节看一下

linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/img_convert/33f6c2014042fc8356990f33df47a22f.png)

#### 谈谈 mmap 内存映射

##### 什么是mmap？

mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203181050391.png" alt="img" style="float: left;" />

##### mmap的过程—原理

1. 进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域
2. 调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系
3. 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝

##### mmap和常规文件操作的区别

常规文件的操作如下：

1. 进程发起读文件请求。
2. 内核查找文件描述符，定位到内核已打开的文件信息，找到文件的inode。
3. 查看文件页是否在缓存中，如果存在则直接返回这片页面
4. 如果不存在，缺页中断，需要定位到该文件的磁盘地址处，将数据从磁盘复制到页缓存中，然后发起页面读写过程，将页缓存中的数据发送给用户

常规文件需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。

而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。

##### 匿名映射
