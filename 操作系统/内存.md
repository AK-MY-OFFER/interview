# 内存

## 问题

### 虚拟内存机制

* 为什么要虚拟内存，有什么用？
* 如何实现虚拟内存？
  * 硬件支持
  * 软件支持
* Linux 进程的内存分布长什么样？



### malloc 和 free

* malloc() 如何分配内存？

* malloc() 分配的是物理内存吗？

* malloc(1) 会分配多大内存？

* malloc() 为什么不全部使用 mmap 来分配内存？

* mmap 实现原理？

* malloc() 为什么不全部使用 brk 来分配内存？

* malloc() 如果没有成功，可能什么原因，计算机会做什么？

* malloc() 是线程安全的吗 ?是可重入的吗？

* free() 释放内存，会归还给操作系统吗？

* free() 函数只传入一个内存地址，为什么会知道要释放多大的内存？

	

### 连续存储管理

* 静态分区分配是什么？有什么优缺点？
* 动态分区分配是什么？有什么优缺点？
* 什么是内部碎片？什么是外部碎片？各自有什么解决方法？



* 首次适应算法？
* 最佳适应算法？
* 最差适应算法？
* 邻近适应算法？



* Buddy 伙伴算法
* Slab 算法？

### 非连续存储管理

* 谈谈内存分段？
	* 什么是内存分段
	* 分段机制下，虚拟地址和物理地址是如何映射的？
	* 分段的优点
	* 分段的缺点及解决方案
* 谈谈内存分页？
	* 什么是内存分页
	* 分页机制下，虚拟地址和物理地址是如何映射的？
	* 分页的优点
	* 分页的缺点及解决方案
* 谈谈段页式内存管理
	* 什么是内存分页
	* 分页机制下，虚拟地址和物理地址是如何映射的？
	* 分页的优点
	* 分页的缺点及解决方案



## 回答

### 虚拟内存机制

#### 为什么要虚拟内存，有什么用？

单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。

另外，**单片机的 CPU 是直接操作内存的「物理地址」**。

![img](https://img-blog.csdnimg.cn/019f1f0d2d30469cbda2b8fe2cf5e622.png)

在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。

> 操作系统是如何解决这个问题呢？

这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。

我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「**虚拟地址**」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。

![进程的中间层](https://img-blog.csdnimg.cn/img_convert/298fb68e3da94d767b02f2ed81ebf2c4.png)

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

- 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
- 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：

![img](https://img-blog.csdnimg.cn/72ab76ba697e470b8ceb14d5fc5688d9.png)

**虚拟内存的作用**

- 第一，虚拟内存可以使得进程的运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。



### malloc 和 free

#### malloc() 如何分配内存？

实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。

malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。

- 方式一：通过 brk() 系统调用从堆分配内存
- 方式二：通过 mmap() 系统调用在文件映射区域分配内存；

方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/brk%E7%94%B3%E8%AF%B7.png)

方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/mmap%E7%94%B3%E8%AF%B7.png)

> 什么场景下 malloc() 会通过 brk() 分配内存？又是什么场景下通过 mmap() 分配内存？

malloc() 源码里默认定义了一个阈值：

- 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；
- 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；

注意，不同的 glibc 版本定义的阈值也是不同的。



man 手册

> 通常，malloc () 从堆中分配内存，并调整使用sbrk(2)根据需要设置堆的大小。当分配
> 大于MMAP_THRESHOLD字节的内存块时，glibc malloc () 实现使用mmap(2)将内存分配为私有匿名映射。  MMAP_THRESHOLD默认为 128 kB ，但可以使用mallopt(3)进行调整。在 Linux 4.7 之前，使用 mmap(2)执行的分配不受 RLIMIT_DATA资源限制的影响；自 Linux 4.7 起，此限制也适用于使用 mmap(2) 执行的分配。



#### malloc() 分配的是物理内存吗？

不是的，**malloc() 分配的是虚拟内存**。

如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的，这样就不会占用物理内存了。

只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发缺页中断，然后操作系统会建立虚拟内存和物理内存之间的映射关系。



#### malloc(1) 会分配多大内存？

malloc() 在分配内存的时候，并不是老老实实按用户预期申请的字节数来分配内存空间大小，而是**会预分配更大的空间作为内存池**。

具体会预分配多大的空间，跟 malloc 使用的内存管理器有关系，我们就以 malloc 默认的内存管理器（Ptmalloc2）来分析。

接下里，我们做个实验，用下面这个代码，通过 malloc 申请 1 字节的内存时，看看操作系统实际分配了多大的内存空间。

```c
#include <stdio.h>
#include <malloc.h>

int main() {
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());
  
  //申请1字节的内存
  void *addr = malloc(1);
  printf("此1字节的内存起始地址：%x\n", addr);
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());
 
  //将程序阻塞，当输入任意字符时才往下执行
  getchar();

  //释放内存
  free(addr);
  printf("释放了1字节的内存，但heap堆并不会释放\n");
  
  getchar();
  return 0;
}
```

执行代码（**先提前说明，我使用的 glibc 库的版本是 2.17**）：

![图片](https://img-blog.csdnimg.cn/img_convert/080ee187c8c92db45092b6688774e8da.png)

我们可以通过 /proc//maps 文件查看进程的内存分布情况。我在 maps 文件通过此 1 字节的内存起始地址过滤出了内存地址的范围。

```shell
[root@xiaolin ~]# cat /proc/3191/maps | grep d730
00d73000-00d94000 rw-p 00000000 00:00 0                                  [heap]
```

这个例子分配的内存小于 128 KB，所以是通过 brk() 系统调用向堆空间申请的内存，因此可以看到最右边有 [heap] 的标识。

可以看到，堆空间的内存地址范围是 00d73000-00d94000，这个范围大小是 132KB，也就说明了 **malloc(1) 实际上预分配 132K 字节的内存**。

可能有的同学注意到了，程序里打印的内存起始地址是 `d73010`，而 maps 文件显示堆内存空间的起始地址是 `d73000`，为什么会多出来 `0x10` （16字节）呢？这个问题，我们先放着，后面会说。



#### malloc() 为什么不全部使用 mmap 来分配内存？

因为向操作系统申请内存，是要通过系统调用的，执行系统调用是要进入内核态的，然后在回到用户态，运行态的切换会耗费不少时间。

所以，申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用。

另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。

也就是说，**频繁通过 mmap 分配的内存话，不仅每次都会发生运行态的切换，还会发生缺页中断（在第一次访问虚拟地址后），这样会导致 CPU 消耗较大**。

为了改进这两个问题，malloc 通过 brk() 系统调用在堆空间申请内存的时候，由于堆空间是连续的，所以直接预分配更大的内存来作为内存池，当内存释放的时候，就缓存在内存池中。

**等下次在申请内存的时候，就直接从内存池取出对应的内存块就行了，而且可能这个内存块的虚拟地址与物理地址的映射关系还存在，这样不仅减少了系统调用的次数，也减少了缺页中断的次数，这将大大降低 CPU 的消耗**。



#### mmap 实现原理？



#### malloc() 为什么不全部使用 brk 来分配内存？

前面我们提到通过 brk 从堆空间分配的内存，并不会归还给操作系统，那么我们那考虑这样一个场景。

如果我们连续申请了 10k，20k，30k 这三片内存，如果 10k 和 20k 这两片释放了，变为了空闲内存空间，如果下次申请的内存小于 30k，那么就可以重用这个空闲内存空间。

![图片](https://img-blog.csdnimg.cn/img_convert/75edee0cb75450e7987a8a482b975bda.png)

但是如果下次申请的内存大于 30k，没有可用的空闲内存空间，必须向 OS 申请，实际使用内存继续增大。

因此，随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片，导致“内存泄露”。而这种“泄露”现象使用 valgrind 是无法检测出来的。

所以，malloc 实现中，充分考虑了 brk 和 mmap 行为上的差异及优缺点，默认分配大块内存 (128KB) 才使用 mmap 分配内存空间。



#### malloc() 如果没有成功，可能什么原因，计算机会做什么？

*  内存不足。 
* 在前面的程序中出现了内存的越界访问，导致malloc()分配函数所涉及的一些信息被破坏。下次再使用malloc()函数申请内存就会失败，返回空指针NULL(0)。

查看方式：

1、内存不足，使用free命令查看当前还有多少内存，看是否合理，之前是否有内存泄漏等。

2、按照流程查看malloc失败前的几次malloc、memcpy或字符串拷贝等，查看是否有内存越界。



man 手册

>  默认情况下，Linux 遵循乐观的内存分配策略。这意味着当malloc () 返回非 NULL 时，不能保证内存确实可用。如果 发现系统内存不足，OOM 杀手将杀死一个或多个进程。更多信息请参见proc(5)中/proc/sys/vm/overcommit_memory和 /proc/sys/vm/oom_adj的描述，以及 Linux 内核源文件 Documentation/vm/overcommit-accounting.rst。



#### malloc() 是线程安全的吗 ?是可重入的吗？

**线程安全**

man 手册

> 为了避免多线程应用程序中的损坏，内部使用互斥锁来保护这些函数使用的内存管理数据结构。在线程同时分配和释放内存的多线程应用程序中，可能存在对这些互斥体的争用。为了在多线程应用程序中可伸缩地处理内存分配，如果检测到互斥争用，glibc 会创建
> 额外的内存分配区域。每个 arena 都是由系统内部分配的大内存区域（使用brk(2)或mmap(2)），并且使用自己的互斥锁进行管理。



https://blog.csdn.net/qq_40334837/article/details/96423711

**malloc 可重入吗？**

在man手册中，与系统调用有关的函数都会说明该函数是否线程安全，所以这也是我们写代码需要关注的，而线程安全与函数是否可重入有很大关系，**函数可重入一定是线程安全的，线程安全不一定是可重入函数，比如maloc使用递归锁实现了线程安全，但它是不可重入函数**，所以不可重入函数可以通过内核锁实现线程安全（锁是系统调用，所以工作在内核态，也叫内核锁），还有很多函数也是这样实现线程安全的



**信号**

1、基本概念

软中断信号（signal，又简称为信号）用来**通知进程发生了异步事件**。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。注意，信号只是用来通知某进程发生了什么事件，并不给该进程传递任何数据。

收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类：

* 第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。
* 第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。
* 第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。



**内核对信号的基本处理方法**

**内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理**，比如线程中系统调用malloc申请内存，所以从用户态进入了内核态，现在信号发生，这时操作系统会从内核态跳转到用户态执行signal函数（signal函数本身是应用层的一行代码需要被运行，属于用户态，当执行到绑定的函数时，函数内部有系统调用函数，然后进入内核态）。进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数，而且执行用户定义的函数的方法很巧妙（这个函数时signal函数绑定的那个处理信号函数，比如里面出现malloc系统调用），内核是在用户栈上创建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时，才返回原先进入内核的地方（线程中调用malloc所在内核执行处）。这样做的原因是用户定义的处理函数不应该在内核态下执行，所以一般在信号处理函数中，最好仅仅用来打印一条信息，然后使用longjmp或者exit退出。

![img](https://img-blog.csdnimg.cn/20190718103716258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMzM0ODM3,size_16,color_FFFFFF,t_70)

综上所述，如果信号被捕获，执行点从内核态返回用户态，在返回时，如果发现待执行进程存在被触发的signal，那么在离开内核态之后（也就是将CPU切换到用户模式），执行用户进程为该signal绑定的signal处理函数，从这一点上看，signal处理函数是在用户进程上下文中执行的。当执行完signal处理函数之后，再返回到用户进程被中断或者system call（软中断或者指令陷阱）打断的地方。



**如果signal处理函数使用系统调用，比如malloc，free**

信号处理函数中只能调用可重入函数，而不能调用不可重入函数。进程捕捉到信号并对其进行处理时，正在执行的正常指令序列就被信号处理程序临时中断，它首先执行该信号处理函数中的指令。如果从信号处理程序返回，则继续执行在捕捉到信号时正在执行的正常指令序列（这类似于发生硬件中断时所做的）。但在信号处理函数中，不能判断捕捉到信号时线程执行到何处。

 信号处理函数默认情况下是在进程的主线程调用的，这种情况下使用不可重入函数，有可能会造成不可预知的错误。比如调用了malloc函数，为了保证malloc是线程安全的，所以内部使用了锁，根据malloc中锁的不同处理方式，分别可能会导致以下情况的发生：

1)  如果是普通锁，在主线程中malloc函数获取锁之后被signal中断，在signal处理函数中继续调用malloc，因为主线程中的malloc已经获取到了锁，signal处理函数只能等待锁释放，而主线程中的malloc函数正在等待signal处理函数返回后继续执行，这样就造成了锁死；

2)  如果是递归锁，那么signal处理函数中的malloc函数获取锁后进行内存分配，因为上次的malloc操作还没完，可能成会造成内存数据混乱。




就定时而言，可不直接使用singal alarm，而使用posix定时器，通过通知线程的方式，将定时处理函数放到单独的线程中来处理。



**内核线程调度系统对malloc的处理方法**

多线程之前使用malloc是安全的，虽然它不可重入，但是用锁实现了

1)  如果是普通锁，A线程获取堆栈锁后，B线程必须等待A线程执行完成后，释放锁，然后B线程malloc才能申请内存。

2)  如果是递归锁，内核调度系统在线程之间调度时，如果线程A的malloc函数一旦开始了申请，它就不会交出CPU，而是等malloc完成后，才会根据情况是否交出CPU，如果没有特别重要的处理，调度器就会跳转到线程B中执行，如果B线程执行到malloc，同理。（调度器如何工作等我搞明白再修正这




**代码例子**

https://zhuanlan.zhihu.com/p/371222679

```c
#include <stdio.h>
#include <unistd.h>
#include <signal.h>
#include <string.h>
#include <stdlib.h>

void sig_handler(int signum)
{
    printf("\nInside handler function\n");
    char *p = NULL;
    p = (char *)malloc(sizeof(char) * 1024);
    if (NULL == p)
    {
        return;
    }
    free(p);
}


int main(int argc, char **argv)
{
    char *p = NULL;
    signal(SIGINT, sig_handler); // 初始化信号处理函数
    
    while (1)
    {
        p = (char *)malloc(sizeof(char) * 1024);
        if (NULL == p)
        {
            continue;
        }
        free(p);
    }

    return 0;
}
```

编译上述代码：

```text
gcc -g testsigint.c -o testsigint
```

运行代码，不停的按ctrl+c（要亿点点运气）

```text
[root@root]# ./testsigint
^C
Inside handler function
^C
Inside handler function
^C
Inside handler function
^C
Inside handler function
^C^C^C^C^C^C
```

当出现多个^C的时候，证明该进程已经锁死了。

新开一个窗口，获取该进程的堆栈打印。

```text
[root@root]# pstack `pidof testsigint`
#0  0x00007faae50275cc in __lll_lock_wait_private () from /lib64/libc.so.6
#1  0x00007faae4fa3b12 in _L_lock_16654 () from /lib64/libc.so.6
#2  0x00007faae4fa0753 in malloc () from /lib64/libc.so.6
#3  0x0000000000400634 in sig_handler (signum=2) at testsigint.c:11
#4  <signal handler called>
#5  0x00007faae4f9bf1b in _int_free () from /lib64/libc.so.6
#6  0x0000000000400699 in main (argc=1, argv=0x7fff29e79aa8) at testsigint.c:32
[root@localhost ~]# pstack `pidof testsigint`
#0  0x00007faae50275cc in __lll_lock_wait_private () from /lib64/libc.so.6
#1  0x00007faae4fa3b12 in _L_lock_16654 () from /lib64/libc.so.6
#2  0x00007faae4fa0753 in malloc () from /lib64/libc.so.6
#3  0x0000000000400634 in sig_handler (signum=2) at testsigint.c:11
#4  <signal handler called>
#5  0x00007faae4f9bf1b in _int_free () from /lib64/libc.so.6
#6  0x0000000000400699 in main (argc=1, argv=0x7fff29e79aa8) at testsigint.c:32
```

可以看到进程挂死在了malloc和free结对的地方，肯定是有内部资源互斥了。

在进程通过信号产生软中断进入用户自定义的信号处理函数，内核会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而用户态函数内部使用的一些全局变量、静态变量，锁等并不在保护之列，所以如果这些值在信号处理函数发生了改变，那么当函数回到用户原本的上下文继续执行时，其结果就不可预料了。

比如上面的malloc，将如一个进程此时正在执行malloc分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个malloc，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表和一些锁，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用可能回去获取同一把锁，也可能回去修改内存里面的值，这样造成的结果是不可预期的。







#### free() 释放内存，会立即归还给操作系统吗？

我们在上面的进程往下执行，看看通过 free() 函数释放内存后，堆内存还在吗？

![图片](https://img-blog.csdnimg.cn/img_convert/1a9337f8f6b83fbc186f257511b5ce67.png)

从下图可以看到，通过 free 释放内存后，堆内存还是存在的，并没有归还给操作系统。

![图片](https://img-blog.csdnimg.cn/img_convert/2b8f63892830553ec04c5f05f336ae8b.png)

这是因为与其把这 1 字节释放给操作系统，不如先缓存着放进 malloc 的内存池里，当进程再次申请 1 字节的内存时就可以直接复用，这样速度快了很多。

当然，当进程退出后，操作系统就会回收进程的所有资源。

上面说的 free 内存后堆内存还存在，是针对 malloc 通过 brk() 方式申请的内存的情况。

如果 malloc 通过 mmap 方式申请的内存，free 释放内存后就会归归还给操作系统。

我们做个实验验证下， 通过 malloc 申请 128 KB 字节的内存，来使得 malloc 通过 mmap 方式来分配内存。

```c
#include <stdio.h>
#include <malloc.h>

int main() {
  //申请1字节的内存
  void *addr = malloc(128*1024);
  printf("此128KB字节的内存起始地址：%x\n", addr);
  printf("使用cat /proc/%d/maps查看内存分配\n",getpid());

  //将程序阻塞，当输入任意字符时才往下执行
  getchar();

  //释放内存
  free(addr);
  printf("释放了128KB字节的内存，内存也归还给了操作系统\n");

  getchar();
  return 0;
}
```

执行代码：

![图片](https://img-blog.csdnimg.cn/img_convert/500fdc021d956f60963f308760f511d0.png)

查看进程的内存的分布情况，可以发现最右边没有 [head] 标志，说明是通过 mmap 以匿名映射的方式从文件映射区分配的匿名内存。

![图片](https://img-blog.csdnimg.cn/img_convert/501f458b8d35abe5e378a0f14c667797.png)

然后我们释放掉这个内存看看：

![图片](https://img-blog.csdnimg.cn/img_convert/fcdbe91cc03b6a2f6e93dd1971d1b438.png)

再次查看该 128 KB 内存的起始地址，可以发现已经不存在了，说明归还给了操作系统。

![图片](https://img-blog.csdnimg.cn/img_convert/3f63c56b131d92806b5aabca29d33a38.png)

对于 「malloc 申请的内存，free 释放内存会归还给操作系统吗？」这个问题，我们可以做个总结了：

- malloc 通过 **brk()** 方式申请的内存，free 释放内存的时候，**并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用**；
- malloc 通过 **mmap()** 方式申请的内存，free 释放内存的时候，**会把内存归还给操作系统，内存得到真正的释放**。

#### free() 函数只传入一个内存地址，为什么会知道要释放多大的内存？

还记得，我前面提到， malloc 返回给用户态的内存起始地址比进程的堆空间起始地址多了 16 字节吗？

这个多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。

![图片](https://img-blog.csdnimg.cn/img_convert/cb6e3ce4532ff0a6bfd60fe3e52a806e.png)

这样当执行 free() 函数时，free 会对传入进来的内存地址向左偏移 16 字节，然后从这个 16 字节的分析出当前的内存块的大小，自然就知道要释放多大的内存了。



### 连续存储管理

#### 静态分区分配是什么？有什么优缺点？

优点：简单，要求的硬件支持少，软件算法也简单

缺点：

* 内存利用率低，产生内部碎片
* 尺寸和分区数量难以确定
* 分区总数固定，限制了并发执行的程序数量



#### 动态分区分配是什么？有什么优缺点？

不预先划分内存，在程序装入内存时，根据进程的大小动态地建立分区，并使得分区的大小正好适合进程的需要，因此系统中分区的大小和数目是可变的。

在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进程使用，这就是动态分区的分配策略



优点：

*  没有内部碎片
* 能较有效利用内存空间，提高了多道程序系统对内存的共享

缺点：

* 容易产生外部碎片问题，为解决外部碎片问题，需要采用动态重定位，增加了计算机硬件成本，而紧凑工作又要花费大量处理机时间



#### 什么是内部碎片？什么是外部碎片？有什么解决方法？

**内部碎片就是已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间；**

内部碎片是处于区域内部或页面内部的存储块。占有这些区域或页面的进程并不使用这个存储块。而在进程占有这块存储块时，系统无法利用它。直到进程释放它，或进程结束时，系统才有可能利用这个存储块。



**外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。**

外部碎片是出于任何已分配区域或页面外部的空闲存储块。这些存储块的总和可以满足当前申请的长度要求，但是由于它们的地址不连续或其他原因，使得系统无法满足当前申请



**解决外部碎片 --> 紧缩：**

移动内存中的进程，将碎片集中起来，重新构成大的内存块。需要运行时的动态重定位，费时。

紧缩方向：

* 向一头紧缩
* 向两头紧缩。

紧缩时机：

* 在释放分区时，如果不能与空闲分区合并，则立刻进行紧缩。**好处是不存在外部碎片，坏处是费时。**
* 在内存分配时，如果剩余的空闲空间总量能满足要求但没有一个独立的空闲块能满足要求，则进行紧缩。**好处是减少紧缩次数**。





#### 首次适应算法？

思想：从头到尾寻找合适的分区



将所有空闲分区**按照地址递增的次序链接**，在申请内存分配时，从链首开始查找，**将满足需求的第一个**空闲分区分配给作业



优点：

* 综合看，首次适应算法性能最好。**算法开销小**，回收分区后，一般不需要对空闲分区队列重新排序
* 分区集中在内存的前部，大内存留在后面，便于释放后的合并



#### 最佳适应算法？

思想：优先使用更小的分区，以保留更多的大分区



将所有空闲分区按照**从小到大**的顺序形成空闲分区链，在申请内存分配时，总是把**满足需求的、最小的**空闲分区分配给作业



优点：会有更多的大分区被保留下来，更能满足大进程需求

缺点

* 会产生很多太小的、难以利用的外部碎片，需要频繁紧缩
* **算法开销大**，回收分区后可能需要对空闲分区队列重新排序



#### 最差适应算法？

思想：优先使用更大的分区，以防止产生太小的不可用碎片



将所有的空闲分区按照**从大到小**的顺序形成空闲分区链，在申请内存分配时，总是把**满足需求的、最大的**空闲分区分配给作业



优点：优先使用更大的分区，以防止产生太小的不可用碎片

缺点

* 大分区容易被用完，不利于大进程
* **算法开销大**，回收分区后可能需要对空闲分区队列重新排序



#### 邻近适应算法？（循环首次适应算法）

思想：由首次适应算法演变而来，每次从上次查找结束的位置开始查找



将所有空闲分区**按照地址递增的次序链接**（可排列成循环链表），在申请内存分配时，**总是从上次找到的空闲分区的下一个空闲分区开始查找**，将满足需求的第一个空闲分区分配给作业



优点：不用每次都从低地址的小分区开始检索**算法开销小**（原因同首次适应算法）

缺点：会使高地址的大分区也被用完





#### Buddy 伙伴算法？

伙伴算法：将动态分区的大小限定为 2^k  字节，分割方式限定为平分，分区就会变得较为规整，分割与合并会更容易，可以减少一些外部碎片。平分后的两块互称伙伴。

![img](https:////upload-images.jianshu.io/upload_images/5346502-c766de1d4facb6ee.png?imageMogr2/auto-orient/strip|imageView2/2/w/653/format/webp)

分配时可能要多次平分，释放时可能要多次合并。举例：

![img](https:////upload-images.jianshu.io/upload_images/5346502-937492787301e74a.png?imageMogr2/auto-orient/strip|imageView2/2/w/565/format/webp)

**伙伴的概念**，满足以下三个条件的称为伙伴：

* 两个块大小相同；
* 两个块地址连续；
* 两个块必须是同一个大块中分离出来的；



**关于位图**
Linux内核伙伴算法中每个order 的位图都表示所有的空闲块，位图的某位对应于两个伙伴块，为1就表示其中一块忙，为0表示两块都闲或都在使用。系统每次分配和回收伙伴块时都要对它们的伙伴位跟1进行[异或运算](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97)。所谓[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)是指刚开始时，两个伙伴块都空闲，它们的伙伴位为0，如果其中一块被使用，[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得1；如果另一块也被使用，[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得0；如果前面一块回收了[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得1；如果另一块也回收了[异或](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%BC%82%E6%88%96)后得0。
**位图的主要用途是在回收算法中指示是否可以和伙伴块合并，分配时只要搜索空闲链表就足够了。当然，分配的同时还要对相应位异或一下，这是为回收算法服务**



**记录大小不同的空闲页**

![img](https:////upload-images.jianshu.io/upload_images/5346502-8d12e8a8d7d5d353.png?imageMogr2/auto-orient/strip|imageView2/2/w/550/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/5346502-b76497f021809357.png?imageMogr2/auto-orient/strip|imageView2/2/w/343/format/webp)

**分配和释放过程**

Buddy算法的分配原理：

　　假如系统需要$4(2^2)$个页面大小的内存块，该算法就到free_area[2]中查找，如果链表中有空闲块，就直接从中摘下并分配出去。如果没有，算法将顺着数组向上查找free_area[3],如果free_area[3]中有空闲块，则将其从链表中摘下，分成等大小的两部分，前四个页面作为一个块插入free_area[2]，后4个页面分配出去，free_area[3]中也没有，就再向上查找，如果free_area[4]中有，就将这$16(2^4)$个页面等分成两份，前一半挂如free_area[3]的链表头部，后一半的8个页等分成两等分，前一半挂free_area[2]
的链表中，后一半分配出去。假如free_area[4]也没有，则重复上面的过程，知道到达free_area数组的最后，如果还没有则放弃分配。

![image.png](https://s2.loli.net/2022/10/17/6IsoA937UebM1G8.png)



 

 Buddy算法的释放原理：

　　内存的释放是分配的逆过程，也可以看作是伙伴的合并过程。当释放一个块时，先在其对应的链表中考查是否有伙伴存在，如果没有伙伴块，就直接把要释放的块挂入链表头；如果有，则从链表中摘下伙伴，合并成一个大块，然后继续考察合并后的块在更大一级链表中是否有伙伴存在，直到不能合并或者已经合并到了最大的块($2^9$个页面)。





**伙伴算法是静态分区和动态分区法的折中，比静态分区法灵活，不受分区尺寸及个数的限制；比动态分区法规范，不易出现外部碎片。会产生内部碎片，但比静态分区的小。**



**优缺点**

伙伴算法的一大优势是它能够完全避免外部碎片的产生，申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。



**适合大小恰好为 $2^k$  大小的，否则会有比较大的内部碎片。（Linux C++ vector 2 倍扩容机制）**



优点：

* 较好的解决外部碎片问题
* 当需要分配若干个内存页面时，用于DMA的内存页面必须连续，伙伴算法很好的满足了这个要求
* 只要请求的块不超过512个页面(2K)，内核就尽量分配连续的页面
* 针对大内存分配设计

缺点：

* 合并的要求太过严格，只能是满足伙伴关系的块才能合并，比如第1块和第2块就不能合并。
* 碎片问题：一个连续的内存中仅仅一个页面被占用，导致整块内存区都不具备合并的条件
* 浪费问题：伙伴算法只能分配2的幂次方内存区，当需要8K（2页）时，好说，当需要9K时，那就需要分配16K（4页）的内存空间，但是实际只用到9K空间，多余的7K空间就被浪费掉。
* 算法的效率问题： 伙伴算法拆分和合并涉及了比较多的计算还有链表和位图的操作，开销还是比较大的，如果每次 $2^n$ 大小的伙伴块就会合并到  $2^{n+1}$ 的链表队列中，那么 $2^n$ 大小链表中的块就会因为合并操作而减少，但系统随后立即有可能又有对该大小块的需求，为此必须再从 $2^{n+1}$ 大小的链表中拆分，这样的合并又立即拆分的过程是无效率的。

**Linux针对大内存的物理地址分配**，采用伙伴算法，如果是针对小于一个page的内存，频繁的分配和释放，有更加适宜的解决方案，如slab和kmem_cache等



**优化?**

* 解决内部碎片过大问题（eg：申请5页，分配8页，浪费3页）：
	* ucore 在前部留下需要的页数，释放掉尾部各页。每次释放1页，先划分成页块，再逐个释放。
* 解决切分与合并过于频繁的问题：
	* 用得较多的是单个页。位于处理器Cache中页称为热页（hot page），其余页称为冷页（cold page）。处理器对热页的访问速度要快于冷页。可建一个热页队列（per_cpu_page），暂存刚释放的单个物理页，将合并工作向后推迟 Lazy。总是试图从热页队列中分配单个物理页。分配与释放都在热页队列的队头进行。
* 解决内存碎化(有足够多的空闲页，但是没有大页块)问题：
	* 将页块从一个物理位置移动到另一个物理位置，并保持移动前后逻辑地址不变（拷贝页块内容）
	* 逻辑内存管理器。
* 满足大内存的需求：

* 物理内存空间都耗尽的情况：
	* 在任何情况下，都应该预留一部分空闲的物理内存以备急需。定义两条基准线low和high，当空闲内存量小于low时，应立刻开始回收物理内存，直到空闲内存量大于high。

* 回收物理内存：
	* 法一：启动一个守护进程，专门用于回收物理内存。周期性启动，也可被唤醒。
	* 法二：申请者自己去回收内存。实际是由内存分配程序回收。回收的方法很多，如释放缓冲区、页面淘汰等。



#### Slab 算法？

slab是Linux操作系统的一种内存分配机制。其工作是针对一些**经常分配并释放的对象**，如进程描述符等，这些对象的**大小一般比较小**，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内部碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。 


Linux 的slab 可有三种状态：

* 满的：slab 中的所有对象被标记为使用。
* 空的：slab 中的所有对象被标记为空闲。
* 部分：slab 中的对象有的被标记为使用，有的被标记为空闲。

slab 分配器首先从部分空闲的slab 进行分配。如没有，则从空的slab 进行分配。如没有，则从物理连续页上分配新的slab，并把它赋给一个cache ，然后再从新slab 分配空间。



与传统的内存管理模式相比， slab 缓存分配器提供了很多优点。
　　1、内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。
　　2、slab 缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。
　　3、slab 分配器还支持通用对象的初始化，从而避免了为同一目的而对一个对象重复进行初始化。
　　4、slab 分配器还可以支持硬件缓存对齐和着色，这允许不同缓存中的对象占用相同的缓存行，从而提高缓存的利用率并获得更好的性能。



### 非连续存储管理
