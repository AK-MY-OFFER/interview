# 同步互斥

## 问题

### 锁

* 知道哪些种类的锁？各自特点和适用环境？
  * 互斥锁与自旋锁
  * 读写锁？
  * 乐观锁与悲观锁？
  * CAS 锁？
  * CAS 不是乐观锁吗，为什么基于 CAS 实现的自旋锁是悲观锁？
* 谈谈死锁
  * 死锁是什么？
  * 形成死锁的条件？
  * 死锁处理？
  * 死锁恢复（解除）？
  * 死锁预防（写代码的时候）？
  * 死锁避免？
  * 如何检测死锁？
  * 如何用工具排查死锁？
  * 手搓一个模拟死锁的代码?
* 锁的可重入不可重入了解吗
* 忙等待锁怎么实现？
* 无等待锁怎么实现？
* 读写锁怎么实现？



### 条件变量

* 什么是条件变量
* 为什么 pthread_cond_wait 需要加锁？
* 在生产者线程中修改条件时为什么要加 mutex？
* 消费者线程中判断条件为什么要放在 while 中？
* signal 到底是放在 unlock 之前还是之后？
* 条件变量实现机制？
* 虚假唤醒和唤醒丢失问题？

https://www.cnblogs.com/harlanc/p/8596211.html

### 信号量

* 记录型和整型信号量的区别与使用方法？
* 信号量机制怎么实现的？



### 原子操作

* 原子操作的是如何实现的？



### 经典问题

* 谈谈生产者-消费者模式？
	* 什么是生产者-消费者模式？
	* 为什么要使用生产者消费者模式？
	* 生产者-消费者模式的特点？
	* 生产者-消费者模式的应用场景？
	* 生产者-消费者模式的优点？

* 生产者消费者模式的实现（手搓代码）？
* 谈谈不同的生产者消费者模型？
	* 单生产者单消费者 SPSC
	* 多生产者单消费者 MPSC
	* 单生产者多消费者 SPMC
	* 多生产者多消费者-单缓冲区 MPMC-SB
	* 多生产者多消费者-双缓冲区 MPMC-MB
	* 多生产者多消费者-DUO缓冲区 MPMC-MB
	* 多生产者多消费者-环形缓冲区 MPMC-RingBuffer
	
* 哲学家就餐问题？
* 读者写者问题？



## 回答

### 锁

#### 知道哪些种类的锁？各自特点和适用环境？

**互斥锁与自旋锁**

最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。

加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：

- **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；
- **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；

互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，**既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞**。

**对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的**。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%94%81/%E4%BA%92%E6%96%A5%E9%94%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。

那这个开销成本是什么呢？会有**两次线程上下文切换的成本**：

- 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
- 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。

线程的上下文切换的是什么？当两个线程是属于同一个进程，**因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。

所以，**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**

自旋锁是通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

一般加锁的过程，包含两个步骤：

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；

CAS 函数就把这两个步骤合并成一条硬件级指令，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。

比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。

使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 `while` 循环等待实现，不过最好是使用 CPU 提供的 `PAUSE` 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。

自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。**需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。**

自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。

自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。

它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。

------



**读写锁**

读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。

所以，**读写锁适用于能明确区分读操作和写操作的场景**。

读写锁的工作原理是：

- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
- 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。

所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。

知道了读写锁的工作原理后，我们可以发现，**读写锁在读多写少的场景，能发挥出优势**。

另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。

读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%94%81/%E8%AF%BB%E4%BC%98%E5%85%88%E9%94%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

而「写优先锁」是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%94%81/%E5%86%99%E4%BC%98%E5%85%88%E9%94%81%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。

写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。

**既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。**

**公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。**

互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

------



**乐观锁与悲观锁**

前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。

悲观锁做事比较悲观，它认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。

那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。

乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。

可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现**乐观锁全程并没有加锁，所以它也叫无锁编程**。

这里举一个场景例子：在线文档。

我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。

那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。

怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。

服务端要怎么验证是否冲突了呢？通常方案如下：

- 由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；
- 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。

实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。

乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**



**CAS 锁？**

CAS 是乐观锁的一种实现，CAS 全称是比较和替换，CAS 的操作主要由以下几个步骤组成：

1. 先查询原始值
2. 操作时比较原始值是否修改
3. 如果修改，则操作失败，禁止更新操作，如果没有发生修改，则更新为新值

上述三个步骤是一个原子性操作，不可以被拆分执行。

![img](https://pic4.zhimg.com/v2-de62c2ce5711fe38b4b57ff20e511e87_b.jpg)

CAS 的优势：CAS 是一种无锁操作，不需要加锁，避免了线程切换的开销。



CAS 虽然在低并发量的情况下可以减少系统的开销，但是CAS也有一些问题：

- CPU 开销过大问题
- ABA 问题
- 只能针对一个共享变量



CPU 开销过大

在我们使用 CAS 时，如果并发量过大，我们的程序有可能会一直自旋，长时间占用CPU资源。



ABA 问题

假设有个共享变量 J，原始值为 1。

1. 线程 A 读取变量 J ，值为 1
2. 线程 B 读取变量 J，值为 1
3. 线程 A 变量 J+1，CAS 成功从 1 修改为 2
4. 线程 C 读取变量 J，值为 2
5. 线程 C 将变量 J-1，CAS 成功从 2 修改为 1
6. 线程 A 通过 CAS 比较和替换，依然可以改为自己想修改的值

上述过程，线程 B 和 C 已经将变量 J 的值已经改变了，但是线程 A 无法发现，依然可以修改共享变量，这就产生了 ABA 问题。



共享变量单一

CAS操作单个共享变量的时候可以保证原子的操作，无法操作多个变量。但是在JDK5之后，AtomicReference可以用来保证对象之间的原子性，我们可以把多个对象放入CAS中操作。



如何防止 CAS 的 ABA

四个字：加标志位（version）。

至于标志位可以是自增的数字，也可以是时间戳。通过标志位我们可以精确的知道每次修改。





**CAS 不是乐观锁吗，为什么基于 CAS 实现的自旋锁是悲观锁？**

乐观锁是先修改同步资源，再验证有没有发生冲突。

悲观锁是修改共享数据前，都要先加锁，防止竞争。

CAS 是乐观锁没错，但是 CAS 和自旋锁不同之处，自旋锁基于 CAS 加了while 或者睡眠 CPU 的操作而产生自旋的效果，加锁失败会忙等待直到拿到锁，自旋锁是要需要事先拿到锁才能修改数据的，所以算悲观锁。





#### 谈谈死锁

**死锁是什么**？

那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成**两个线程都在等待对方释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。



**形成死锁的条件**？

同时满足

- 互斥条件：多个线程不能同时使用同一个资源
- 持有并等待条件：持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1
- 不可剥夺条件：当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取
- 环路等待条件：在死锁发生的时候，两个线程获取资源的顺序构成了环形链。



**死锁的处理方法？**

* 鸵鸟策略
* 死锁检测与死锁恢复
* 死锁预防
* 死锁避免



鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1、每种类型一个资源的死锁检测

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/QQ%E6%88%AA%E5%9B%BE20210227001659.png)

上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

2、每种类型多个资源的死锁检测

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/QQ%E6%88%AA%E5%9B%BE20210227001758.png)

上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。



**死锁恢复（解除）？**

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复



**死锁预防？**

在程序运行之前预防发生死锁。

1. 破坏互斥条件：例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。
2. 破坏请求和保持条件：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。
3. 破坏不剥夺条件：允许抢占资源
4. 破坏循环请求等待：给资源统一编号，进程只能按编号顺序来请求资源。



**死锁避免？**

在程序运行时避免发生死锁。



安全状态

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/QQ%E6%88%AA%E5%9B%BE20210227001840.png)

图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。



单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/QQ%E6%88%AA%E5%9B%BE20210227001911.png)

上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。



多个资源的银行家算法

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/QQ%E6%88%AA%E5%9B%BE20210227001939.png)

上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。



检查一个状态是否安全的算法如下：

- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。



**如何检测死锁**？

https://blog.csdn.net/qq_42956653/article/details/126313099#t6

死锁问题转换为有向图环路问题。

* 用 pair 把锁和线程绑定
* hook pthread_mutex_lock 函数
	* 加锁前调用 lock_before 函数：检测这个锁有没有被别的线程占用，如果被占用，那么我们就需要往图里面加一条边
	* 加锁后调度用 lock_after 函数
* dfs 判环



使用pthread_mutex_lock和pthread_mutex_unlock构建有向图？

在调用系统提供的lock以前，我们需要检测这个锁有没有被别的线程占用，如果被占用，那么我们就需要往图里面加一条边。

如果没有被占用，那么我们就往里面走。也就是说加锁完，调用系统提供的lock之后， 我们需要告诉后面的线程，这个锁被我占用了，即添加一项pair，供别人lock之前去检测。 如果被占用了，然后锁被释放，本线程获取到了这个以前被占用的锁，那么我们lock之后，需要把原来添加的一条边删除掉，因为这个锁已经属于自己了，并且将锁对应的pair中的th_id改成自己。

在调用系统提供的unlock之后，解锁了一个锁之后，我们去看看还有没有渴望得到这个锁的，如果没有，则将锁对应的pair置空，如果有，则不管pair。



**如何用工具排查死锁**？

由于小林的死锁代码例子是 C 写的，在 Linux 下，我们可以使用 `pstack` + `gdb` 工具来定位死锁问题。

pstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 `pstack <pid>` 就可以了。

那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。

我用 pstack 输出了我前面模拟死锁问题的进程的所有线程的情况，我多次执行命令后，其结果都一样，如下：

```shell
$ pstack 87746
Thread 3 (Thread 0x7f60a610a700 (LWP 87747)):
#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0
#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000400725 in threadA_proc ()
#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0
#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6
Thread 2 (Thread 0x7f60a5709700 (LWP 87748)):
#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0
#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000400792 in threadB_proc ()
#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0
#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7f60a610c700 (LWP 87746)):
#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0
#1  0x0000000000400806 in main ()

....

$ pstack 87746
Thread 3 (Thread 0x7f60a610a700 (LWP 87747)):
#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0
#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000400725 in threadA_proc ()
#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0
#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6
Thread 2 (Thread 0x7f60a5709700 (LWP 87748)):
#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0
#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000400792 in threadB_proc ()
#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0
#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6
Thread 1 (Thread 0x7f60a610c700 (LWP 87746)):
#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0
#1  0x0000000000400806 in main ()
```

可以看到，Thread 2 和 Thread 3 一直阻塞获取锁（*pthread_mutex_lock*）的过程，而且 pstack 多次输出信息都没有变化，那么可能大概率发生了死锁。

但是，还不能够确认这两个线程是在互相等待对方的锁的释放，因为我们看不到它们是等在哪个锁对象，于是我们可以使用 gdb 工具进一步确认。

整个 gdb 调试过程，如下：

```shell
// gdb 命令
$ gdb -p 87746

// 打印所有的线程信息
(gdb) info thread
  3 Thread 0x7f60a610a700 (LWP 87747)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
  2 Thread 0x7f60a5709700 (LWP 87748)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
* 1 Thread 0x7f60a610c700 (LWP 87746)  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0
//最左边的 * 表示 gdb 锁定的线程，切换到第二个线程去查看

// 切换到第2个线程
(gdb) thread 2
[Switching to thread 2 (Thread 0x7f60a5709700 (LWP 87748))]#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0 

// bt 可以打印函数堆栈，却无法看到函数参数，跟 pstack 命令一样 
(gdb) bt
#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0
#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0
#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0
#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25
#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0
#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6

// 打印第三帧信息，每次函数调用都会有压栈的过程，而 frame 则记录栈中的帧信息
(gdb) frame 3
#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25
27    printf("thread B waiting get ResourceA \n");
28    pthread_mutex_lock(&mutex_A);

// 打印mutex_A的值 ,  __owner表示gdb中标示线程的值，即LWP
(gdb) p mutex_A
$1 = {__data = {__lock = 2, __count = 0, __owner = 87747, __nusers = 1, __kind = 0, __spins = 0, __list = {__prev = 0x0, __next = 0x0}}, 
  __size = "\002\000\000\000\000\000\000\000\303V\001\000\001", '\000' <repeats 26 times>, __align = 2}

// 打印mutex_B的值 ,  __owner表示gdb中标示线程的值，即LWP
(gdb) p mutex_B
$2 = {__data = {__lock = 2, __count = 0, __owner = 87748, __nusers = 1, __kind = 0, __spins = 0, __list = {__prev = 0x0, __next = 0x0}}, 
  __size = "\002\000\000\000\000\000\000\000\304V\001\000\001", '\000' <repeats 26 times>, __align = 2}  
```

我来解释下，上面的调试过程：

1. 通过 `info thread` 打印了所有的线程信息，可以看到有 3 个线程，一个是主线程（LWP 87746），另外两个都是我们自己创建的线程（LWP 87747 和 87748）；
2. 通过 `thread 2`，将切换到第 2 个线程（LWP 87748）；
3. 通过 `bt`，打印线程的调用栈信息，可以看到有 threadB_proc 函数，说明这个是线程 B 函数，也就说 LWP 87748 是线程 B;
4. 通过 `frame 3`，打印调用栈中的第三个帧的信息，可以看到线程 B 函数，在获取互斥锁 A 的时候阻塞了；
5. 通过 `p mutex_A`，**打印互斥锁 A 对象信息，可以看到它被 LWP 为 87747（线程 A） 的线程持有着**；
6. 通过 `p mutex_B`，**打印互斥锁 B 对象信息，可以看到他被 LWP 为 87748 （线程 B） 的线程持有着**；

因为线程 B 在等待线程 A 所持有的 mutex_A, 而同时线程 A 又在等待线程 B 所拥有的mutex_B, 所以可以断定该程序发生了死锁。

**手搓一个模拟死锁的代码**?

```c++
#include <pthread.h>
#include <unistd.h>
#include <stdio.h>

pthread_mutex_t m_mutex1, m_mutex2;
int A = 0, B = 0;

void* threadFunc1(void* args) {
    pthread_mutex_lock(&m_mutex1);
    A = 1;
	printf("thread 1 write source A\n");
	usleep(100);

    pthread_mutex_lock(&m_mutex2);
    B = 1;
	printf("thread 1 write source B\n");
	
	//解锁，实际上是跑不到这里的，因为前面已经死锁了
    pthread_mutex_unlock(&m_mutex2);
    pthread_mutex_unlock(&m_mutex1);

    return NULL;
}

void* threadFunc2(void* args) {
    pthread_mutex_lock(&m_mutex2);
    B = 1;
	printf("thread 2 write source B\n");
	usleep(100);

    pthread_mutex_lock(&m_mutex1);
    A = 1;
	printf("thread 2 write source A\n");
	
	//解锁，实际上是跑不到这里的，因为前面已经死锁了
    pthread_mutex_unlock(&m_mutex1);
    pthread_mutex_unlock(&m_mutex2);

    return NULL;
}

int main() {
    if(pthread_mutex_init(&m_mutex1, 0) != 0) {
        printf("init mutex 1 failed\n");
        return -1;
    }
    if(pthread_mutex_init(&m_mutex2, 0) != 0) {
        printf("init mutex 2 failed\n");
        return -1;
    }

    pthread_t hThread1, hThread2;
    if(pthread_create(&hThread1, NULL, &threadFunc1, NULL) != 0) {
        printf("create thread1 failed\n");
        return -1;
    }
    if(pthread_create(&hThread2, NULL, &threadFunc2, NULL) != 0) {
        printf("create thread1 failed\n");
        return -1;
    }

    while(1) {
        sleep(1);
    }

    pthread_mutex_destroy(&m_mutex1);
    pthread_mutex_destroy(&m_mutex2);

    return 0;
}
```



#### 锁的可重入不可重入了解吗

java 里的概念

不可重入锁：只判断这个锁有没有被锁上，只要被锁上申请锁的线程都会被要求等待。实现简单

可重入锁：不仅判断锁有没有被锁上，还会判断锁是谁锁上的，当就是自己锁上的时候，那么他依旧可以再次访问临界资源，并把加锁次数加一。
设计了加锁次数，以在解锁的时候，可以确保所有加锁的过程都解锁了，其他线程才能访问。不然没有加锁的参考值，也就不知道什么时候解锁？解锁多少次？才能保证本线程已经访问完临界资源了可以唤醒其他线程访问了。实现相对复杂。



#### 忙等待锁怎么实现？

在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊**原子操作指令 —— 测试和置位（Test-and-Set）指令**。

如果用 C 代码表示 Test-and-Set 指令，形式如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/13-TestAndSet.jpg)

测试并设置指令做了下述事情:

- 把 `old_ptr` 更新为 `new` 的新值
- 返回 `old_ptr` 的旧值；

当然，**关键是这些代码是原子执行**。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。

那什么是原子操作呢？**原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态**

我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/14-%E8%87%AA%E6%97%8B%E9%94%81.jpg)

我们来确保理解为什么这个锁能工作：

- 第一个场景是，首先假设一个线程在运行，调用 `lock()`，没有其他线程持有锁，所以 `flag` 是 0。当调用 `TestAndSet(flag, 1)` 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 `unlock()` 将 `flag` 清理为 0。
- 第二种场景是，当某一个线程已经持有锁（即 `flag` 为1）。本线程调用 `lock()`，然后调用 `TestAndSet(flag, 1)`，这一次返回 1。只要另一个线程一直持有锁，`TestAndSet()` 会重复返回 1，本线程会一直**忙等**。当 `flag` 终于被改为 0，本线程会调用 `TestAndSet()`，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。

很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为**自旋锁（spin lock）**。

这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。

#### 无等待锁怎么实现？

无等待锁顾明思议就是获取不到锁的时候，不用自旋。

既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/15-%E6%97%A0%E7%AD%89%E5%BE%85%E9%94%81.jpg)



#### 读写锁怎么实现？

```c++
#include <shared_mutex>

class readWriteLock {
private:
    std::shared_mutex readMtx;	// 可多线程同时读
    std::mutex writeMtx;
    int readCnt; // 已加读锁个数
public:
    readWriteLock() : readCnt(0) {}
    void readLock()
    {
        readMtx.lock();
        if (++readCnt == 1) {
            writeMtx.lock();  // 存在线程读操作时，写加锁（只加一次）
        }
        readMtx.unlock();
    }
    void readUnlock()
    {
        readMtx.lock();
        if (--readCnt == 0) { // 没有线程读操作时，释放写锁
            writeMtx.unlock();
        }
        readMtx.unlock();
    }
    void writeLock()
    {
        writeMtx.lock();
    }
    void writeUnlock()
    {
        writeMtx.unlock();
    }
};

```



### 条件变量

#### 什么是条件变量

条件变量是线程的另外一种同步机制，这些同步对象为线程提供了会合的场所，理解起来就是两个（或者多个）线程需要碰头（或者说进行交互-一个线程给另外的一个或者多个线程发送消息），我们指定在条件变量这个地方发生，一个线程用于修改这个变量使其满足其它线程继续往下执行的条件，其它线程则接收条件已经发生改变的信号。

条件变量同锁一起使用使得线程可以以一种**无竞争**的方式等待任意条件的发生。所谓无竞争就是，条件改变这个信号会发送到所有等待这个信号的线程。而不是说一个线程接受到这个消息而其它线程就接收不到了。



**条件变量的优点：**

相较于mutex而言，条件变量可以减少竞争。如直接使用mutex，除了生产者、消费者之间要竞争互斥量以外，消费者之间也需要竞争互斥量，但如果汇聚（链表）中没有数据，消费者之间竞争互斥锁是无意义的。有了条件变量机制以后，只有生产者完成生产，才会引起消费者之间的竞争。提高了程序效率。



具体的函数介绍就不说了，详细参考APUE

* pthread_cond_init()函数               功能：初始化一个条件变量
* pthread_cond_wait()函数             功能：阻塞等待一个条件变量
* pthread_cond_timedwait()函数    功能：限时等待一个条件变量
* pthread_cond_signal()函数          功能：唤醒至少一个阻塞在条件变量上的线程
* pthread_cond_broadcast()函数    功能：唤醒全部阻塞在条件变量上的线程
* pthread_cond_destroy()函数        功能：销毁一个条件变量

以上6 个函数的返回值都是：成功返回0， 失败直接返回错误号。

pthread_cond_t 类型，其本质是一个结构体。为简化理解，应用时可忽略其实现细节，简单当成整数看待。如：

pthread_cond_t  cond; 变量cond只有两种取值1、0。



下面通过一个例子来详细说一下正确使用条件变量的方法。下例实现了生产者和消费者模型，生产者向队列中插入数据，消费者则在生产者发出队列准备好（有数据了）后接收消息，然后取出数据进行处理。实现的关键点在以下几个方面：

* 生产者和消费者都对条件变量的使用加了锁
* 消费者调用pthread_cond_wait,等待队列是否准备好的信息，注意参数有两个，一个是pthread_cond_t，另外一个是pthread_mutex_t.

代码：

```c++

#include <pthread.h>
struct msg {
struct msg *m_next;
/* ... more stuff here ... */
};
struct msg *workq;
pthread_cond_t qready = PTHREAD_COND_INITIALIZER;
pthread_mutex_t qlock = PTHREAD_MUTEX_INITIALIZER;
void
process_msg(void)	// 消费者
{
	struct msg *mp;
	for (;;) {
        pthread_mutex_lock(&qlock);
        while (workq == NULL)
            pthread_cond_wait(&qready, &qlock);
        mp = workq;
        workq = mp->m_next;
        pthread_mutex_unlock(&qlock);
        /* now process the message mp */
	}
}
void
enqueue_msg(struct msg *mp)	// 生产者
{
	pthread_mutex_lock(&qlock);
	mp->m_next = workq;
	workq = mp;
	pthread_cond_signal(&qready);
    pthread_mutex_unlock(&qlock);
}

```



#### 为什么 pthread_cond_wait 需要加锁？

**防止因为缺少锁造成唤醒丢失**

pthread_cond_wait中的mutex用于保护条件变量，调用这个函数进行等待条件的发生时,mutex会被自动释放，以供其它线程（生产者）改变条件pthread_cond_wait中的两个步骤必须是原子性的(atomically,万恶的APUE中文版把这个单词翻译成了『自动』，误人子弟啊)，也就是说必须把两个步骤捆绑到一起：

- 把调用线程放到条件等待队列上
- 释放mutex

不然呢，如果不是原子性的，上面的两个步骤中间就可能插入其它操作。比如，如果先释放mutex，这时候生产者线程向队列中添加数据，然后signal,之后消费者线程才去『把调用线程放到等待队列上』，signal信号就这样被丢失了。

如果先把调用线程放到条件等待队列上，这时候另外一个线程发送了pthread_cond_signal（我们知道这个函数的调用是不需要mutex的），然后调用线程立即获取mutex，两次获取mutex会产生deadlock.



#### 在生产者线程中修改条件时为什么要加 mutex？

**防止因为缺少锁造成唤醒丢失**

如果不这么做信号可能会丢失，看下面的例子：

```lisp
Thead A（消费者）                    Thread B（生产者）

pthread_mutex_lock(&qlock);
while (workq == NULL)
                                   mp->m_next = workq;
	                               workq = mp;
                                   pthread_cond_signal(&cond);

pthread_cond_wait(&qready, &qlock);
```

在while判断之后向队列中插入数据，虽然已经有数据了，但线程A还是调用了pthread_cond_wait等待下一个信号到来。



#### 消费者线程中判断条件为什么要放在 while 中？

**防止虚假唤醒**

```lisp
while (workq == NULL)
    pthread_cond_wait(&qready, &qlock);
mp = workq;  
```

我们把while换成if可不可以呢？

```lisp
if (workq == NULL)
    pthread_cond_wait(&qready, &qlock);
mp = workq; 
```

答案是不可以，一个生产者可能对应着多个消费者，生产者向队列中插入一条数据之后发出signal，然后各个消费者线程的pthread_cond_wait获取mutex后返回，当然，这里只有一个线程获取到了mutex，然后进行处理，其它线程会pending在这里，处理线程处理完毕之后释放mutex，刚才等待的线程中有一个获取mutex，如果这里用if，就会在当前队列为空的状态下继续往下处理，这显然是不合理的。



#### signal 到底是放在 unlock 之前还是之后？

```cpp
void
enqueue_msg(struct msg *mp)
{
	pthread_mutex_lock(&qlock);
	mp->m_next = workq;
	workq = mp;
	pthread_mutex_unlock(&qlock);
	pthread_cond_signal(&qready);
}
```

如果先unlock，再signal,如果这时候有一个消费者线程恰好获取mutex，然后进入条件判断，这里就会判断成功，从而跳过pthread_cond_wait,下面的signal就会不起作用；另外一种情况，一个优先级更低的不需要条件判断的线程正好也需要这个mutex，这时候就会转去执行这个优先级低的线程，就违背了设计的初衷。

```cpp
void
enqueue_msg(struct msg *mp)
{
	pthread_mutex_lock(&qlock);
	mp->m_next = workq;
	workq = mp;
	pthread_cond_signal(&qready);
	pthread_mutex_unlock(&qlock);
}
```

如果把signal放在unlock之前，消费者线程会被唤醒，获取mutex发现获取不到，就又去sleep了。浪费了资源.但是在LinuxThreads或者NPTL里面，就不会有这个问题，因为在Linux 线程中，有两个队列，分别是cond_wait队列和mutex_lock队列，  cond_signal只是让线程从cond_wait队列移到mutex_lock队列，而不用返回到用户空间，不会有性能的损耗。所以在Linux中推荐使用这种模式。



#### 条件变量实现机制？

https://blog.csdn.net/THEANARKH/article/details/117160793

条件变量是线程间同步的一种机制，本文分析条件变量的实现和使用。我们先看一下条件变量的定义。

```c
typedef struct
{
  int c_spinlock;                  /* Spin lock to protect the queue.  */
  struct _pthread_queue c_waiting; /* Threads waiting on this condition.  */
} pthread_cond_t;

```

条件变量就是在条件不满足的时候，把线程插入等待队列，等待条件满足的时候再唤醒队列里的线程。我们看一下具体实现

`pthread_cond_wait`

```c
// 阻塞等待条件。进入该函数前，已经获得了互斥锁mutex
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex)
{
  volatile pthread_t self = thread_self();
  // 加锁操作队列
  acquire(&cond->c_spinlock);
  // 插入条件的等待队列
  enqueue(&cond->c_waiting, self);
  // 操作完释放锁
  release(&cond->c_spinlock);
  // 释放互斥变量，否则别人无法操作资源，导致条件一直无法满足
  pthread_mutex_unlock(mutex);
  // 挂起等待条件满足后被唤醒
  suspend_with_cancellation(self);
  // 被唤醒后重新获取互斥锁
  pthread_mutex_lock(mutex);
  /* This is a cancellation point */
  // 取消点，等待期间被取消了
  if (self->p_canceled && self->p_cancelstate == PTHREAD_CANCEL_ENABLE) {
    /* Remove ourselves from the waiting queue if we're still on it */
    acquire(&cond->c_spinlock);
    // 线程准备退出，从条件阻塞队列中移除
    remove_from_queue(&cond->c_waiting, self);
    release(&cond->c_spinlock);
    pthread_exit(PTHREAD_CANCELED);
  }
  return 0;
}

```

pthread_cond_wait函数是当条件不能满足时，线程调用的函数。调用完后线程会被挂起，等待被唤醒（如果不希望一直被阻塞可以调用pthread_cond_timedwait，pthread_cond_timedwait支持定时阻塞）。看一下挂起线程的逻辑。

`suspend_with_cancellation`

```c
static inline void suspend_with_cancellation(pthread_t self)
{
  sigset_t mask;
  sigjmp_buf jmpbuf;
  // 获取当前的信号屏蔽码
  sigprocmask(SIG_SETMASK, NULL, &mask); /* Get current signal mask */
  // 清除PTHREAD_SIG_RESTART的信号掩码，即允许处理该信号
  sigdelset(&mask, PTHREAD_SIG_RESTART); /* Unblock the restart signal */
  /* No need to save the signal mask, we'll restore it ourselves */
  /*
    直接调用返回0，从siglongjump回来返回非0,这里支持线程挂起时，
    收到restart信号被唤醒，或者在取消信号的处理函数中，通过siglongjmp返回这里
  */
  if (sigsetjmp(jmpbuf, 0) == 0) {
    self->p_cancel_jmp = &jmpbuf;
    // 已经被取消并且是可取消的则直接返回，否则挂起等待唤醒
    if (! (self->p_canceled && self->p_cancelstate == PTHREAD_CANCEL_ENABLE)) {
      do {
        // 挂起等待restart信号
        sigsuspend(&mask);               /* Wait for a signal */
      } while (self->p_signal != PTHREAD_SIG_RESTART);
    }
    self->p_cancel_jmp = NULL;
  } else {
    // 从cancel信号的处理函数中的siglongjmp返回，重新设置信号掩码,屏蔽restart信号
    sigaddset(&mask, PTHREAD_SIG_RESTART); /* Reblock the restart signal */
    sigprocmask(SIG_SETMASK, &mask, NULL);
  }
}

```

我们看到最终通过调用sigsuspend挂起线程。等待信号的唤醒，从while循环的条件我们可以看到，当收到PTHREAD_SIG_RESTART信号的时候线程才会真正被“唤醒”。接着我们看看当条件满足后，其他线程是如何唤醒被阻塞的线程的。

`pthread_cond_signal`

```c
// 条件满足，唤醒线程
int pthread_cond_signal(pthread_cond_t *cond)
{
  pthread_t th;

  acquire(&cond->c_spinlock);
  // 取出一个被被阻塞的线程
  th = dequeue(&cond->c_waiting);
  release(&cond->c_spinlock);
  // 发送信号唤醒他
  if (th != NULL) restart(th);
  return 0;
}

// 给pid进程发送唤醒信号
static inline void restart(pthread_t th)
{
  kill(th->p_pid, PTHREAD_SIG_RESTART);
}
```

我们看到pthread_cond_signal的函数非常简单，从阻塞队列中获取一个线程，然后给他发一个唤醒信号。另外线程库也支持唤醒所有线程。

`pthread_cond_broadcast`

```c
// 条件满足，唤醒所有线程
int pthread_cond_broadcast(pthread_cond_t *cond)
{
  pthread_queue tosignal;
  pthread_t th;

  acquire(&cond->c_spinlock);
  /* Copy the current state of the waiting queue and empty it */
  tosignal = cond->c_waiting;
  // 重置阻塞队列
  queue_init(&cond->c_waiting);
  release(&cond->c_spinlock);
  /* Now signal each process in the queue */
  // 发送信号唤醒所有线程
  while ((th = dequeue(&tosignal)) != NULL) restart(th);
  return 0;
}

```

pthread_cond_broadcast就是给每一个等待的线程发送唤醒信号。这就是线程条件变量的原理和实现。最后我们看一下使用例子。

```c
struct prodcons {
  int buffer[BUFFER_SIZE];      /* 环形数据缓冲区 */
  pthread_mutex_t lock;         /* 访问数据区的互斥锁 */
  int readpos, writepos;        /* 读写指针 */
  pthread_cond_t notempty;      /* 消费者使用的条件变量，非空即有数据消费 */
  pthread_cond_t notfull;       /* 生产者使用的条件变量，非满即可以生产数据 */
};

struct prodcons buffer;

void init(struct prodcons * b)
{
  pthread_mutex_init(&b->lock, NULL);
  pthread_cond_init(&b->notempty, NULL);
  pthread_cond_init(&b->notfull, NULL);
  b->readpos = 0;
  b->writepos = 0;
}

int main()
{
  pthread_t th_a, th_b;
  void * retval;
  // 初始化线程间共享的数据结构
  init(&buffer);
  // 创建两个线程
  pthread_create(&th_a, NULL, producer, 0);
  pthread_create(&th_b, NULL, consumer, 0);
  pthread_join(th_a, &retval);
  pthread_join(th_b, &retval);
  return 0;
}

void * producer(void * data)
{
  int n;
  for (n = 0; n < 10000; n++) {
    printf("%d --->\n", n);
    put(&buffer, n);
  }
  put(&buffer, OVER);
  return NULL;
}

void * consumer(void * data)
{
  int d;
  while (1) {
    d = get(&buffer);
    if (d == OVER) break;
    printf("---> %d\n", d);
  }
  return NULL;
}

void put(struct prodcons * b, int data)
{
  // 操作共享数据需要加锁
  pthread_mutex_lock(&b->lock);
  /* 写指针+1等于读指针，说明没有空闲可写了，等待空闲空间 */
  while ((b->writepos + 1) % BUFFER_SIZE == b->readpos) {
    pthread_cond_wait(&b->notfull, &b->lock);
  }
  // pthread_cond_wait中被唤醒后会重新获得互斥锁，所以这里直接操作就行
  b->buffer[b->writepos] = data;
  b->writepos++;
  // 到尾巴了，修正位置
  if (b->writepos >= BUFFER_SIZE) b->writepos = 0;
  /* 有数据可消费了，通知等待的消费者 */
  pthread_cond_signal(&b->notempty);
  pthread_mutex_unlock(&b->lock);
}


int get(struct prodcons * b)
{
  int data;
  pthread_mutex_lock(&b->lock);
  /* 读写指针相等说明没有数据读了，等待数据 */
  while (b->writepos == b->readpos) {
    pthread_cond_wait(&b->notempty, &b->lock);
  }
  data = b->buffer[b->readpos];
  b->readpos++;
  if (b->readpos >= BUFFER_SIZE) b->readpos = 0;
  /* 消费了数据，说明有空闲空间了，唤醒生产者 */
  pthread_cond_signal(&b->notfull);
  pthread_mutex_unlock(&b->lock);
  return data;
}

```



#### 什么是唤醒丢失问题？

https://blog.csdn.net/qq_39354847/article/details/126432944

唤醒丢失：唤醒信号是一次性的且存在丢失可能，要根据实际情况决定是否等待

**唤醒丢失情况1：缺少条件**

```c
std::mutex mutex;
std::condition_variable cv;
std::vector<int> vec;

void Consume() {
  std::unique_lock<std::mutex> lock(mutex);
  cv.wait(lock);
  std::cout << "consume " << vec.size() << "\n";
}

void Produce() {
  std::unique_lock<std::mutex> lock(mutex);
  vec.push_back(1);
  cv.notify_all();
  std::cout << "produce \n";
}

int main() {
  std::thread t(Consume);
  t.detach();
  Produce();
  return 0;
}
```


如果先执行的Produce()，后执行的Consume()，生产者提前生产出了数据，去通知消费者，但是此时消费者线程如果还没有执行到wait语句，即线程还没有处于挂起等待状态，线程没有等待此条件变量上，那通知的信号就丢失了，后面Consume()中才执行wait处于等待状态，但此时生产者已经不会再触发notify，那消费者线程就会始终阻塞下去，出现bug。

如果先执行的Produce()，后执行的Consume()，生产者提前生产出了数据，去通知消费者，但是此时消费者线程如果还没有执行到wait语句，即线程还没有处于挂起等待状态，线程没有等待此条件变量上，那通知的信号就丢失了，后面Consume()中才执行wait处于等待状态，但此时生产者已经不会再触发notify，那消费者线程就会始终阻塞下去，出现bug。
---- 程序喵大人

**唤醒信号是一次性的且存在丢失可能，因此我们需要根据实际情况决定是否要等待**

* 如果先执行的Produce()，后执行的Consume()，队列中已经有东西了，那么就不用等待了
* 否则，队列开始的那么还是要等待

因此我们需要给等待加上条件（下面的代码是有问题的！！！）

```c++
std::mutex mutex;
std::condition_variable cv;
std::vector<int> vec;

void Consume() {
  std::unique_lock<std::mutex> lock(mutex);
  if (vec.empty()) { // 加入此判断条件，但这样虚假唤醒的问题！！！
      cv.wait(lock);
  }
  std::cout << "consume " << vec.size() << "\n";
}

void Produce() {
  std::unique_lock<std::mutex> lock(mutex);
  vec.push_back(1);
  cv.notify_all();
  std::cout << "produce \n";
}

int main() {
  std::thread t(Consume);
  t.detach();
  Produce();
  return 0;
}

```

这样就能解决信号丢失的问题，但是使用 `if`来进行条件判断虚假唤醒的问题，这个在后面虚假唤醒的部分解决。**建议暂时跳过`唤醒丢失情况 2：没有搭配锁` 这部分内容，先去看`虚假唤醒`这部分内容**

唤醒丢失情况2：没有搭配锁
例子：来自参考资料4

```c++
class Foo {
    mutex mtx;
    condition_variable cv;
    int k = 0;
  
public:
    Foo() {
    }

    void first(function<void()> printFirst) {
        // printFirst() outputs "first". Do not change or remove this line.
        lock_guard<mutex> lock(mtx);
        printFirst();
        k = 1;
        cv.notify_all();
    }

    void second(function<void()> printSecond) {
    
        // printSecond() outputs "second". Do not change or remove this line.
        unique_lock<mutex> lock(mtx);
        cv.wait(lock, [this](){ return k == 1;});
        printSecond();
        k = 2;
        cv.notify_one();
        
    }

    void third(function<void()> printThird) {
        
        // printThird() outputs "third". Do not change or remove this line.
        unique_lock<mutex> lock(mtx);
        cv.wait(lock, [this](){ return k == 2;});
        printThird();
    }
};

```

上面是力扣多线程题目 1114. 按序打印 的一片题解的条件变量解法部分，评论区中有人指出这个做法存在问题。
考虑下面的情况

![在这里插入图片描述](https://img-blog.csdnimg.cn/f2c22f74dd6f406e858ac814e00c1008.png)

由于在修改 k 的共享内存的时候没有加锁，导致线程 2 检查条件 k == 1 发现结果为 false 然后决定等待的过程中 k 的值发生改变。条件变量开始等待之前 k = 1（检查条件失效） 并且唤醒信号已经被发送（唤醒丢失）

```c++
class Foo {
    mutex mtx;
    condition_variable cv;
    int k = 0;
  
public:
    Foo() {
    }

    void first(function<void()> printFirst) {
        // printFirst() outputs "first". Do not change or remove this line.
        lock_guard<mutex> lock(mtx);
        printFirst();
        k = 1;
        cv.notify_all();
    }

    void second(function<void()> printSecond) {
    
        // printSecond() outputs "second". Do not change or remove this line.
        unique_lock<mutex> lock(mtx);
        cv.wait(lock, [this](){ return k == 1;});
        printSecond();
        k = 2;
        cv.notify_one();
        
    }

    void third(function<void()> printThird) {
        
        // printThird() outputs "third". Do not change or remove this line.
        unique_lock<mutex> lock(mtx);
        cv.wait(lock, [this](){ return k == 2;});
        printThird();
    }
};

```

#### 什么是虚假唤醒？

**什么是虚假唤醒**

当线程从等待已发出信号的条件变量中醒来，却发现它等待的条件未得到满足时，就会发生虚假唤醒。之所以称为虚假，是因为该线程似乎无缘无故地被唤醒了。但是虚假唤醒不会无缘无故发生：它们通常是因为在发出条件变量信号和等待线程最终运行之间，另一个线程运行并更改了条件。线程之间存在竞争条件，典型的结果是有时，在条件变量上唤醒的线程首先运行，赢得竞争，有时它运行第二，失去竞争。
在许多系统上，尤其是多处理器系统上，虚假唤醒的问题更加严重，因为如果有多个线程在条件变量发出信号时等待它，系统可能会决定将它们全部唤醒，将每个signal( )唤醒一个线程视为broadcast( )唤醒所有这些，从而打破了信号和唤醒之间任何可能预期的 1:1 关系。如果有 10 个线程在等待，那么只有一个会获胜，另外 9 个会经历虚假唤醒。
为了让实现在处理操作系统内部的错误条件和竞争时具有灵活性，即使没有发出信号，也可以允许条件变量从等待中返回，尽管目前尚不清楚有多少实现实际上这样做了。在条件变量的 Solaris 实现中，如果进程发出信号，则可能发生虚假唤醒而没有发出条件信号；等待系统调用中止并返回EINTR。条件变量的 Linux p-thread 实现保证它不会那样做。
因为只要有竞争甚至可能在没有竞争或信号的情况下都可能发生虚假唤醒，因此当线程在条件变量上唤醒时，它应该始终检查它所寻求的条件是否得到满足。如果不是，它应该回到条件变量上睡觉，等待另一个机会。

**虚假唤醒情况 1：notify_one 但是多线程争抢**

```c++
std::condition_variable cv;
std::mutex mx;

void thread1()
{
    while (true) {
        // do some work ...
        std::unique_lock<std::mutex> lock(mx);
        cv.notify_one();    // wake other thread
    }
}

void thread2()
{
    while (true) {
        std::unique_lock<std::mutex> lock(mx);
        cv.wait(lock);    // might block forever
        // do work ...
    }
}
```

在这里，如果有其他thread消费者thread1的通知，thread2会永久等待



**虚假唤醒情况 2 ： 系统原因**

有些操作系统为了在处理内部的错误条件和竞争时具有灵活性，即使没有发出信号，也可以允许条件变量从等待中返回。因此下面的代码在某些操作系统会存在问题（也就是唤醒丢失情况 1 当中的改进代码)

> linux 系统提供的 pthread 保证不会发生这种情况的虚假唤醒

```c++
void Consume() {
  std::unique_lock<std::mutex> lock(mutex);
  if (vec.empty()) { // 加入此判断条件，但这样虚假唤醒的问题！！！
      cv.wait(lock);
  }
  std::cout << "consume " << vec.size() << "\n";
}

void Produce() {
  std::unique_lock<std::mutex> lock(mutex);
  vec.push_back(1);
  cv.notify_all();
  std::cout << "produce \n";
}

```

我们应当使用 while 而不是 if 来判断条件

```c++
void Consume() {
  std::unique_lock<std::mutex> lock(mutex);
  while (vec.empty()) { // 使用 while 来判断条件
      cv.wait(lock);
  }
  std::cout << "consume " << vec.size() << "\n";
}
```


对于 C++ 我们可以直接将条件通过 lambda 的方式传递给条件变量，C++ 内部会自动使用 while进行判断

```c++
 while (vec.empty()) { // 使用 while 来判断条件
     cv.wait(lock);
 }
// 和下面的等效
cv.wait(lock, [](){ return vec.empty();} );
```





### 信号量

#### 记录型和整型信号量的区别与使用方法？

信号量：信号量是基于软件互斥或硬件互斥方法实现的一种用于同步和互斥的机制。信号量只有两种操作原语：wait, signal

**一.整型信号量**
整型信号量用于描述临界资源的个数。

```c
s=10; 表示一个初始资源数量为10的信号量
wait(s) {
	while (s <= 0);
	s --;
}

signal(s) {
	s ++;
}
```

缺点：违背“让权等待”的同步原则，由于当信号量所表示的资源数目<=0时，而此时该进程的时间片还未用完，便会不断运行while(s<=0)，从而造成cpu资源的浪费，违背“让权等待”的原则。

**二.记录型信号量**
为了解决整型信号量中在wait原语中违背“让权等待”的原则的问题，记录型信号量提出新的想法，设置一个阻塞队列，当s.value<=0时，便将改成挂到阻塞队列队尾，以免造成对cpu时间的浪费。
记录型信号量是一个结构题，包含对临界资源数量的描述以及阻塞队列。

```c
typedef struct semaphore {
	int value; // 描述临界资源的数量
	queue<process*> blockQue; // 阻塞队列
}sem;


void wait(sem s) {
	s.value --;
	if (s.value < 0) {
		blockQue.push(this process);
		block(blockQue);
		调用block原语，进行自我阻塞，放弃CPU的使用权
	}
}

void signal(sem s) {
	s.value ++;
	if (s.value <= 0) {
		process* head=blockQue.front();blcokQue.pop();
		wakeup(head);
		使用wakeup原语唤醒进程   阻塞态->就绪态
	}
}
```

**三.用法**
对于整型信号量：
当用于同步时，信号量的初始值设置为0。同步是为了规定不同进程的执行的先后顺序，在实际开发中，可能会有两个进程需要相互合作完成某项任务，比如，前者执行的结果是后者的初始值。

```c
int x=10;
sem s=0;

A() {
	x ++;
	v(s);
}

B() {
	p(s);
	cout << x << endl;
}
```



当用于互斥时，信号量的初始值设置为1。当信号量的初始值为1时，表示临界资源的格式为1个，当不同进程使用临界资源时，需要互斥的使用。

```c
int x=10;//临界资源
sem s=1;

A() {
	p(s);
	x ++;
	v(s);
}

B() {
	p(s);
	cout << x << endl;
	v(s);
}
```



#### 信号量机制怎么实现的？

**依靠原子操作和中断屏蔽**

为了克服忙等待需要，可以这样修改信号量操作 wait() 和 signal() 的定义：当一个进程执行操作 wait() 并且发现信号量值不为正时，它必须等待。然而，该进程不是忙等待而是阻塞自己。阻塞操作将一个进程放到与信号量相关的等待队列中，并且将该进程状态切换成等待状态。然后，控制转到 CPU 调度程序，以便选择执行另一个进程。

等待信号量 S 而阻塞的进程，在其他进程执行操作 signal() 后，应被重新执行。进程的重新执行是通过操作 wakeup() 来进行的，它将进程从等待状态改为就绪状态。然而，进程被添加到就绪队列。（取决于 CPU 调度算法，CPU 可能会也可能不会从正在运行的进程切换到新的就绪进程。）

为了实现这样定义的信号量，我们按如下定义信号量：

```c
typedef struct {
   int value;
   struct process *list;
} semaphore;
```

每个信号量都有一个整数 value 和一个进程链表 list。当一个进程必须等待信号量时，就被添加到进程链表。操作 signal() 从等待、进程链表上取走一个进程，并加以唤醒。

现在，信号量操作 wait() 可以定义如下：

```c
wait(semaphore *S) {
	S->value--;
	if (S->value < 0) {
	add this process to S->list;
	block();
	}
}
```

而信号量操作 signal() 可定义如下：

```c
signal(semaphore *S) {
	S->value++;
	if (S->value <= 0) {
    remove a process P from S->list;
   wakeup(P);
   }
}
```



操作 block() 挂起调用它的进程。操作 wakeup(P) 重新启动阻塞进程 P 的执行。这两个操作都是由操作系统作为基本系统调用来提供的。

注意，这样实现的信号量的值可以是负数，而在具有忙等待的信号量经典定义下，信号量的值不能为负。如果信号量的值为负，那么它的绝对值就是等待它的进程数。出现这种情况源于，在实现操作 wait() 时互换了递减和测试的顺序。

通过每个进程控制块 PCB 的一个链接字段，等待进程的链表可以轻松实现。每个信号量包括一个整数和一个 PCB 链表指针。向链表中增加和删除进程以便确保有限等待的一种方法采用 FIFO 队列，这里的信号量包括队列的首指针和尾指针。然而，一般来说，链表可以使用任何排队策略。信号量的正确使用不依赖于信号量链表的特定排队策略。

关键的是，信号量操作应原子执行。我们应保证：对同一信号量，没有两个进程可以同时执行操作 wait() 和 signal()。这是一个临界区问题。

对于单处理器环境，在执行操作 wait() 和 signal() 时，可以简单禁止中断。这种方案在单处理器环境下能工作，这是因为一旦中断被禁用，不同进程指令不会交织在一起。只有当前运行进程一直执行，直到中断 被重新启用并且调度程序重新获得控制。

对于多处理器环境，每个处理器的中断都应被禁止；否则，在不同处理器上不同的运行进程可能会以任意不同方式一起交织执行。每个处理器中断的禁止会很困难，也会严重影响性能。因此，SMP 系统应提供其他加锁技术，如 compare_and__swap() 或自旋锁，以确保 wait() 与 signal() 原子执行。

重要的是，对于这里定义的操作 wait() 和 signal()，我们并没有完全取消忙等待。我们只是将忙等待从进入区移到临界区。此外，我们将忙等待限制在操作 wait() 和 signal() 的临界区内，这些区比较短（如经合理编码，它们不会超过 10 条指令）。因此，临界区几乎不被占用，忙等待很少发生，而且所需时间很短。对于应用程序，存在一种完全不同的情况，即临界区可能很长（数分钟或数小时）或几乎总是被占用。在这种情况下，忙等待极为低效。

 



### 原子操作

#### 原子操作的是如何实现的？

**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。**首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。

（1）使用总线锁保证原子性 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图下图所示。

```plaintext
CPU1    CPU2
 i=1     i=1
 i+1     i+1
 i=2     i=2
```

原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。

处理器使用总线锁就是来解决这个问题的。**所谓总线锁就是使用处理器提供的一个LOCK信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。**

（2）使用缓存锁保证原子性 第二个机制是通过缓存锁定来保证原子性。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但**总线锁定把CPU和内存之间的通信锁住了**，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。

频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。

所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能使用同时缓存i的缓存行。**

但是有两种情况下处理器不会使用缓存锁定。 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。

 



### 经典问题

#### 谈谈生产者-消费者模式？

https://blog.csdn.net/xiaoqiu_cr/article/details/95756625#t5

https://blog.csdn.net/JMW1407/article/details/108487490#t0

**什么是生产者-消费者模式**

比如有两个进程A和B，它们共享一个固定大小的缓冲区，A进程产生数据放入缓冲区，B进程从缓冲区中取出数据进行计算，那么这里其实就是一个生产者和消费者的模式，A相当于生产者，B相当于消费者

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019071315322087.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9xaXVfY3I=,size_16,color_FFFFFF,t_70)

**为什么要使用生产者消费者模式**

在多线程开发中，如果生产者生产数据的速度很快，而消费者消费数据的速度很慢，那么生产者就必须等待消费者消费完了数据才能够继续生产数据，因为生产那么多也没有地方放啊；同理如果消费者的速度大于生产者那么消费者就会经常处理等待状态，所以为了达到生产者和消费者生产数据和消费数据之间的平衡，那么就需要一个缓冲区用来存储生产者生产的数据，所以就引入了生产者-消费者模式

简单来说这里的缓冲区的作用就是为了平衡生产者和消费者的处理能力，起到一个数据缓存的作用，同时也达到了一个解耦的作用

**生产者-消费者模式的特点**

* 保证生产者不会在缓冲区满的时候继续向缓冲区放入数据，而消费者也不会在缓冲区空的时候，消耗数据
* 当缓冲区满的时候，生产者会进入休眠状态，当下次消费者开始消耗缓冲区的数据时，生产者才会被唤醒，开始往缓冲区中添加数据；当缓冲区空的时候，费者也会进入休眠状态，直到生产者往缓冲区中添加数据时才会被唤醒

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019071315322087.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9xaXVfY3I=,size_16,color_FFFFFF,t_70)

**生产者-消费者模式的应用场景**

生产者-消费者模式一般用于将生产数据的一方和消费数据的一方分割开来，将生产数据与消费数据的过程解耦开来

* Excutor任务执行框架：
	通过将任务的提交和任务的执行解耦开来，提交任务的操作相当于生产者，执行任务的操作相当于消费者
	例如使用Excutor构建web服务器，用于处理线程的请求：生产者将任务提交给线程池，线程池创建线程处理任务，如果需要运行的任务数大于线程池的基本线程数，那么就把任务扔到阻塞队列（通过线程池+阻塞队列的方式比只使用一个阻塞队列的效率高很多，因为消费者能够处理就直接处理掉了，不用每个消费者都要先从阻塞队列中取出任务再执行）
* 消息中间件activeMQ:
	双十一的时候，会产生大量的订单，那么不可能同时处理那么多的订单，需要将订单放入一个队列里面，然后由专门的线程处理订单。这里用户下单就是生产者，处理订单的线程就是消费者；再比如12306的抢票功能，先由一个容器存储用户提交的订单，然后再由专门处理订单的线程慢慢处理，这样可以在短时间内支持高并发服务
* 任务的处理时间比较长的情况下：
	比如上传附近并处理，那么这个时候可以将用户上传和处理附件分成两个过程，用一个队列暂时存储用户上传的附近，然后立刻返回用户上传成功，然后有专门的线程处理队列中的附近

**生产者-消费者模式的优点**

* 解耦：将生产者类和消费者类进行解耦，消除代码之间的依赖性，简化工作负载的管理
* 复用：通过将生产者类和消费者类独立开来，那么可以对生产者类和消费者类进行独立的复用与扩展
	调整并发数：由于生产者和消费者的处理速度是不一样的，可以调整并发数，给予慢的一方多的并发数，来提高任务的处理速度
* 异步：对于生产者和消费者来说能够各司其职，生产者只需要关心缓冲区是否还有数据，不需要等待消费者处理完；同样的对于消费者来说，也只需要关注缓冲区的内容，不需要关注生产者，通过异步的方式支持高并发，将一个耗时的流程拆成生产和消费两个阶段，这样生产者因为执行put()的时间比较短，而支持高并发
* 支持分布式：生产者和消费者通过队列进行通讯，所以不需要运行在同一台机器上，在分布式环境中可以通过redis的list作为队列，而消费者只需要轮询队列中是否有数据。同时还能支持集群的伸缩性，当某台机器宕掉的时候，不会导致整个集群宕掉

#### 生产者消费者模式的实现（手搓）？

首先我们从最简单的开始，假设只有一个生产者线程执行put操作，向缓冲区中添加数据，同时也只有一个消费者线程从缓冲区中取出数据

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190713153232440.png)

UML实体关系图,从UML类图中可以看出，我们的producer和consumer类都持有一个对container对象的引用，这样的设计模式实际上在很多设计模式都有用到，比如我们的装饰者模式等等，它们共同的目的都是为了达到解耦和复用的效果

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190713153242679.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9xaXVfY3I=,size_16,color_FFFFFF,t_70)


在实现生产者-消费者模式之前我们需要搞清两个问题：

* 如何保证容器中数据状态的一致性
* 如何保证消费者和生产者之间的同步和协作关

1. 容器中数据状态的一致性：当一个consumer执行了take()方法之后，此时容器为空，但是还没来得及更新容器的size,那么另外一个consumer来了之后以为size不等于0，那么继续执行take(),从而造成了了状态的不一致性
2. 为了保证当容器里面没有数据的时候，消费者不会继续take，此时消费者释放锁，处于阻塞状态；并且一旦生产者添加了一条数据之后，此时重新唤醒消费者，消费者重新获取到容器的锁，继续执行take();

当容器里面满的时候，生产者也不会继续put, 此时生产者释放锁，处于阻塞状态；一旦消费者take了一条数据，此时应该唤醒生产者重新获取到容器的锁，继续put



所以对于该容器的任何访问都需要进行同步，也就是说在获取容器的数据之前，需要先获取到容器的锁。



#### 谈谈不同的生产者消费者模型

**单生产者单消费者 SPSC**

对于单生产者单消费者，只用保证缓冲区满的时候，生产者不会继续向缓冲区放数据，缓冲区空的时候，消费者不会继续从缓冲区取数据，而不存在同时有两个生产者使用缓冲区资源，造成数据不一致的状态。

所以对于单生产者单消费者，如果采用信号量模型来实现的话，那么只需要两个信号量：empytyCount和fullCount分别来表示缓冲区满或者空的状态，进而能够更加容易控制消费者和生产者到底什么时候处于阻塞状态，什么时候处于运行状态; 而不需要使用互斥信号量了
```C
emptyCount = N ; fullCount = 0 ;

produce:
    P(emptyCount)//信号量emptyCount减一
    putItemIntoQueue(item)//执行put操作
    V(fullCount)//信号量fullCount加一

consume:
    P(fullCount)//fullCount -= 1
    item ← getItemFromQueue()
    V(emptyCount)//emptyCount += 1
```

**多生产者单消费者 MPSC**

对于多生产者单消费者来说，多生产者之间具有互斥关系，所以这里需要一个互斥锁来实现缓冲区的互斥访问，那么具体的实现方式就是在单生产者单消费者的基础之上，加一个互斥信号量useQueue

如果采用信号量来实现的话可以如下：

```c
emptyCount = N ; fullCount = 0 ; useQueue = 1

produce:
    P(emptyCount)//信号量emptyCount减一
    P(useQueue)//二值信号量useQueue减一，变为0（其他线程不能进入缓冲区，阻塞状态）
    putItemIntoQueue(item)//执行put操作
    V(useQueue)//二值信号量useQueue加一，变为1（其他线程可以进入缓冲区）
    V(fullCount)//信号量fullCount加一

consume:
    P(fullCount)//fullCount -= 1   
    item ← getItemFromQueue()
    V(emptyCount)//emptyCount += 1
```

具体的实现和单生产者单消费者差不多，只不过在生产者类里面多加了一个互斥信号量useQueue



**单生产者多消费者 SPMC**

```C
emptyCount = N ; fullCount = 0 ; useQueue = 1
    
produce:
    P(emptyCount)//信号量emptyCount减一
    putItemIntoQueue(item)//执行put操作
    V(fullCount)//信号量fullCount加一

consume:
    P(fullCount)//fullCount -= 1   
    P(useQueue)//二值信号量useQueue减一，变为0（其他线程不能进入缓冲区，阻塞状态）
    item ← getItemFromQueue()
    V(useQueue)//二值信号量useQueue加一，变为1（其他线程可以进入缓冲区）
    V(emptyCount)//emptyCount += 1
```

具体的实现和单生产者单消费者差不多，只不过在消费者类里面多加了一个互斥信号量useQueue



**多生产者多消费者-单缓冲区 MPMC-SB**

对于多生产者多消费者问题，是一个同步+互斥问题，不仅需要生产者和消费者之间的同步协作，还需要实现对缓冲区资源的互斥访问；这个可以参考前面对生产者消费者4种实现方式

```C
emptyCount = N ; fullCount = 0 ; useQueue = 1
    
produce:
    P(emptyCount)//信号量emptyCount减一
    P(useQueue)//二值信号量useQueue减一，变为0（其他线程不能进入缓冲区，阻塞状态）
    putItemIntoQueue(item)//执行put操作
    V(useQueue)//二值信号量useQueue加一，变为1（其他线程可以进入缓冲区）
    V(fullCount)//信号量fullCount加一

consume:
    P(fullCount)//fullCount -= 1   
    P(useQueue)//二值信号量useQueue减一，变为0（其他线程不能进入缓冲区，阻塞状态）
    item ← getItemFromQueue()
    V(useQueue)//二值信号量useQueue加一，变为1（其他线程可以进入缓冲区）
    V(emptyCount)//emptyCount += 1
```



**多生产者多消费者-双缓冲区 MPMC-MB**

**为什么要用双缓冲区：读写分离减少释放锁和获取锁的开销**

用一个缓冲区，生产者和消费者需要先获取到缓冲区的锁才能进行put和take操作，每一次put和take都需要获取一次锁，这需要大量的同步与互斥操作，十分损耗性能。

所以如果采用双缓冲区的话，一个缓冲区bufferA用于生产者执行put操作，一个缓冲区bufferB用于消费者执行take操作；生产者线程和消费者线程在使用各自的缓冲区之前都需要先获取到缓冲区对应的锁，才能进行操作；

生产者和消费者各自使用自己独立的缓冲区，那么就不存在同一个缓冲区被put的同时进行take操作

所以一旦生产者和消费者一旦获取到了对应缓冲区的锁，那么每一次执行put/take操作时就不用再次重新获取锁了，从而减少了很多获取锁、释放锁的性能开销

**缓冲区的切换**

如果bufferA被put满了，那么生产者释放bufferA的锁，并等待消费者释放bufferB的锁；当bufferB被take空了，消费者释放bufferB的锁，此时生产者获取到bufferB的锁，对bufferB进行put;消费者获取到bufferA的锁，对bufferA进行take,那么就完成了一次缓冲区的切换

**双缓冲区的状态**

* 并发读写：bufferA和bufferB都处于工作状态，一个读一个写
* 单个缓冲区空闲：假设bufferA已经满了，那么生产者就会释放bufferA的锁，尝试获取bufferB，而此时bufferB还在执行take操作，消费者还没释放bufferB的锁，那么生产者进入等待状态
* 缓冲区的切换：当bufferB为空，那么此时消费者释放bufferB的锁，尝试获取bufferA的锁，此时消费者被唤醒，重新尝试获取bufferB的锁

**双缓冲区的死锁问题**

如果操作完当前的缓冲区之后，先获取另外一个缓冲区的锁，再释放当前缓冲区的锁，就会发生死锁问题。如果bufferA和bufferB的线程同时尝试获取对方的锁，那么就会一直循环等待下去

**需要注意的问题**

由于双缓冲区是为了避免每次读写的时候不用进行同步与互斥操作，所以对于一些本来就是线程安全的类例如arrayblockingqueue就不适合作为双缓冲区，因为他们内部已经实现了每次读写操作的时候进行加锁和释放

**应用场景：**

* 共享内存和共享文件
* 逻辑处理线程和IO处理线程分离。 I/0处理线程负责网络数据的发送和接收，连接的建立和维护。 逻辑处理线程处理从IO线程接收到的包。



**多生产者多消费者-环形缓冲区 MPMC-MB**

多个缓冲区构成一个缓冲池，同样需要两个同步信号量emtpyCount和fullCount，还有一个互斥信号量useQueue,同时还需要两个变量指示哪些是空缓冲区哪些是有数据的缓冲区，多缓冲区和双缓冲区一样，同样是以空间换时间，减少单个读写操作的同步与互斥操作，对于同一个缓冲区而言，不可能同时会put和take



**多生产者多消费者-环形缓冲区 MPMC-RingBuffer**

为什么要引入环形缓冲区
讨论为什么要引入环形缓冲区，其实也就是在讨论队列缓冲区有什么弊端，而环形缓冲区是如何解决这种弊端的

那么我们先认识一下什么是环形缓冲区

* 循环缓冲区的有用特性是，当使用一个循环缓冲区时，它不需要将其元素打乱。
* FIFO
* 所有的 push/pop 操作都是在一个固定的存储空间内进行，少掉了对于缓冲区元素所存储空间的分配、释放

队列缓冲区

* 如果使用非循环缓冲区，那么在使用一个缓冲区时，需要移动所有元素
* LIFO
* 在执行push和pop操作时，涉及到内存的分配与释放开销大



#### 哲学家就餐问题？

先来看看哲学家就餐的问题描述：

- `5` 个老大哥哲学家，闲着没事做，围绕着一张圆桌吃面；
- 巧就巧在，这个桌子只有 `5` 支叉子，每两个哲学家之间放一支叉子；
- 哲学家围在一起先思考，思考中途饿了就会想进餐；
- **奇葩的是，这些哲学家要两支叉子才愿意吃面，也就是需要拿到左右两边的叉子才进餐**；
- **吃完后，会把两支叉子放回原处，继续思考**；

那么问题来了，如何保证哲 学家们的动作有序进行，而不会出现有人永远拿不到叉子呢？

* 在拿叉子前，加个互斥信号量。只有一个人能吃。
* 奇数先拿左边后拿右边，偶数先拿右边后拿左边。
* 信号量给哲学家三个状态，进餐、思考、饥饿（准备拿叉子），一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。
* 集中式管理。



> 方案一

我们用信号量的方式，也就是 PV 操作来尝试解决它，代码如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/24-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%80%E7%A4%BA%E4%BE%8B.jpg)

上面的程序，好似很自然。拿起叉子用 P 操作，代表有叉子就直接用，没有叉子时就等待其他哲学家放回叉子。

![方案一的问题](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/25-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%80%E9%97%AE%E9%A2%98.jpg)

不过，这种解法存在一个极端的问题：**假设五位哲学家同时拿起左边的叉子，桌面上就没有叉子了， 这样就没有人能够拿到他们右边的叉子，也就说每一位哲学家都会在 `P(fork[(i + 1) % N ])` 这条语句阻塞了，很明显这发生了死锁的现象**。

> 方案二

既然「方案一」会发生同时竞争左边叉子导致死锁的现象，那么我们就在拿叉子前，加个互斥信号量，代码如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/26-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%BA%8C%E7%A4%BA%E4%BE%8B.jpg)

上面程序中的互斥信号量的作用就在于，**只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐。**

![方案二的问题](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/27-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%BA%8C%E9%97%AE%E9%A2%98.jpg)

方案二虽然能让哲学家们按顺序吃饭，但是每次进餐只能有一位哲学家，而桌面上是有 5 把叉子，按道理是能可以有两个哲学家同时进餐的，所以从效率角度上，这不是最好的解决方案。

> 方案三

那既然方案二使用互斥信号量，会导致只能允许一个哲学家就餐，那么我们就不用它。

另外，方案一的问题在于，会出现所有哲学家同时拿左边刀叉的可能性，那我们就避免哲学家可以同时拿左边的刀叉，采用分支结构，根据哲学家的编号的不同，而采取不同的动作。

**即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」。**

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/28-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg)

上面的程序，在 P 操作时，根据哲学家的编号不同，拿起左右两边叉子的顺序不同。另外，V 操作是不需要分支的，因为 V 操作是不会阻塞的。

![方案三可解决问题](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/29-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E4%B8%89-%E5%9B%BE%E8%A7%A3.jpg)

方案三即不会出现死锁，也可以两人同时进餐。

> 方案四

在这里再提出另外一种可行的解决方案，我们**用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。**

那么，**一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。**

第 `i` 个哲学家的左邻右舍，则由宏 `LEFT` 和 `RIGHT` 定义：

- *LEFT* : ( i + 5 - 1 ) % 5
- *RIGHT* : ( i + 1 ) % 5

比如 i 为 2，则 `LEFT` 为 1，`RIGHT` 为 3。

具体代码实现如下：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/30-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E5%9B%9B%E7%A4%BA%E4%BE%8B.jpg)

上面的程序使用了一个信号量数组，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。

注意，每个进程/线程将 `smart_person` 函数作为主代码运行，而其他 `take_forks`、`put_forks` 和 `test` 只是普通的函数，而非单独的进程/线程。

![方案四也可解决问题](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/31-%E5%93%B2%E5%AD%A6%E5%AE%B6%E8%BF%9B%E9%A4%90-%E6%96%B9%E6%A1%88%E5%9B%9B-%E5%9B%BE%E8%A7%A3.jpg)

方案四同样不会出现死锁，也可以两人同时进餐



方案五：

上面都是分布式协作的方式，实际上可以采用集中式管理，引入一个服务员，实现起来可能更加方便

#### 读者写者问题？

读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。

读者-写者的问题描述：

- 「读-读」允许：同一时刻，允许多个读者同时读
- 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
- 「写-写」互斥：没有其他写者时，写者才能写

接下来，提出几个解决方案来分析分析。

* 读优先
* 写优先
* 公平



> 方案一

使用信号量的方式来尝试解决：

- 信号量 `wMutex`：控制写操作的互斥信号量，初始值为 1 ；
- 读者计数 `rCount`：正在进行读操作的读者个数，初始化为 0；
- 信号量 `rCountMutex`：控制对 rCount 读者计数器的互斥修改，初始值为 1；

接下来看看代码的实现：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/32-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%B8%80%E7%A4%BA%E4%BE%8B.jpg)

上面的这种实现，是读者优先的策略，因为只要有读者正在读的状态，后来的读者都可以直接进入，如果读者持续不断进入，则写者会处于饥饿状态。

> 方案二

那既然有读者优先策略，自然也有写者优先策略：

- 只要有写者准备要写入，写者应尽快执行写操作，后来的读者就必须阻塞；
- 如果有写者持续不断写入，则读者就处于饥饿；

在方案一的基础上新增如下变量：

- 信号量 `rMutex`：控制读者进入的互斥信号量，初始值为 1；
- 信号量 `wDataMutex`：控制写者写操作的互斥信号量，初始值为 1；
- 写者计数 `wCount`：记录写者数量，初始值为 0；
- 信号量 `wCountMutex`：控制 wCount 互斥修改，初始值为 1；

具体实现如下代码：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/33-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%BA%8C%E7%A4%BA%E4%BE%8B.jpg)

注意，这里 `rMutex` 的作用，开始有多个读者读数据，它们全部进入读者队列，此时来了一个写者，执行了 `P(rMutex)` 之后，后续的读者由于阻塞在 `rMutex` 上，都不能再进入读者队列，而写者到来，则可以全部进入写者队列，因此保证了写者优先。

同时，第一个写者执行了 `P(rMutex)` 之后，也不能马上开始写，必须等到所有进入读者队列的读者都执行完读操作，通过 `V(wDataMutex)` 唤醒写者的写操作。

> 方案三

既然读者优先策略和写者优先策略都会造成饥饿的现象，那么我们就来实现一下公平策略。

公平策略：

- 优先级相同；
- 写者、读者互斥访问；
- 只能一个写者访问临界区；
- 可以有多个读者同时访问临界资源；

具体代码实现：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/34-%E8%AF%BB%E8%80%85%E5%86%99%E8%80%85-%E6%96%B9%E6%A1%88%E4%B8%89%E7%A4%BA%E4%BE%8B.jpg)

看完代码不知你是否有这样的疑问，为什么加了一个信号量 `flag`，就实现了公平竞争？

对比方案一的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进入读者队列， 而写者必须等待，直到没有读者到达。

没有读者到达会导致读者队列为空，即 `rCount==0`，此时写者才可以进入临界区执行写操作。

而这里 `flag` 的作用就是阻止读者的这种特殊权限（特殊权限是只要读者到达，就可以进入读者队列）。

比如：开始来了一些读者读数据，它们全部进入读者队列，此时来了一个写者，执行 `P(falg)` 操作，使得后续到来的读者都阻塞在 `flag` 上，不能进入读者队列，这会使得读者队列逐渐为空，即 `rCount` 减为 0。

这个写者也不能立马开始写（因为此时读者队列不为空），会阻塞在信号量 `wDataMutex` 上，读者队列中的读者全部读取结束后，最后一个读者进程执行 `V(wDataMutex)`，唤醒刚才的写者，写者则继续开始进行写操作。
