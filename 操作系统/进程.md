# 进程

## 问题

### 基本概念

* 什么是进程？进程与程序的区别？
* 什么是控制终端、进程组、会话？它们之间是什么关系
* 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免僵尸进程？
* 终端退出，终端运行的进程会怎样？
* 如何让进程后台运行？
* 什么是守护进程？如何创建守护进程？（手搓）

### 进程通信

* 进程间通信方式？
* 管道怎么实现的？
* 共享内存通过什么来管理，有那些 API？

### 进程调度

* 进程状态及其转换？
* 什么时候发生调度？
* 不能进行调度的情况？
* 非抢占式调度和抢占式调度区别？
* 调度算法考虑哪些原则？
* 单核 CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？
* 谈谈比例份额调度？
  * 彩票机制
  * 步长调度
  * 谈谈Linux完全公平调度？
* 谈谈多级反馈队列？
  * 没有工作长度的先验知识，如何减少响应时间和周转时间？
  * 如何设置优先级的？
  * 多级反馈队列如何配置或调优？
* 多处理器调度？
* 时间片调度的时间片如何校准时间？
* 谈谈优先级反转以及解决思路？
* Linux 如何提升进程优先级？

### 进程上下文切换

* 谈一下系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换？
* 进程在哪些场景会进行上下文切换？
* 进程上下文切换做了哪些事？流程是怎么样的？
* 上下文切换为什么资源消耗会比较高？消耗在什么地方？

### 进程控制

* 进程控制结构，包含哪些信息？
* PCB 是如何组织？几种方式优缺点（要改）
* 如何创建进程？
* 如何终止进程？
* 如何阻塞进程？
* 如何唤醒进程？
* Linux 系统如何管理进程？
* fork 和 vfork 区别
* fork,wait,exec

## 回答

## 基本概念

#### 什么是进程？进程与程序的区别？

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，**那么这个运行中的程序，就被称为「进程」（Process）**

* 程序是指令和数据的有序集合，是一个静态的概念。而进程是程序在处理机上的一次执行过程，它是一个 动态的概念。
* 程序可以作为一种软件资料长期存在，而进程是有一定生命期的。程序是永久的，进程是暂时的。
* 进程是由进程控制块、程序段、数据段三部分组成;
* 进程具有创建其他进程的功能，而程序没有。
* 同一程序同时运行于若干个数据集合上，它将属于若干个不同的进程，也就是说同一程序可以对应多个进 程。
* 在传统的操作系统中，程序并不能独立运行，作为资源分配和独立运行的基本单元都是进程。

进程是操作系统中最重要的抽象概念之一，是资源分配的基本单位，是独立运行的基本单位。

进程的经典定义就是一个执行中程序的实例。系统中的每个程序都运行在某个进程的上下文（context）中。

上下文是由程序正确运行所需的状态组成的。**这个状态包括存放在内存中的程序的代码和数据，它的栈、通用目的寄存器的内容、程序计数器、环境变量以及打开文件描述符的集合**。

进程一般由以下的部分组成：

1. 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地
 址，进程优先级、CPU现场保护区（用于进程切换），占有的资源清单等。
2. 程序段
3. 数据段

#### 什么是控制终端、进程组、会话？它们之间是什么关系

**终端**

* 在 UNIX 系统中，用户通过终端登录系统后得到一个 shell 进程，这个终端成为 shell 进程的控制终端（Controlling Terminal），进程中，控制终端是保存在 PCB 中的信息，而 fork() 会复制 PCB 中的信息，因此由 shell 进程启动的其它进程的控制终端也是这个终端。
* 默认情况下（没有重定向），每个进程的标准输入、标准输出和标准错误输出都指向控制终端，进程从标准输入读也就是读用户的键盘输入，进程往标准输出或标准错误输出写也就是输出到显示器上。
* 在控制终端输入一些特殊的控制键可以给前台进程发信号，例如 Ctrl + C 会产生 SIGINT 信号，Ctrl + \ 会产生 SIGQUIT 信号。

**进程组**

每个进程都属于一个进程组。每个进程组都有一个组长进程，组长进程的进程号等于进程组 ID。只要某个进程组中有一个进程存在，则该进程组就存在，与组长进程是否终止无关。从进程组创建开始到其中最后一个进程离开为止的时间区间成为进程组的生存期。进程组中最后一个进程可以终止或者转移到另一个进程组中。

* 进程组和会话在进程之间形成了一种两级层次关系：进程组是一组相关进程的集合，会话是一组相关进程组的集合。进程组和会话是为支持 shell 作业控制而定义的抽象概念，用户通过 shell 能够交互式地在前台或后台运行命令。
* 进行组由一个或多个共享同一进程组标识符（PGID）的进程组成。一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程 ID 为该进程组的 ID，新进程会继承其父进程所属的进程组 ID。
* 进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。一个进程可能会因为终止而退出进程组，也可能会因为加入了另外一个进程组而退出进程组。进程组首进程无需是最后一个离开进程组的成员。

**会话**

* 会话是一组进程组的集合。会话首进程是创建该新会话的进程，其进程 ID 会成为会话 ID。新进程会继承其父进程的会话 ID。
* 一个会话中的所有进程共享单个控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端
* 在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。当用户在控制终
 端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员。

* 当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程

![在这里插入图片描述](https://img-blog.csdnimg.cn/8b9b94fd6e7b45399e962e60efb2d81f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6bG856u_6ZKT6bG85bmy,size_20,color_FFFFFF,t_70,g_se,x_16)

#### 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免？

**unix提供了一种机制保证父进程知道子进程结束时的状态信息。**

这种机制是：在每个进程退出的时候，内核会释放所有的资源，包括打开的文件，占用的内存等。但是仍保留一部分信息(进程号 PID，退出状态，运行时间等)。直到父进程通过 wait 或 waitpid 来取时才释放。

但是这样就会产生问题：如果父进程不调用wait或waitpid的话，那么保留的信息就不会被释放，其进程号就会被一直占用，**但是系统所能使用的进程号是有限的，如果大量产生僵死进程，将因没有可用的进程号而导致系统无法产生新的进程，这就是僵尸进程的危害**

孤儿进程是没有父进程的进程，它由init进程循环的wait()回收资源，init进程充当父进程。因此**孤儿进程并没有什么危害。**

补充：任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程的数据结构，等待父进程去处理。**如果父进程在子进程exit()之后，没有及时处理，出现僵尸进程，并可以用ps命令去查看，它的状态是“Z”。**

**孤儿进程：**父进程结束了，而它的一个或多个子进程还在运行，那么这些子进程就成为孤儿进程(father died)。子进程的资源由init进程(进程号PID = 1)回收。

**僵尸进程：**子进程退出了，但是父进程没有用wait或waitpid去获取子进程的状态信息，那么子进程的进程描述符(包括进程号 PID，退出状态 the termination status of the process，运行时间 the amount of CPU time taken by the process 等)仍然保存在系统中，这种进程称为僵尸进程

**解决方案**

1. kill杀死元凶父进程(一般不用)
 严格的说，僵尸进程并不是问题的根源，罪魁祸首是产生大量僵死进程的父进程。因此，我们可以直接除掉元凶，通过kill发送SIGTERM或者SIGKILL信号。元凶死后，僵尸进程进程变成孤儿进程，由init充当父进程，并回收资源。

 或者运行：kill -9 父进程的pid值、（僵尸进程无法用kill直接杀死）

2. 父进程用wait或waitpid去回收资源(方案不好)
 父进程通过wait或waitpid等函数去等待子进程结束，但是不好，会导致父进程一直等待被挂起，相当于一个进程在干活，没有起到多进程的作用。

3. 通过信号机制，在处理函数中调用wait，回收资源
 通过信号机制，子进程退出时向父进程发送SIGCHLD信号，父进程调用signal(SIGCHLD,sig_child)去处理SIGCHLD信号，在信号处理函数sig_child()中调用wait进行处理僵尸进程。什么时候得到子进程信号，什么时候进行信号处理，父进程可以继续干其他活，不用去阻塞等待。

#### 终端退出，终端运行的进程会怎样？

终端在退出时会发送SIGHUP给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进 程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出

#### 如何让进程后台运行？

我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。

**1. nohup**

nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。

nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上"&"来将命令同时放入后台运行，也可用">filename 2>&1"来更改缺省的重定向文件名。

1. 安装命令（默认没有，可在usr/bin下查看是否安装成功）：

 ```java
 yum install coreutils
 1
 ```

2. 使用示例：

 ```bash
 [root@pythontab ~]# nohup ping www.baidu.com &
 [1] 3059
 nohup: appending output to `nohup.out'
 [root@pythontab ~]# ps -ef |grep 3059
 root      3059   984  0 15:06 pts/3    00:00:00 ping www.baidu.com
 root      3067   984  0 15:06 pts/3    00:00:00 grep 3059
 [root@pythontab ~]#
 1234567
 ```

**2. setsid**

nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。

setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。

```bash
[root@pythontab ~]# setsid ping www.baidu.com
[root@pythontab ~]# ps -ef |grep www.baidu.com
root     31094     1  0 07:28 ?        00:00:00 ping www.baidu.com
root     31102 29217  0 07:29 pts/4    00:00:00 grep www.baidu.com
[root@pythontab ~]#
12345
```

值得注意的是，上例中我们的进程 ID(PID)为31094，**而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。**

**3. screen**

我们已经知道了如何让进程免受 HUP 信号的影响，**但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？**

此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。

使用 screen 很方便，有以下几个常用选项：

* 用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。
* 用screen -list 来列出所有会话。
* 用screen -r session name来重新连接指定会话。
* 用快捷键CTRL-a d 来暂时断开当前会话。

screen 示例

```
[root@pvcent107 ~]# screen -dmS Urumchi
 
[root@pvcent107 ~]# screen -list
 
There is a screen on:
 
       12842.Urumchi   (Detached)
 
1 Socket in /tmp/screens/S-root.
 
  
 
[root@pvcent107 ~]# screen -r Urumchi
```

当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。

1. 未使用 screen 时新进程的进程树

```
[root@pvcent107 ~]# ping www.google.com &
 
[1] 9499
 
[root@pvcent107 ~]# pstree -H 9499
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─2*[sendmail]
 
    ├─sshd─┬─sshd───bash───pstree
 
    │       └─sshd───bash───ping

```

我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。

2. 使用了 screen 后新进程的进程树

```
[root@pvcent107 ~]# screen -r Urumchi
 
[root@pvcent107 ~]# ping www.ibm.com &
 
[1] 9488
 
[root@pvcent107 ~]# pstree -H 9488
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─screen───bash───ping
 
    ├─2*[sendmail]
```

而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。

**4. Ctrl + Z 挂起进程，然后 jobs 查看序号，再使用 bg 后台运行进程**

其他

![img](https://img2020.cnblogs.com/blog/1657559/202108/1657559-20210813165932130-69616738.png)

#### 什么是守护进程？如何创建守护进程？（手搓）

守护进程，也就是通常说的Daemon进程，是Linux中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是脱离于终端并且在后台运行的进程。守护进程脱离于终端是为了避免进程在执行过程中的信息在任何终端上显示并且进程也不会被任何终端所产生的终端信息所打断。

1. **执行一个 fork()，之后父进程退出，子进程继续执行。**

 守护进程变成孤儿进程，这样就被init进程领养，init进程成为其父进程。由于子进程会继承父进程的会话，进程组，控制终端，文件描述符等，我们要让子进程和原来的这些信息脱离。

2. **子进程调用 setsid() 开启一个新会话。**

 脱离了原来会话组、进程组、控制终端，成为新的会话组组长。（新的会话是没有控制终端的）

 第一步创建子进程的原因是： 当进程是会话组长时setsid()调用失败，两个会话里会产生同样的ID,造成冲突。

 但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。

3. **清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限**

 设置文件掩码是为了不受父进程的 umask 的影响，能自由创建读写文件和目录

4. **修改进程的当前工作目录，通常会改为根目录（/）。**

 刚启动守护进程的时候默认使用当前位置作为工作目录，如果你用U盘之类的启动就很不合理了。

5. **关闭守护进程从其父进程继承而来的所有打开着的文件描述符。**

 子进程会从父进程继承文件描述符，这些文件描述符会占用资源，因此我们最好关闭它们。至少要关闭 0,1,2 这三个文件描述符，分别对应了 stdin, stdout, 和 stderr。不过通常用 sysconf(_SC_OPEN_MAX) 获取系统允许的最大文件描述符个数，然后全部 close 掉。

6. **在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null 并使用dup2() 使所有这些描述符指向这个设备。**

 同时为了防止有些操作使用0,1,2文件描述符出问题，所以重定向到/dev/null设备

 tip：/dev/null设备会把操作给丢弃到

7. **核心业务逻辑**

```c++
/*
    写一个守护进程，每隔2s获取一下系统时间，将这个时间写入到磁盘文件中。
*/

#include <stdio.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/time.h>
#include <signal.h>
#include <time.h>
#include <stdlib.h>
#include <string.h>

void work(int num) {
    // 捕捉到信号之后，获取系统时间，写入磁盘文件
    time_t tm = time(NULL);
    struct tm * loc = localtime(&tm);
    // char buf[1024];

    // sprintf(buf, "%d-%d-%d %d:%d:%d\n",loc->tm_year,loc->tm_mon
    // ,loc->tm_mday, loc->tm_hour, loc->tm_min, loc->tm_sec);

    // printf("%s\n", buf);

    char * str = asctime(loc);
    int fd = open("time.txt", O_RDWR | O_CREAT | O_APPEND, 0664);
    write(fd ,str, strlen(str));
    close(fd);
}

int main() {

    // 1.创建子进程，退出父进程
    pid_t pid = fork();

    if(pid > 0) {
        exit(0);
    }

    // 2.将子进程重新创建一个会话
    setsid();

    // 3.设置掩码
    umask(022);

    // 4.更改工作目录
    chdir("/home/nowcoder/");

    // 5. 关闭、重定向文件描述符
    int fd = open("/dev/null", O_RDWR);
    dup2(fd, STDIN_FILENO);
    dup2(fd, STDOUT_FILENO);
    dup2(fd, STDERR_FILENO);

    // 6.业务逻辑

    // 捕捉定时信号
    struct sigaction act;
    act.sa_flags = 0;
    act.sa_handler = work;
    sigemptyset(&act.sa_mask);
    sigaction(SIGALRM, &act, NULL);

    struct itimerval val;
    val.it_value.tv_sec = 2;
    val.it_value.tv_usec = 0;
    val.it_interval.tv_sec = 2;
    val.it_interval.tv_usec = 0;

    // 创建定时器
    setitimer(ITIMER_REAL, &val, NULL);

    // 不让进程结束
    while(1) {
        sleep(10);
    }

    return 0;
}
```

### 进程通信

#### 进程间通信方式

**管道**

分为匿名管道和命名管道

* 不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作
* **管道这种通信方式效率低，不适合进程间频繁地交换数据**
* 好处：简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了
* 另外，管道传输的数据是无格式的流且大小受限

匿名管道

* 没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中
* shell 命令中的「`|`」竖线就是匿名管道
* 通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道
* **匿名管道是只能用于存在父子关系的进程间通信**
* 匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道

* 突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，**那么毫无关系的进程就可以通过这个设备文件进行通信。**`mkfifo myPipe`

**消息队列**

* 消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。

* 优点
  * 可以频繁通信了
  * 可以独立于读写进程存在，避免了 FIFO 中同步管道打开和关闭可能产生的困难
  * 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法
  * 读进程可以根据消息消息类型有选择的接受消息，而不是像 FIFO 那样默认接受

* 缺点
  * 通信不及时，**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**
  * 附件也有大小限制
  * **消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。
* 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在

**共享内存**

* **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。

* 可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。
* 但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

**信号量**

* 用来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。
* **信号量不仅可以实现访问的互斥性（1），还可以实现进程间的同步（0）**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

**信号**

* **对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

* 信号是**异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件
* 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）
* 一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。
* 有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。
* 常用信号：`kill -l` 查询
  * `Ctrl+C` 产生 `SIGINT`信号表示终止该进程
  * `Ctrl+Z`产生`SIGTSTP`信号，表示停止该进程但还没结束

**Socket**

```
int socket(int domain, int type, int protocal);
// domain:AF_INET,AF_LOCAL,AF_UNIX
// type:SOCK_STREAM,SOCK_DGRAM
// protocal:弃用填 0 即可
```

* 如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。
* Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信
* 可根据创建 Socket 的类型不同，分为三种常见的通信方式
  * 基于 TCP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_STREAM；
  * 基于 UDP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_DGRAM；
  * 本地进程间通信方式：
    * 本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM
    * 本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM
    * 另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket
    * 实现效率比 IPv4，IPv6 大很多
    * 不需要绑定 IP地址和端口，而是绑定一个本地文件

#### 管道如何实现

每个进程的用户空间都是独立的，但内核空间却是共用的。所以，进程间通信必须由内核提供服务。前面介绍了 `管道(pipe)` 的使用，接下来将会介绍管道在内核中的实现方式。

管道是由内核管理的一个缓冲区，相当于我们放入内存中的一个纸条。
管道的一端连接一个进程的输出。这个进程会向管道中放入信息。
管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。
一个缓冲区不需要很大一般为4K大小，它被设计成为环形的数据结构，以便管道可以被循环利用。
当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。
当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。
当两个进程都终结的时候，管道也自动消失。

> 本文使用 Linux-2.6.23 内核作为分析对象。

**1. 环形缓冲区（Ring Buffer）**

在内核中，`管道` 使用了环形缓冲区来存储数据。环形缓冲区的原理是：把一个缓冲区当成是首尾相连的环，其中通过读指针和写指针来记录读操作和写操作位置。如下图所示：

![img](https://pic4.zhimg.com/v2-dabc05d984f0c12152b10fd57ea3f553_b.jpg)

在 Linux 内核中，使用了 16 个内存页作为环形缓冲区，所以这个环形缓冲区的大小为 64KB（16 * 4KB）。

当向管道写数据时，从写指针指向的位置开始写入，并且将写指针向前移动。而从管道读取数据时，从读指针开始读入，并且将读指针向前移动。当对没有数据可读的管道进行读操作，将会阻塞当前进程。而对没有空闲空间的管道进行写操作，也会阻塞当前进程。

> 注意：可以将管道文件描述符设置为非阻塞，这样对管道进行读写操作时，就不会阻塞当前进程。

**2. 管道对象**

在 Linux 内核中，管道使用 `pipe_inode_info` 对象来进行管理。我们先来看看 `pipe_inode_info` 对象的定义，如下所示：

```c
struct pipe_inode_info {
    wait_queue_head_t wait;
    unsigned int nrbufs,
    unsigned int curbuf;
    ...
    unsigned int readers;
    unsigned int writers;
    unsigned int waiting_writers;
    ...
    struct inode *inode;
    struct pipe_buffer bufs[16];
};
```

下面介绍一下 `pipe_inode_info` 对象各个字段的作用：

* `wait`：等待队列，用于存储正在等待管道可读或者可写的进程。
* `bufs`：环形缓冲区，由 16 个 `pipe_buffer` 对象组成，每个 `pipe_buffer` 对象拥有一个内存页 ，后面会介绍。
* `nrbufs`：表示未读数据已经占用了环形缓冲区的多少个内存页。
* `curbuf`：表示当前正在读取环形缓冲区的哪个内存页中的数据。
* `readers`：表示正在读取管道的进程数。
* `writers`：表示正在写入管道的进程数。
* `waiting_writers`：表示等待管道可写的进程数。
* `inode`：与管道关联的 `inode` 对象。

由于环形缓冲区是由 16 个 `pipe_buffer` 对象组成，所以下面我们来看看 `pipe_buffer` 对象的定义：

```c
struct pipe_buffer {
    struct page *page;
    unsigned int offset;
    unsigned int len;
    ...
};
```

下面介绍一下 `pipe_buffer` 对象各个字段的作用：

* `page`：指向 `pipe_buffer` 对象占用的内存页。
* `offset`：如果进程正在读取当前内存页的数据，那么 `offset` 指向正在读取当前内存页的偏移量。
* `len`：表示当前内存页拥有未读数据的长度。

下图展示了 `pipe_inode_info` 对象与 `pipe_buffer` 对象的关系：

![img](https://pic2.zhimg.com/v2-d139ec66e983198cb3a8e1191999542d_b.jpg)

管道的环形缓冲区实现方式与经典的环形缓冲区实现方式有点区别，经典的环形缓冲区一般先申请一块地址连续的内存块，然后通过读指针与写指针来对读操作与写操作进行定位。

**但为了减少对内存的使用，内核不会在创建管道时就申请 64K 的内存块，而是在进程向管道写入数据时，按需来申请内**存。

那么当进程从管道读取数据时，内核怎么处理呢？下面我们来看看管道读操作的实现方式。

**3. 读操作**

从 `经典的环形缓冲区` 中读取数据时，首先通过读指针来定位到读取数据的起始地址，然后判断环形缓冲区中是否有数据可读，如果有就从环形缓冲区中读取数据到用户空间的缓冲区中。如下图所示：

![img](https://pic2.zhimg.com/v2-3febc9c9ed243d11ff0370eeaa494181_b.jpg)

而 `管道的环形缓冲区` 与 `经典的环形缓冲区` 实现稍有不同，`管道的环形缓冲区` 其读指针是由 `pipe_inode_info` 对象的 `curbuf` 字段与 `pipe_buffer` 对象的 `offset` 字段组合而成：

* `pipe_inode_info` 对象的 `curbuf` 字段表示读操作要从 `bufs` 数组的哪个 `pipe_buffer` 中读取数据。
* `pipe_buffer` 对象的 `offset` 字段表示读操作要从内存页的哪个位置开始读取数据。

读取数据的过程如下图所示：

![img](https://pic4.zhimg.com/v2-3c326682792950683e50b7071ebd6d17_b.jpg)

从缓冲区中读取到 n 个字节的数据后，会相应移动读指针 n 个字节的位置（也就是增加 `pipe_buffer` 对象的 `offset` 字段），并且减少 n 个字节的可读数据长度（也就是减少 `pipe_buffer` 对象的 `len` 字段）。

当 `pipe_buffer` 对象的 `len` 字段变为 0 时，表示当前 `pipe_buffer` 没有可读数据，那么将会对 `pipe_inode_info` 对象的 `curbuf` 字段移动一个位置，并且其 `nrbufs` 字段进行减一操作。

我们来看看管道读操作的代码实现，读操作由 `pipe_read` 函数完成。为了突出重点，我们只列出关键代码，如下所示：

```c
static ssize_t
pipe_read(struct kiocb *iocb, const struct iovec *_iov, unsigned long nr_segs,
          loff_t pos)
{
    ...
    struct pipe_inode_info *pipe;

    // 1. 获取管道对象
    pipe = inode->i_pipe;

    for (;;) {
        // 2. 获取管道未读数据占有多少个内存页
        int bufs = pipe->nrbufs;

        if (bufs) {
            // 3. 获取读操作应该从环形缓冲区的哪个内存页处读取数据
            int curbuf = pipe->curbuf;  
            struct pipe_buffer *buf = pipe->bufs + curbuf;
            ...

            /* 4. 通过 pipe_buffer 的 offset 字段获取真正的读指针,
             *    并且从管道中读取数据到用户缓冲区.
             */
            error = pipe_iov_copy_to_user(iov, addr + buf->offset, chars, atomic);
            ...

            ret += chars;
            buf->offset += chars; // 增加 pipe_buffer 对象的 offset 字段的值
            buf->len -= chars;    // 减少 pipe_buffer 对象的 len 字段的值

            /* 5. 如果当前内存页的数据已经被读取完毕 */
            if (!buf->len) {
                ...
                curbuf = (curbuf + 1) & (PIPE_BUFFERS - 1);
                pipe->curbuf = curbuf; // 移动 pipe_inode_info 对象的 curbuf 指针
                pipe->nrbufs = --bufs; // 减少 pipe_inode_info 对象的 nrbufs 字段
                do_wakeup = 1;
            }

            total_len -= chars;

            // 6. 如果读取到用户期望的数据长度, 退出循环
            if (!total_len)
                break;
        }
        ...
    }

    ...
    return ret;
}
```

上面代码总结来说分为以下步骤：

* 通过文件 `inode` 对象来获取到管道的 `pipe_inode_info` 对象。
* 通过 `pipe_inode_info` 对象的 `nrbufs` 字段获取管道未读数据占有多少个内存页。
* 通过 `pipe_inode_info` 对象的 `curbuf` 字段获取读操作应该从环形缓冲区的哪个内存页处读取数据。
* 通过 `pipe_buffer` 对象的 `offset` 字段获取真正的读指针， 并且从管道中读取数据到用户缓冲区。
* 如果当前内存页的数据已经被读取完毕，那么移动 `pipe_inode_info` 对象的 `curbuf` 指针，并且减少其 `nrbufs` 字段的值。
* 如果读取到用户期望的数据长度，退出循环。

**4. 写操作**

分析完管道读操作的实现后，接下来，我们分析一下管道写操作的实现。

`经典的环形缓冲区` 写入数据时，首先通过写指针进行定位要写入的内存地址，然后判断环形缓冲区的空间是否足够，足够就把数据写入到环形缓冲区中。如下图所示：

![img](https://pic4.zhimg.com/v2-22a142fb53114fc696e31096b1513e6b_b.jpg)

但 `管道的环形缓冲区` 并没有保存 `写指针`，而是通过 `读指针` 计算出来。那么怎么通过读指针计算出写指针呢？

其实很简单，就是：

> 写指针 = 读指针 + 未读数据长度

下面我们来看看，向管道写入 200 字节数据的过程示意图，如下所示：

如上图所示，向管道写入数据时：

![img](https://pic2.zhimg.com/v2-cd84a6f08ccc625083d3e1ec79825531_b.jpg)

* 首先通过 `pipe_inode_info` 的 `curbuf` 字段和 `nrbufs` 字段来定位到，应该向哪个 `pipe_buffer` 写入数据。
* 然后再通过 `pipe_buffer` 对象的 `offset` 字段和 `len` 字段来定位到，应该写入到内存页的哪个位置。

下面我们通过源码来分析，写操作是怎么实现的，代码如下（为了特出重点，代码有所删减）：

```c
static ssize_t
pipe_write(struct kiocb *iocb, const struct iovec *_iov, unsigned long nr_segs,
           loff_t ppos)
{
    ...
    struct pipe_inode_info *pipe;
    ...
    pipe = inode->i_pipe;
    ...
    chars = total_len & (PAGE_SIZE - 1); /* size of the last buffer */

    // 1. 如果最后写入的 pipe_buffer 还有空闲的空间
    if (pipe->nrbufs && chars != 0) {
        // 获取写入数据的位置
        int lastbuf = (pipe->curbuf + pipe->nrbufs - 1) & (PIPE_BUFFERS-1);
        struct pipe_buffer *buf = pipe->bufs + lastbuf;
        const struct pipe_buf_operations *ops = buf->ops;
        int offset = buf->offset + buf->len;

        if (ops->can_merge && offset + chars <= PAGE_SIZE) {
            ...
            error = pipe_iov_copy_from_user(offset + addr, iov, chars, atomic);
            ...
            buf->len += chars;
            total_len -= chars;
            ret = chars;

            // 如果要写入的数据已经全部写入成功, 退出循环
            if (!total_len)
                goto out;
        }
    }

    // 2. 如果最后写入的 pipe_buffer 空闲空间不足, 那么申请一个新的内存页来存储数据
    for (;;) {
        int bufs;
        ...
        bufs = pipe->nrbufs;

        if (bufs < PIPE_BUFFERS) {
            int newbuf = (pipe->curbuf + bufs) & (PIPE_BUFFERS-1);
            struct pipe_buffer *buf = pipe->bufs + newbuf;
            ...

            // 申请一个新的内存页
            if (!page) {
                page = alloc_page(GFP_HIGHUSER);
                ...
            }
            ...
            error = pipe_iov_copy_from_user(src, iov, chars, atomic);
            ...
            ret += chars;

            buf->page = page;
            buf->ops = &anon_pipe_buf_ops;
            buf->offset = 0;
            buf->len = chars;

            pipe->nrbufs = ++bufs;
            pipe->tmp_page = NULL;

            // 如果要写入的数据已经全部写入成功, 退出循环
            total_len -= chars;
            if (!total_len)
                break;
        }
        ...
    }

out:
    ...
    return ret;
}
```

上面代码有点长，但是逻辑却很简单，主要进行如下操作：

* 如果上次写操作写入的 `pipe_buffer` 还有空闲的空间，那么就将数据写入到此 `pipe_buffer` 中，并且增加其 `len` 字段的值。
* 如果上次写操作写入的 `pipe_buffer` 没有足够的空闲空间，那么就新申请一个内存页，并且把数据保存到新的内存页中，并且增加 `pipe_inode_info` 的 `nrbufs` 字段的值。
* 如果写入的数据已经全部写入成功，那么就退出写操作。

#### 共享内存通过什么来管理，有那些 API？

共享内存需要配合信号量来管理

**创建共享内存**

```c++
#include <sys/ipc.h>
#include <sys/shm.h>

int shmget(key_t key, size_t size,int shmflg);
/*
创建或打开一块共享内存区。
参数：
key：进程间通信键值，ftok() 的返回值。
size：该共享存储段的长度(字节)。
shmflg：标识函数的行为及共享内存的权限，其取值如下：
 IPC_CREAT：如果不存在就创建
 IPC_EXCL： 如果已经存在则返回失败位或权限位：共享内存位或权限位后可以设置共享内存的访问权限，格式和 open() 函数的 mode_t 一样（open() 的使用请点此链接），但可执行权限未使用。
返回值：
 成功：共享内存标识符。
 失败：-1。
*/
```

```c++
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>
 
#define BUFSZ 1024
 
int main(int argc, char *argv[]) {
 int shmid;
 key_t key;
 
 key = ftok("./", 2015); 
 if(key == -1)
 {
  perror("ftok");
 }
 
 //创建共享内存
 shmid = shmget(key, BUFSZ, IPC_CREAT|0666); 
 if(shmid < 0) { 
  perror("shmget"); 
  exit(-1); 
 } 
 
 return 0;
}
```

运行结果如下：

![img](https://pic2.zhimg.com/v2-8108c55cd015c8282af81fc37f467249_b.jpg)

**共享内存映射**

```c++
#include <sys/types.h>
#include <sys/shm.h>
void *shmat(int shmid, const void *shmaddr, int shmflg);

/*
将一个共享内存段映射到调用进程的数据段中。简单来理解，让进程和共享内存建立一种联系，让进程某个指针指向此共享内存。

参数：
shmid：共享内存标识符，shmget() 的返回值。
shmaddr：共享内存映射地址(若为 NULL 则由系统自动指定)，推荐使用 NULL。
shmflg：共享内存段的访问权限和映射条件( 通常为 0 )，具体取值如下：
 0：共享内存具有可读可写权限。
 SHM_RDONLY：只读。
 SHM_RND：（shmaddr 非空时才有效）
返回值：
 成功：共享内存段映射地址( 相当于这个指针就指向此共享内存 )
 失败：-1
*/
```

**解除共享内存映射**

```c++
#include <sys/types.h>
#include <sys/shm.h>

int shmdt(const void *shmaddr);
/*
将共享内存和当前进程分离( 仅仅是断开联系并不删除共享内存，相当于让之前的指向此共享内存的指针，不再指向)。

参数：
shmaddr：共享内存映射地址。
返回值：
 成功：0
 失败：-1
*/
```

**共享内存控制**

```c++
#include <sys/ipc.h>
#include <sys/shm.h>

int shmctl(int shmid, int cmd, struct shmid_ds *buf);
/*
共享内存属性的控制。

参数：
shmid：共享内存标识符。
cmd：函数功能的控制，其取值如下：
 IPC_RMID：删除。(常用 )
 IPC_SET：设置 shmid_ds 参数，相当于把共享内存原来的属性值替换为 buf 里的属性值。
 IPC_STAT：保存 shmid_ds 参数，把共享内存原来的属性值备份到 buf 里。
 SHM_LOCK：锁定共享内存段( 超级用户 )。
 SHM_UNLOCK：解锁共享内存段。
 SHM_LOCK 用于锁定内存，禁止内存交换。并不代表共享内存被锁定后禁止其它进程访问。其真正的意义是：被锁定的内存不允许被交换到虚拟内存中。这样做的优势在于让共享内存一直处于内存中，从而提高程序性能。
buf：shmid_ds 数据类型的地址(具体类型请点此链接 )，用来存放或修改共享内存的属性。

返回值：
 成功：0
 失败：-1
*/
```

**实战示例**

接下来我们做这么一个例子：创建两个进程，在 A 进程中创建一个共享内存，并向其写入数据，通过 B 进程从共享内存中读取数据。

写端代码如下：

```c++
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>
 
#define BUFSZ 512
 
int main(int argc, char *argv[])
{
 int shmid;
 int ret;
 key_t key;
 char *shmadd;
 
 //创建key值
 key = ftok("../", 2015); 
 if(key == -1)
 {
  perror("ftok");
 }
 
 //创建共享内存
 shmid = shmget(key, BUFSZ, IPC_CREAT|0666); 
 if(shmid < 0) 
 { 
  perror("shmget"); 
  exit(-1); 
 }
 
 //映射
 shmadd = shmat(shmid, NULL, 0);
 if(shmadd < 0)
 {
  perror("shmat");
  _exit(-1);
 }
 
 //拷贝数据至共享内存区
 printf("copy data to shared-memory\n");
 bzero(shmadd, BUFSZ); // 共享内存清空
 strcpy(shmadd, "how are you, mike\n");
 
 return 0;
}
```

读端代码如下：

```c++
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/shm.h>
 
#define BUFSZ 512
 
int main(int argc, char *argv[])
{
 int shmid;
 int ret;
 key_t key;
 char *shmadd;
 
 //创建key值
 key = ftok("../", 2015); 
 if(key == -1)
 {
  perror("ftok");
 }
 
 system("ipcs -m"); //查看共享内存
 
 //打开共享内存
 shmid = shmget(key, BUFSZ, IPC_CREAT|0666);
 if(shmid < 0) 
 { 
  perror("shmget"); 
  exit(-1); 
 } 
 
 //映射
 shmadd = shmat(shmid, NULL, 0);
 if(shmadd < 0)
 {
  perror("shmat");
  exit(-1);
 }
 
 //读共享内存区数据
 printf("data = [%s]\n", shmadd);
 
 //分离共享内存和当前进程
 ret = shmdt(shmadd);
 if(ret < 0)
 {
  perror("shmdt");
  exit(1);
 }
 else
 {
  printf("deleted shared-memory\n");
 }
 
 //删除共享内存
 shmctl(shmid, IPC_RMID, NULL);
 
 system("ipcs -m"); //查看共享内存
 
 return 0;
}
```

运行结果如下：

![img](https://pic3.zhimg.com/v2-ea961b44c86d0b293bee95b83d730d06_b.jpg)

### 进程调度

#### 进程状态

在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。

它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

上图中各个状态的意义：

* 运行状态（*Running*）：该时刻进程占用 CPU；
* 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
* 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

* 创建状态（*new*）：进程正在被创建时的状态；
* 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

再来详细说明一下进程的状态变迁：

* *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
* *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
* *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
* *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
* *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
* *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
* *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。

所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

![虚拟内存管理-换入换出](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/9-%E6%8D%A2%E5%85%A5%E6%8D%A2%E5%87%BA.jpg)

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。

另外，挂起状态可以分为两种：

* 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
* 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

这两种挂起状态加上前面的五种状态，就变成了七种状态变迁（留给我的颜色不多了），见如下图：

![七种状态变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg)

导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

* 通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。
* 用户希望挂起一个程序的执行，比如在 Linux 中用 `Ctrl+Z` 挂起进程；

#### 什么时候发生调度？

1. 当前运行的进程运行结束。
2. 当前运行的进程由于某种原因阻塞。
3. 执行完系统调用等系统程序后返回用户进程。
4. 在使用抢占调度的系统中，具有更高优先级的进程就绪时。
5. 分时系统中，分给当前进程的时间片用完。

#### 不能进行调度的情况？

1. 在中断处理程序执行时。
2. 在操作系统的内核程序临界区内。
3. 其它需要完全屏蔽中断的原子操作过程中。

#### 非抢占式调度和抢占式调度区别？

如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

* **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
* **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

#### 调度算法考虑哪些原则？

* **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
* **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
* **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
* **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
* **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。
* 确保每个工作获得一定比例的 CPU 时间（比例份额调度的特殊要求）

#### 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？

**先来先服务调度算法**

最简单的一个调度算法，就是非抢占式的**先来先服务（First Come First Severd, FCFS）算法**了。

![FCFS 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg)

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

**最短作业优先调度算法**

**最短作业优先（Shortest Job First, SJF）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

**高响应比优先调度算法**

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （Highest Response Ratio Next, HRRN）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)

从上面的公式，可以发现：

* 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
* 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

**时间片轮转调度算法**

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（Round Robin, RR）调度算法**。

![RR 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg)

**每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。**

* 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
* 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

* 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
* 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

**最高优先级调度算法**

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

* 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
* 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

* 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
* 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 比例份额调度算法

**基本概念：票数代表份额**

* 每个进程持有一些彩票号，调度程序每一次调度时，进行抽奖，持有开奖号数的进程被调度
* 利用了随机性，可以避免很多最差的情况

**彩票机制**

* 彩票货币：每个用户可以有自己的货币，最后再转换成调度程序的货币
* 彩票转让：进程可以临时将自己的彩票交给另一个进程
* 彩票膨胀：一个进程可以临时提升或降低彩票数量。只有进程相互信任的环境才有意义。

**步长调度**

* 每个工作都有步长，步长等于一个大数除以它的票数
* 每个进程都有行程值，每次调度完一个进程后，行程值增加它的步长
* 每次调度选择拥有最小行程值的进程
* 与彩票机制调度不同的是，由于彩票机制使用了随机性，所以可能无法提供正确的比例，特别是在短时间内发生的调度行为，而步长调度则是能够确保这种比例
* 而步长调度的缺点则是，在新进程加入时，它的行程值为0，会使得它长时间独占CPU

**问题**
如何分配票数？这个问题非常难解决，因此比例份额调度只有在容易确定份额的场景下才适用。

---

**Linux完全公平调度（CFS）**

**基本操作**
尽管大多数调度程序都是基于固定时间片的概念，但 CFS 的操作有所不同。它的目标很简单：**在所有竞争的进程之间平均分配 CPU。它通过称为虚拟运行时（vruntime）的基于计数的简单技术来实现。**
在每个进程运行时，它将积累 vruntime。在最基本的情况下，每个进程的虚拟运行时以相同的速率增长，与物理（实时）时间成比例。当发生调度决策时，CFS 将选择运行 vruntime最低的进程。
这就引出了一个问题：调度程序应该何时停止当前正在运行的进程，然后运行下一个进程？这里的压力很明显：如果CFS切换得太频繁，公平性就会增加，因为 CFS 将确保每个进程即使在很小的时间窗口内也能获得其 CPU 的份额，但是会以性能为代价（上下文切换过多）；如果CFS切换的频率较低，则性能会提高（上下文切换减少），但会以近期的公平为代价。CFS 通过各种控制参数来管理这种压力。

**调度延迟（sched_latency）**

 CFS 使用此值来确定在考虑切换之前一个进程应运行多长时间（以动态方式有效地确定其时间段）。典型的调度延迟时间值为48（毫秒）。 CFS将该值除以CPU上正在运行的进程数（n）来确定一个进程的时间片，从而确保在这段时间内 CFS 将完全公平。
例如，如果正在运行 n = 4 个进程，则 CFS 将调度延迟时间的值除以 n，得出每个进程的时间片为12 ms。然后，CFS 调度第一个任务并运行它，直到它使用了12毫秒的（虚拟）运行时为止，然后检查是否有一个具有较低 vruntime 的任务要运行。在这种情况下，CFS 将切换到其他三个任务之一，依此类推。下图显示了一个示例，其中四个任务（A，B，C，D）以这种方式分别运行两个时间片。然后，其中两个（C，D）完成，仅剩下两个，然后以循环方式分别运行24 ms。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917231054521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

但是，如果运行的进程“太多”怎么办？那会不会导致时间片太小，从而导致上下文切换过多？

**最小粒度**

为了解决此问题，CFS 添加了另一个参数最小粒度，通常设置为6 ms之类的值。CFS永远不会将时间片设置小于该值，从而确保在调度开销方面不会花费太多时间。
例如，如果有十个进程在运行，我们的原始计算将调度的延迟除以十来确定时间片（结果：4.8毫秒）。但是，由于最小粒度，CFS会将每个进程的时间片设置为6ms。尽管CFS在48毫秒的目标调度延迟（调度延迟）上并不能（完全）公平，但在达到较高CPU效率的同时，它还是很接近的。
注意，CFS利用了周期性的计时中断，这意味着它只能以固定的时间间隔做出决定。该中断频繁关闭（例如，每1毫秒一次），使CFS有机会唤醒并确定当前任务是否已运行结束。如果任务的时间片不是计时中断间隔的完美倍数，则没问题； CFS精确跟踪vruntime，这意味着从长远来看，它将最终接近理想的CPU共享。

**加权（精细度）**
CFS还可以控制进程优先级，从而使用户或管理员可以为某些进程分配更高的 CPU 份额。它不使用票而是通过经典的UNIX机制（称为进程的nice级别）来完成的。可以将一个进程的nice参数设置为-20到+19之间的任意值，默认值为0。正的nice值表示优先级较低，而负的值表示优先级较高。
CFS将每个进程的nice值映射到权重，如下所示：

```
static const int prio_to_weight[40] = {
 /* -20 */ 88761, 71755, 56483, 46273, 36291,
 /* -15 */ 29154, 23254, 18705, 14949, 11916,
 /* -10 */ 9548, 7620, 6100, 4904, 3906,
 /* -5 */  3121, 2501, 1991, 1586, 1277,
 /* 0 */   1024, 820, 655, 526, 423,
 /* 5 */   335, 272, 215, 172, 137,
 /* 10 */  110, 87, 70, 56, 45,
 /* 15 */  36, 29, 23, 18, 15,
};
```

这些权重使我们能够计算每个进程的有效时间片（就像我们之前所做的一样），但是现在考虑了它们的优先级差异。这样做的公式如下：$\frac{weight_k}{\sum\limits^{n-1}_{i=0}weight_i}*sched\_latency$

让我们看一个例子，看看它是如何工作的。假设有两个任务，A和B。A，因为它是我们最宝贵的工作，被赋予了更高的优先级，所以分配给它的nice值-5；B，因为我们讨厌它，所以它具有默认优先级（nice值等于0）。这意味着 $weight_A$ 为3121，而$weight_B$ 为1024。然后，计算每个任务的时间片，A的时间片约为调度延迟的 $\frac{3}{4} $ （因此为36毫秒），而B的时间片约为$\frac{1}{4} $（因此为12毫秒）。
除了概括时间片计算之外，还必须调整 CFS 计算 vruntime 的方式。这是新的公式，它采用进程 $i $累计的实际运行时间（$runtime_i$），并按进程的权重进行反比例缩放。在我们的运行示例中，A的 vruntime 将以B的速度的三分之一累积。$vruntime_i=vruntime_i+\frac{weight_0}{weight_i}*runtime_i$ 上面的权重表的构造的一个明智的方面是，当nice值的差异恒定时，该表保留CPU比例比率。例如，如果进程A的nice值为5（不是-5），而进程B的nice值为10（不是0），则CFS将以与以前完全相同的方式调度它们。

**使用红黑树**
如上所述，CFS的一个主要重点是效率。对于调度程序而言，效率有很多方面，但是其中一个方面是如此简单：当调度程序必须找到要运行的下一个任务时，它应该尽快完成。像列表这样的简单数据结构无法扩展：现代系统有时由数千个进程组成，因此每隔几毫秒搜索一个长列表是很浪费的。
CFS通过将进程保存在红黑树中来解决此问题。红黑树是许多平衡树中的一种。与简单的二叉树（在最坏情况下的插入操作性能可能退化为类似链表的性能）相比，平衡树做了一些额外的工作来保持较低的深度，从而确保操作在时间上是对数级别的（而不是线性的）。
**CFS不会将所有进程都保留在此结构中，而是仅将运行（或可运行）的进程保留在其中。如果某个进程进入睡眠状态（例如，等待I / O完成，或者等待网络数据包到达），则将其从树中删除并跟踪其他位置。**
让我们看一个例子。假设有十个任务，并且它们具有以下vruntime值：1、5、9、10、14、18、17、21、22和24。如果我们将这些任务保留在有序列表中，查找下一个要运行的任务很简单：只需删除第一个元素。但是，当将该任务放回列表中时（按顺序），我们要扫描列表，寻找正确的位置将其插入，这是一个O（n）的操作。任何查找的效率也很低，平均也要花费线性时间。
在红黑树中保持相同的值可以使大多数操作更高效，如图所示。进程按 vruntime 在树中排序，并且大多数操作（例如插入和删除）在时间上都是对数的，即O（log n）。当n上千时，对数的效率明显高于线性的效率。

![img](https://img-blog.csdnimg.cn/20200917235919529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

**处理I / O和睡眠进程**
选择最低 vruntime 的进程来运行导致的一个问题是长期处于休眠状态的任务。想象一下两个进程，A 和 B，其中一个（A）连续运行，另一个（B）长时间睡眠（例如10秒）。当B醒来时，其 vruntime 将比A的运行时间晚10秒，因此（如果我们不小心的话），B现在会在接下来的10秒钟内独占CPU，使A饥饿。
CFS 通过在任务唤醒时更改其 vruntime 来处理这种情况。**具体来说，CFS 将该任务的 vruntime 设置为在树中找到的最小值（请记住，该树仅包含正在运行的任务）。这样，CFS避免了饥饿，但并非没有代价：短时间内频繁睡眠的任务经常无法获得应有的 CPU 份额。**

**CFS其他有趣的功能**
CFS具有许多其他功能，它包括多种启发式方法，可以提高缓存性能，具有有效处理多CPU的策略，可以跨大组进程进行调度（而不是将每个进程视为一个独立的实体），以及许多其他有趣的功能。

**总结**
我们介绍了比例分配调度的概念，并简要讨论了三种方法：彩票调度，步长调度和Linux的完全公平调度（CFS）。彩票调度巧妙地利用随机性来实现比例分配。步长调度非常具有确定性。 CFS是本章中讨论的唯一“真正的”调度程序，有点像带有动态时间片的加权循环调度，但是可以在负载下扩展和运行良好。据说，它是当今最广泛使用的公平份额调度程序。
没有调度程序是万能的灵丹妙药，公平份额的调度程序也有很多问题。
一个问题是这种方法不能与I / O很好地融合在一起；如上所述，偶尔执行I / O的任务可能无法公平得到CPU。另一个问题是，它们没有解决票或优先级分配的难题，即如何知道应该分配浏览器程序多少票，或者如何设置文本编辑器的nice值？其他通用调度程序（例如前面讨论的MLFQ和其他类似的Linux调度程序）会自动处理这些问题，因此可能更易于部署。
好消息是，在许多领域中，这些问题并不是主要问题，并且比例份额调度程序可发挥巨大作用。例如，在虚拟数据中心（或云）中，你可能希望将四分之一的CPU周期分配给Windows VM，其余的分配给基本的Linux安装，比例份额可以变得简单而有效。这个想法也可以扩展到其他资源。

#### 多级反馈队列调度

**多级反馈队列调度算法**（无先验经验）

**多级反馈队列（Multilevel Feedback Queue）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

* 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
* 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)

来看看，它是如何工作的：

* 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
* 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
* 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

#### 多处理器调度？

**单队列**

![img](https://pic4.zhimg.com/v2-f424f5893cd3bbdd49ebb77c8c70c3bf_b.jpg)

这种形式不需要在单处理器的框架下做太多改动，**同样的是维护一个进程的全局就绪队列，为所有 CPU 共享。运行在 CPU 上的调度程序从这个队列中挑选合适的进程执行。**

**特点**：

* 实现较简单，对所有的 CPU 来说很公平。
* 这个队列是全局共享的，所以当一个 CPU 挑选进程时需要加锁，不然多个 CPU 就可能选取同一个进程。但是锁机制不可避免带来额外的开销使得性能降低，可扩展性降低。
* 处理器亲和性(Processor Affinity)不容易实现，处理器亲和性是系统提供给用户的一种选择，用户可以指定特定的处理器来执行进程。
* 每个处理器都有自己的缓存，处理器亲和性不好，一个进程可能在多个处理器之间来回运行，使得处理器的缓存无效，所以缓存亲和性也不好，性能较为低下。

**多队列**

![img](https://pic4.zhimg.com/v2-af9ad1b1877b020d9412a56a0ff72877_b.jpg)

如上图所示：**每个 CPU 都有自己单独的调度队列**。每个 CPU 只在自己本地的队列中挑选合适的进程，速度很快。

**队列之间的调度相互独立**，可不再使用锁机制，可扩展性增强，比如每个队列可使用不同的调度算法。

**所有的任务工作都能在固定的 CPU 上执行，能够很好的利用缓存数据**。

**但是也有明显缺点：各个 CPU 的负载不均衡**，从上图就可以看出 CPU2 负载较大，而 CPU3 负载较小

**解决负载均衡的办法叫做迁移(Migration)，从繁忙 CPU 的队列中迁移一些进程到空闲 CPU 中去**。

#### 谈谈优先级反转以及解决思路？

**什么是优先级反转**
优先级反转是指使用信号量时，出现的一种不合理的反常现象，既是一个 高优先级任务 试图通过信号量机制访问某个共享资源时，哎，发现这个资源已经被低优先级任务占有。

人家抢先了就只能等呗，但是这就导致了低优先级任务 阻塞高优先级任务的现象，导致 高优先级任务 被 低优先级任务 阻塞，影响了 高优先级任务 的实时性。

最坏的情况下在 高优先级任务 等待低优先级任务的时候，出现一个中优先级任务，中优先级任务卡住了低优先级任务，却在被 高优先级任务 卡住，这就出现了类似死锁的情况发生。

系统运行对时间要求非常严格，如果因为某些问题导致系统时间延迟有误差，可能会导致比较严重的问题，这种情况在实时系统中会更严重。

![图片](https://mmbiz.qpic.cn/mmbiz_png/Qof5hj3zMPe0ZReyzKfI0yicdicFjowJDcxMswOF30AxPZnC2MoEWial34GMia8HnNmX2PaBr5A0J4SemxuZicWiaPNA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

A和C共享一个资源，但是在运行过程中，在某一个时刻，C占有资源的时候，被高于它优先级的进程B抢占了，这时候B就处于一个有利位置，一直会有CPU运行，如果有其他进程优先级高于C的，也会能拿到CPU运行。

这就出现了一个奇怪的现象，**低优先级的进程抢占了高优先级的进程，如果A是特斯拉的刹车进程的话，我相信故障就此发生。**

**如何解决优先级翻转的问题呢？**

提升C的优先级，让C的优先级高于B，就不会存在持有锁的情况下被抢占。

但是C的优先级提升到多少合适呢？

假设共享资源R，有5个任务会申请它，我们需要做的是，持有R资源的任务的优先级是这5个任务中最高的，这就叫**优先级提升**。

**解决方法 1 ：优先权极限**
在优先权极限方案中，系统把每一个临界资源与1个极限优先权相联系。这个极限优先权等于系统此时最高优先权加1。当1个任务进入临界区时，系统便把这个极限 优先权传递给这个任务，使得这个任务的优先权最高；
当这个任务退出临界区后，系统立即把它的优先权恢复正常，从而保证系统不会出现优先权反转的情况。如上例中，当 低优先权任务 进入临界区时，立即把它的优先权升高到极限优先权，保证低优先权任务 此时能尽快退出临界区，进而释放其占有的信号量。当 高优先级任务 执行的时候就不会出现其等待 低优先级任务 释放信号量而被阻塞的情况，从而保证不会出现上面所说的优先级反转。采用这种方案的另一个有利之处，是仅仅通过改变某个临界资源的优先级就可以使多个任务共享这个临界资源

**解决方法 2 ：优先级继承**
在优先级继承方案中，大致原理是让低优先级线程在获得同步资源的时候(如果有高优先级的线程也需要使用该同步资源时)，临时提升其优先级。以前其能更快的执行并释放同步资源。释放同步资源后再恢复其原来的优先级。

当 高优先级任务 想要进入临界区时，由于 低优先级任务 占有这个临界资源的信号量，导致 高优先级任务 被阻塞。这时候，系统把 低优先级任务 的优先权升到 高优先级任务 的优先级，此时优先级处于 低优先级任务 和 高优先级任务 之间的任务 中优先级任务，即使处于就绪状态也不可以被调度执行，因为此时低优先级任务 的优先权已经高于 中优先级任务，所以低优先级任务 此时被调度执行。当 低优先级任务 释放 高优先级任务 需要的信号量时，系统立即把 低优先级任务 的优先权降到原 来的高度，来保证task1和task2正常有序执行。
于是只有中优先级受伤的世界出现了

#### Linux 如何提升进程优先级？

Linux系统进程的优先级取值：-20 到 19，数越大优先级越低。

可以通过top命令来查看，NI那一列。

改变进程的优先级的方法有两种：

* top命令。输入r，然后根据提示输入进程ID，再输入优先级数值。
* renice命令。renice -n 2 -p 3432。-n，后面是优先级的值；-p，是进程号。

另外：

在嵌入式Linux系统中，大多都是跑一个核心的业务，在数据吞吐量大的时候，会大量占用CPU，导致数据处理不过来，常规办法是优化程序或者更换更高性能的平台来解决，但是如果程序已经优化到极限和平台无法更换的情况下，可以通过提高业务进程的优先级来提高业务数据的吞吐量,例如：

nice -n -20 ./bin

nice为Linux环境下的改变进程优先级的命令，-n为进程优先级级别参数，-20为优先级级别，Linux一共有40个优先级，分别从-20到19，-20为最高优先级，19为最低优先级，一般程序默认优先级为0，只有root权限才能将进程优先级设为负数，如果程序已经在运行，可以使用renice，在不中断程序的情况下改变其优先级，程序处于哪个优先级可以通过top命令查看，NI字段则为对应该程序的优先级。在做网络数据分析的时候该方法非常管用，没有提高优先级时，数据吞吐量大概为800Mbps，再往上就开始处理不过来了，直到应用层buffer满了导致数据丢失，将进程提高到最高优先级，数据吞吐量可以提高到接近900Mbps，效果相当明显。

### 进程上下文

#### 谈一下 系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换

**CPU上下文切换**
进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？CPU 上下文切换就是罪魁祸首。

我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要**系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）**。

**CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。**

知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

操作系统管理的这些“任务”到底是什么呢？

**所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。**

**进程上下文切换**
Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中，CPU 特权等级的 Ring 0 和 Ring 3。

内核空间（Ring 0）具有最高权限，可以直接访问所有资源；

用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210630215953751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbmRfcHJvZ3JhbW1vbmtleQ==,size_16,color_FFFFFF,t_70#pic_center)

那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。

而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换。**

**那么，进程上下文切换跟系统调用又有什么区别呢？**

* 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，**进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态**。因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。
* 进程上下文切换，是指从一个进程切换到另一个进程运行。而系统调用过程中一直是同一个进程在运行。

**线程上下文切换**
线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。

说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。

这么一来，线程的上下文切换其实就可以分为两种情况：

* 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
* 第二种，前后两个线程属于同一个进程。**此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

**中断上下文切换**
除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。**中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。**

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

#### 进程在哪些场景会进行上下文切换？

* 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
* 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
* 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
* 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
* 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；

#### 进程上下文切换做了哪些事？流程是怎么样的？

进程切换的视图：

![image.png](https://s2.loli.net/2022/10/06/QydSZ6VWICzGYL2.png)

 **关键点：**

1. 发生中断时的保存现场，将发生中断时的所有通用寄存器保存到进程的内核栈，使用struct pt_regs结构。
2. 地址空间切换将进程自己的页全局目录的基地址 pgd 保存在ttbr0_le1中，用于mmu 的页表遍历的起始点。
3. 硬件上下文切换的时候，将此时的调用保存寄存器和pc, sp保存到struct cpu_context结构中。做好了这几个保存工作，当进程再次被调度回来的时候，通过cpu_context中保存的pc回到了cpu_switch_to的下一条指令继续执行，而由于cpu_context中保存的sp导致当前进程回到自己的内核栈，经过一系列的内核栈的出栈处理，最后将原来保存在pt_regs中的通用寄存器的值恢复到了通用寄存器，这样进程回到用户空间就可以继续沿着被中断打断的下一条指令开始执行，用户栈也回到了被打断之前的位置，而进程访问的指令数据做地址转化（VA到PA）也都是从自己的pgd开始进行，一切对用户来说就好像没有发生一样。

**总结；**

　　进程切换有两大步骤：地址空间切换和处理器状态切换（硬件上下文切换）。前者保证了进程回到用户空间之后能够访问到自己的指令和数据（其中包括减小tlb清空的ASID机制），后者保证了进程内核栈和执行流的切换，会将当前进程的硬件上下文保存在进程所管理的一块内存，然后将即将执行的进程的硬件上下文从内存中恢复到寄存器，有了这两步的切换过程保证了进程运行的有条不紊，当然切换的过程是在内核空间完成，这对于进程来说是透明的。

#### 上下文切换为什么资源消耗会比较高？消耗在什么地方？

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![进程上下文切换](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg)

大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。

### 进程控制

#### 进程控制结构？包含哪些信息？

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

PCB 具体包含什么信息呢？

**进程描述信息：**

* 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
* 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

* 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
* 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

* 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

* CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。

#### PCB 是如何组织？几种方式优缺点（要改）

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

* 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
* 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
* 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

那么，就绪队列和阻塞队列链表的组织形式如下图：

![就绪队列和阻塞队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg)

除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

#### 如何创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。

创建进程的过程如下：

* 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
* 为该进程分配运行时所必需的资源，比如内存资源；
* 将 PCB 插入到就绪队列，等待被调度运行；

#### 如何终止进程

进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

终止进程的过程如下：

* 查找需要终止的进程的 PCB；
* 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
* 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
* 将该进程所拥有的全部资源都归还给操作系统；
* 将其从 PCB 所在队列中删除；

1、main函数的自然返回，return

2、调用exit函数，属于c的函数库

3、调用_exit函数，属于系统调用

4、调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。

 5、接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)

exit和_exit的区别

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-39-1.png)

#### 如何阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：

* 找到将要被阻塞进程标识号对应的 PCB；
* 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
* 将该 PCB 插入到阻塞队列中去；

#### 如何唤醒进程

进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。

唤醒进程的过程如下：

* 在该事件的阻塞队列中找到相应进程的 PCB；
* 将其从阻塞队列中移出，并置其状态为就绪状态；
* 把该 PCB 插入到就绪队列中，等待调度程序调度；

进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。

#### Linux 系统如何管理进程？

每个进程在内核中都有一个进程控制块(PCB)来维护进程相关的信息,Linux内核的进程控制块是task_struct结构体.

task_struct是Linux内核的一种数据结构，它会被装载到RAM中并且包含着进程的信息。每个进程都把它的信息放在 task_struct 这个数据结构体，task_struct 包含了这些内容：

> 1. **标示符**： 描述本进程的唯一标识符，用来区别其他进程。
> 2. **状态** ：任务状态，退出代码，退出信号等。
> 3. **优先级** ：相对于其他进程的优先级。
> 4. **程序计数器**：程序中即将被执行的下一条指令的地址。
> 5. **内存指针**：包括程序代码和进程相关数据的指针，还有和其他进程共享的内存块的指针。
> 6. **上下文数据**：进程执行时处理器的寄存器中的数据。
> 7. **I/O状态信息**：包括显示的I/O请求,分配给进程的I/O设备和被进程使用的文件列表。
> 8. **记账信息**：可能包括处理器时间总和，使用的时钟数总和，时间限制，记账号等。

有关进程信息还有以下三点需要了解：

> 1. 保存进程信息的数据结构叫做 task_struct，可以在 include/linux/sched.h 中找到它；
> 2. 所有运行在系统中的进程都以 task_struct 链表的形式存在内核中；
> 3. 进程的信息可以通过 /proc 系统文件夹查看。要获取PID为400的进程信息，你需要查看 /proc/400 这个文件夹。大多数进程信息同样可以使用top和ps这些用户级工具来获取,例如：

![img](https:////upload-images.jianshu.io/upload_images/12535952-d04f7af40f9bce32.png?imageMogr2/auto-orient/strip|imageView2/2/w/680/format/webp)

#### fork 和 vfork 区别

**fork的基础知识：**

fork:创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

```c++
#include <sys/types.h>

#include <unistd.h>

pid_t fork(void);
```

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

**vfork的基础知识：**

在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了vfork( )系统调用。

```c++
#include <sys/types.h>

#include <unistd.h>

pid_t vfork(void);
```

除了子进程必须要立刻执行一次对exec的系统调用，或者调用_exit( )退出，对vfork( )的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。

vfork( )是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换fork( )争论。实际上，直到2.2.0内核，vfork( )只是一个封装过的fork( )。因为对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。

**补充知识点：写时复制**

Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。

写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。

写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。

在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以**页为基础**进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，**但实际上它们共享父进程的原始页**，接下来这些页又可以被其他的父进程或子进程共享。

写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。**内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享**。

**现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。**

在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。

**fork和vfork的区别：**

1. fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段

2. fork( )的父子进程的执行次序不确定；**vfork( )保证子进程先运行**，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。

3. vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。

4. 当需要改变共享数据段中变量的值，则拷贝父进程。

#### fork,wait,exec

父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写时拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。

fork从父进程返回子进程的pid，从子进程返回0.

调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。

exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1

**请你来说一下fork函数**

参考回答：
Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

```c
#include <sys/types.h>

#include <unistd.h>

pid_t fork(void);
```

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

**请你来手写一下fork调用示例**

1、概念：
Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：

成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。

最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。

在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。

2、fork实例

```c
int main(void)
{
pid_t pid;
signal(SIGCHLD, SIG_IGN);
printf("before fork pid:%d\n", getpid());
int abc = 10;
pid = fork();
if (pid == -1) {           //错误返回

perror("tile");
return -1;
}
if (pid > 0) {              //父进程空间

abc++;
printf("parent:pid:%d \n", getpid());
printf("abc:%d \n", abc);
sleep(20);
}
else if (pid == 0) {       //子进程空间
abc++;
printf("child:%d,parent: %d\n", getpid(), getppid());
printf("abc:%d", abc);
}
printf("fork after...\n");
 }
```

以Unix系统举例：

1. 进程的创建：fork()。新创建的子进程几乎但不完全与父进程相同。**子进程得到与父进程用户级虚拟地址空间相同的(但是独立的)一份副本，包括代码和数据段、堆、共享库以及用户栈**。**子进程还获得与父进程任何打开文件描述符相同的副本**，这就意味着当父进程调用 fork 时，子进程可以读写父进程中打开的任何文件。父进程和新创建的子进程之间最大的区别在于它们有不同的 PID。fork函数是有趣的（也常常令人迷惑）， 因为它只被调用一次，却会返回两次：一次是在调用进程（父进程）中，一次是在新创建的子进程中。在父进程中，fork 返回子进程的 PID。在子进程中，fork 返回 0。因为子进程的 PID 总是为非零，返回值就提供一个明 确的方法来分辨程序是在父进程还是在子进程中执行。

```C++
pid_t fork(void);
```

2. 回收子进程：当一个进程由于某种原因终止时，内核并不是立即把它从系统中清除。相反，进程被
 保持在一种已终止的状态中，直到被它的父进程回收（reaped）。当父进程回收已终止的子进程
 时，内核将子进程的退出状态传递给父进程，然后抛弃已终止的进程。一个进程可以通过调用
 waitpid 函数来等待它的子进程终止或者停止。

  ```C
pid_t waitpid(pid_t pid, int *statusp, int options);
  ```

3. 加载并运行程序：execve 函数在当前进程的上下文中加载并运行一个新程序。

  ```C
int execve(const char *filename, const char *argv[], const char *envp[]);
  ```

4. 进程终止：

  ```C
void exit(int status);
  ```
