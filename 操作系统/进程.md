# 进程

## 问题

### 进程通信

* 进程间通信方式？





* 守护进程、僵尸进程和孤儿进程？
* 如何避免僵尸进程？
* 终端退出，终端运行的进程会怎样？
* 如何让进程后台运行？



### 进程调度

* 什么时候发生调度？
* 非抢占式调度和抢占式调度区别？
* 调度算法考虑哪些原则？
* 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？
* 谈谈比例份额调度？
	* 彩票机制
	* 步长调度
	* 谈谈Linux完全公平调度？

* 谈谈多级反馈队列？
  * 没有工作长度的先验知识，如何减少响应时间和周转时间？
  * 如何设置优先级的？
  * 多级反馈队列如何配置或调优？
* 多处理器调度？



### 进程状态

* 进程状态及其转换？



### 进程上下文切换

* 谈一下系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换？
* 进程在哪些场景会进行上下文切换？
* 进程上下文切换做了哪些事？流程是怎么样的？
* 上下文切换为什么资源消耗会比较高？消耗在什么地方？



### 进程控制

* 进程控制结构
* 如何创建进程
* 如何终止进程
* 如何阻塞进程
* 如何唤醒进程



## 回答

### 进程间通信方式

**管道**

分为匿名管道和命名管道

* 不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作
* **管道这种通信方式效率低，不适合进程间频繁地交换数据**
* 好处：简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了
* 另外，管道传输的数据是无格式的流且大小受限



匿名管道

* 没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中
* shell 命令中的「`|`」竖线就是匿名管道
* 通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道
* **匿名管道是只能用于存在父子关系的进程间通信**
* 匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道

* 突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，**那么毫无关系的进程就可以通过这个设备文件进行通信。**`mkfifo myPipe`

**消息队列**

* 消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。

* 优点
	* 可以频繁通信了
	* 可以独立于读写进程存在，避免了 FIFO 中同步管道打开和关闭可能产生的困难
	* 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法
	* 读进程可以根据消息消息类型有选择的接受消息，而不是像 FIFO 那样默认接受

* 缺点：
  * 通信不及时，**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**
  * 附件也有大小限制
  * **消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。
* 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在

**共享内存**

* **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。

* 可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。
* 但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

**信号量**

* 用来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。
* **信号量不仅可以实现访问的互斥性（1），还可以实现进程间的同步（0）**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

**信号**

* **对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

* 信号是**异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件
* 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）
* 一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。
* 有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。
* 常用信号：`kill -l` 查询
	* `Ctrl+C` 产生 `SIGINT`信号表示终止该进程
	* `Ctrl+Z`产生`SIGTSTP`信号，表示停止该进程但还没结束

**Socket**

```
int socket(int domain, int type, int protocal);
// domain:AF_INET,AF_LOCAL,AF_UNIX
// type:SOCK_STREAM,SOCK_DGRAM
// protocal:弃用填 0 即可
```

* 如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。
* Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信
* 可根据创建 Socket 的类型不同，分为三种常见的通信方式
	* 基于 TCP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_STREAM；
	* 基于 UDP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_DGRAM；
	* 本地进程间通信方式：
		* 本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM
		* 本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM
		* 另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket
		* 实现效率比 IPv4，IPv6 大很多
		* 不需要绑定 IP地址和端口，而是绑定一个本地文件

### 进程调度

#### 什么时候发生调度？

1. 当进程从运行状态转到等待状态；
2. 当进程从运行状态转到就绪状态；
3. 当进程从等待状态转到就绪状态；
4. 当进程从运行状态转到终止状态；

其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。

非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。

那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。

调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。

#### 非抢占式调度和抢占式调度区别？

如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

- **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
- **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

#### 调度算法考虑哪些原则？

- **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
- **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
- **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
- **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。
- 确保每个工作获得一定比例的 CPU 时间（比例份额调度的特殊要求）



#### 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？

**先来先服务调度算法**

最简单的一个调度算法，就是非抢占式的**先来先服务（\*First Come First Severd, FCFS\*）算法**了。

![FCFS 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg)

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。



**最短作业优先调度算法**

**最短作业优先（\*Shortest Job First, SJF\*）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。



**高响应比优先调度算法**

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；



**时间片轮转调度算法**

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（\*Round Robin, RR\*）调度算法**。

![RR 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg)

**每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。


**最高优先级调度算法**

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（\*Highest Priority First，HPF\*）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 比例份额调度算法

**基本概念：票数代表份额**

* 每个进程持有一些彩票号，调度程序每一次调度时，进行抽奖，持有开奖号数的进程被调度
* 利用了随机性，可以避免很多最差的情况

**彩票机制**

* 彩票货币：每个用户可以有自己的货币，最后再转换成调度程序的货币
* 彩票转让：进程可以临时将自己的彩票交给另一个进程
* 彩票膨胀：一个进程可以临时提升或降低彩票数量。只有进程相互信任的环境才有意义。

**步长调度**

* 每个工作都有步长，步长等于一个大数除以它的票数
* 每个进程都有行程值，每次调度完一个进程后，行程值增加它的步长
* 每次调度选择拥有最小行程值的进程
* 与彩票机制调度不同的是，由于彩票机制使用了随机性，所以可能无法提供正确的比例，特别是在短时间内发生的调度行为，而步长调度则是能够确保这种比例
* 而步长调度的缺点则是，在新进程加入时，它的行程值为0，会使得它长时间独占CPU

**问题**
如何分配票数？这个问题非常难解决，因此比例份额调度只有在容易确定份额的场景下才适用。

**Linux完全公平调度（CFS）**
**基本操作**
尽管大多数调度程序都是基于固定时间片的概念，但CFS的操作有所不同。它的目标很简单：在所有竞争的进程之间平均分配CPU。它通过称为虚拟运行时（vruntime）的基于计数的简单技术来实现。
在每个进程运行时，它将积累vruntime。在最基本的情况下，每个进程的虚拟运行时以相同的速率增长，与物理（实时）时间成比例。当发生调度决策时，CFS将选择运行vruntime最低的进程。
这就引出了一个问题：调度程序应该何时停止当前正在运行的进程，然后运行下一个进程？这里的压力很明显：如果CFS切换得太频繁，公平性就会增加，因为CFS将确保每个进程即使在很小的时间窗口内也能获得其CPU的份额，但是会以性能为代价（上下文切换过多）；如果CFS切换的频率较低，则性能会提高（上下文切换减少），但会以近期的公平为代价。
CFS通过各种控制参数来管理这种压力。首先是调度延迟（sched_latency）。 CFS使用此值来确定在考虑切换之前一个进程应运行多长时间（以动态方式有效地确定其时间段）。典型的调度延迟时间值为48（毫秒）。 CFS将该值除以CPU上正在运行的进程数（n）来确定一个进程的时间片，从而确保在这段时间内CFS将完全公平。
例如，如果正在运行n = 4 n = 4n=4个进程，则CFS将调度延迟时间的值除以n，得出每个进程的时间片为12 ms。然后，CFS调度第一个任务并运行它，直到它使用了12毫秒的（虚拟）运行时为止，然后检查是否有一个具有较低vruntime的任务要运行。在这种情况下，CFS将切换到其他三个任务之一，依此类推。下图显示了一个示例，其中四个任务（A，B，C，D）以这种方式分别运行两个时间片。然后，其中两个（C，D）完成，仅剩下两个，然后以循环方式分别运行24 ms。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917231054521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

但是，如果运行的进程“太多”怎么办？那会不会导致时间片太小，从而导致上下文切换过多？
为了解决此问题，CFS添加了另一个参数最小粒度，通常设置为6 ms之类的值。CFS永远不会将时间片设置小于该值，从而确保在调度开销方面不会花费太多时间。
例如，如果有十个进程在运行，我们的原始计算将调度的延迟除以十来确定时间片（结果：4.8毫秒）。但是，由于最小粒度，CFS会将每个进程的时间片设置为6ms。尽管CFS在48毫秒的目标调度延迟（调度延迟）上并不能（完全）公平，但在达到较高CPU效率的同时，它还是很接近的。
注意，CFS利用了周期性的计时中断，这意味着它只能以固定的时间间隔做出决定。该中断频繁关闭（例如，每1毫秒一次），使CFS有机会唤醒并确定当前任务是否已运行结束。如果任务的时间片不是计时中断间隔的完美倍数，则没问题； CFS精确跟踪vruntime，这意味着从长远来看，它将最终接近理想的CPU共享。

**加权（精细度）**
CFS还可以控制进程优先级，从而使用户或管理员可以为某些进程分配更高的CPU份额。它不使用票而是通过经典的UNIX机制（称为进程的nice级别）来完成的。可以将一个进程的nice参数设置为-20到+19之间的任意值，默认值为0。正的nice值表示优先级较低，而负的值表示优先级较高。
CFS将每个进程的nice值映射到权重，如下所示：

```
static const int prio_to_weight[40] = {
	/* -20 */ 88761, 71755, 56483, 46273, 36291,
	/* -15 */ 29154, 23254, 18705, 14949, 11916,
	/* -10 */ 9548, 7620, 6100, 4904, 3906,
	/* -5 */  3121, 2501, 1991, 1586, 1277,
	/* 0 */   1024, 820, 655, 526, 423,
	/* 5 */   335, 272, 215, 172, 137,
	/* 10 */  110, 87, 70, 56, 45,
	/* 15 */  36, 29, 23, 18, 15,
};
```

这些权重使我们能够计算每个进程的有效时间片（就像我们之前所做的一样），但是现在考虑了它们的优先级差异。这样做的公式如下：$\frac{weight_k}{\sum\limits^{n-1}_{i=0}weight_i}*sched\_latency$


让我们看一个例子，看看它是如何工作的。假设有两个任务，A和B。A，因为它是我们最宝贵的工作，被赋予了更高的优先级，所以分配给它的nice值-5；B，因为我们讨厌它，所以它具有默认优先级（nice值等于0）。这意味着 $weight_A$ 为3121，而$weight_B$ 为1024。然后，计算每个任务的时间片，A的时间片约为调度延迟的 $\frac{3}{4} $ （因此为36毫秒），而B的时间片约为$\frac{1}{4} $（因此为12毫秒）。
除了概括时间片计算之外，还必须调整CFS计算vruntime的方式。这是新的公式，它采用进程i ii累计的实际运行时间（$runtime_i$），并按进程的权重进行反比例缩放。在我们的运行示例中，A的vruntime将以B的速度的三分之一累积。$vruntime_i=vruntime_i+\frac{weight_0}{weight_i}*runtime_i$ 上面的权重表的构造的一个明智的方面是，当nice值的差异恒定时，该表保留CPU比例比率。例如，如果进程A的nice值为5（不是-5），而进程B的nice值为10（不是0），则CFS将以与以前完全相同的方式调度它们。

**使用红黑树**
如上所述，CFS的一个主要重点是效率。对于调度程序而言，效率有很多方面，但是其中一个方面是如此简单：当调度程序必须找到要运行的下一个任务时，它应该尽快完成。像列表这样的简单数据结构无法扩展：现代系统有时由数千个进程组成，因此每隔几毫秒搜索一个长列表是很浪费的。
CFS通过将进程保存在红黑树中来解决此问题。红黑树是许多平衡树中的一种。与简单的二叉树（在最坏情况下的插入操作性能可能退化为类似链表的性能）相比，平衡树做了一些额外的工作来保持较低的深度，从而确保操作在时间上是对数级别的（而不是线性的）。
CFS不会将所有进程都保留在此结构中，而是仅将运行（或可运行）的进程保留在其中。如果某个进程进入睡眠状态（例如，等待I / O完成，或者等待网络数据包到达），则将其从树中删除并跟踪其他位置。
让我们看一个例子。假设有十个任务，并且它们具有以下vruntime值：1、5、9、10、14、18、17、21、22和24。如果我们将这些任务保留在有序列表中，查找下一个要运行的任务很简单：只需删除第一个元素。但是，当将该任务放回列表中时（按顺序），我们要扫描列表，寻找正确的位置将其插入，这是一个O（n）的操作。任何查找的效率也很低，平均也要花费线性时间。
在红黑树中保持相同的值可以使大多数操作更高效，如图所示。进程按vruntime在树中排序，并且大多数操作（例如插入和删除）在时间上都是对数的，即O（log n）。当n上千时，对数的效率明显高于线性的效率。

![img](https://img-blog.csdnimg.cn/20200917235919529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

**处理I / O和睡眠进程**
选择最低vruntime的进程来运行导致的一个问题是长期处于休眠状态的任务。想象一下两个进程，A和B，其中一个（A）连续运行，另一个（B）长时间睡眠（例如10秒）。当B醒来时，其vruntime将比A的运行时间晚10秒，因此（如果我们不小心的话），B现在会在接下来的10秒钟内独占CPU，使A饥饿。
CFS通过在任务唤醒时更改其vruntime来处理这种情况。具体来说，CFS将该任务的vruntime设置为在树中找到的最小值（请记住，该树仅包含正在运行的任务）。这样，CFS避免了饥饿，但并非没有代价：短时间内频繁睡眠的任务经常无法获得应有的CPU份额。

**CFS其他有趣的功能**
CFS具有许多其他功能，它包括多种启发式方法，可以提高缓存性能，具有有效处理多CPU的策略，可以跨大组进程进行调度（而不是将每个进程视为一个独立的实体），以及许多其他有趣的功能。

**总结**
我们介绍了比例分配调度的概念，并简要讨论了三种方法：彩票调度，步长调度和Linux的完全公平调度（CFS）。彩票调度巧妙地利用随机性来实现比例分配。步长调度非常具有确定性。 CFS是本章中讨论的唯一“真正的”调度程序，有点像带有动态时间片的加权循环调度，但是可以在负载下扩展和运行良好。据说，它是当今最广泛使用的公平份额调度程序。
没有调度程序是万能的灵丹妙药，公平份额的调度程序也有很多问题。
一个问题是这种方法不能与I / O很好地融合在一起；如上所述，偶尔执行I / O的任务可能无法公平得到CPU。另一个问题是，它们没有解决票或优先级分配的难题，即如何知道应该分配浏览器程序多少票，或者如何设置文本编辑器的nice值？其他通用调度程序（例如前面讨论的MLFQ和其他类似的Linux调度程序）会自动处理这些问题，因此可能更易于部署。
好消息是，在许多领域中，这些问题并不是主要问题，并且比例份额调度程序可发挥巨大作用。例如，在虚拟数据中心（或云）中，你可能希望将四分之一的CPU周期分配给Windows VM，其余的分配给基本的Linux安装，比例份额可以变得简单而有效。这个想法也可以扩展到其他资源。

#### 多级反馈队列调度

**多级反馈队列调度算法**（无先验经验）

**多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)

来看看，它是如何工作的：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**



#### 多处理器调度？

**单队列**

![img](https://pic4.zhimg.com/v2-f424f5893cd3bbdd49ebb77c8c70c3bf_b.jpg)

这种形式不需要在单处理器的框架下做太多改动，**同样的是维护一个进程的全局就绪队列，为所有 CPU 共享。运行在 CPU 上的调度程序从这个队列中挑选合适的进程执行。**

**特点**：

- 实现较简单，对所有的 CPU 来说很公平。
- 这个队列是全局共享的，所以当一个 CPU 挑选进程时需要加锁，不然多个 CPU 就可能选取同一个进程。但是锁机制不可避免带来额外的开销使得性能降低，可扩展性降低。
- 处理器亲和性(Processor Affinity)不容易实现，处理器亲和性是系统提供给用户的一种选择，用户可以指定特定的处理器来执行进程。
- 每个处理器都有自己的缓存，处理器亲和性不好，一个进程可能在多个处理器之间来回运行，使得处理器的缓存无效，所以缓存亲和性也不好，性能较为低下。

**多队列**

![img](https://pic4.zhimg.com/v2-af9ad1b1877b020d9412a56a0ff72877_b.jpg)

如上图所示：**每个 CPU 都有自己单独的调度队列**。每个 CPU 只在自己本地的队列中挑选合适的进程，速度很快。

**队列之间的调度相互独立**，可不再使用锁机制，可扩展性增强，比如每个队列可使用不同的调度算法。

**所有的任务工作都能在固定的 CPU 上执行，能够很好的利用缓存数据**。

**但是也有明显缺点：各个 CPU 的负载不均衡**，从上图就可以看出 CPU2 负载较大，而 CPU3 负载较小

**解决负载均衡的办法叫做迁移(Migration)，从繁忙 CPU 的队列中迁移一些进程到空闲 CPU 中去**。



### 进程状态

在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。

它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

上图中各个状态的意义：

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

再来详细说明一下进程的状态变迁：

- *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
- *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
- *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
- *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
- *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
- *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
- *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。

所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

![虚拟内存管理-换入换出](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/9-%E6%8D%A2%E5%85%A5%E6%8D%A2%E5%87%BA.jpg)

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。

另外，挂起状态可以分为两种：

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

这两种挂起状态加上前面的五种状态，就变成了七种状态变迁（留给我的颜色不多了），见如下图：

![七种状态变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg)

导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

- 通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。
- 用户希望挂起一个程序的执行，比如在 Linux 中用 `Ctrl+Z` 挂起进程；



### 进程上下文

#### 谈一下 系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换

**CPU上下文切换**
进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？CPU 上下文切换就是罪魁祸首。

我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要**系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）**。

**CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。**



知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

操作系统管理的这些“任务”到底是什么呢？

**所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。**

**进程上下文切换**
Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中，CPU 特权等级的 Ring 0 和 Ring 3。

内核空间（Ring 0）具有最高权限，可以直接访问所有资源；

用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210630215953751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbmRfcHJvZ3JhbW1vbmtleQ==,size_16,color_FFFFFF,t_70#pic_center)

那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。

而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换。**

进程上下文切换，是指从一个进程切换到另一个进程运行。

而系统调用过程中一直是同一个进程在运行。

那么，进程上下文切换跟系统调用又有什么区别呢？

**进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。**

**因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。**

那么，**进程在什么时候才会被调度到 CPU 上运行呢？**

最容易想到的一个时机，就是进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。其实还有很多其他场景，也会触发进程调度，在这里我给你逐个梳理下。

其一，为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。

其二，进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。

其三，当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。

其四，当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。

最后一个，发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

**线程上下文切换**
线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。

说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。

这么一来，线程的上下文切换其实就可以分为两种情况：

* 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
* 第二种，前后两个线程属于同一个进程。**此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

**中断上下文切换**
除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。**中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。**

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。



#### 进程在哪些场景会进行上下文切换？

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
- 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；



#### 进程上下文切换做了哪些事？流程是怎么样的？

进程切换的视图：

![image.png](https://s2.loli.net/2022/10/06/QydSZ6VWICzGYL2.png)

 

 **关键点：**

1. 发生中断时的保存现场，将发生中断时的所有通用寄存器保存到进程的内核栈，使用struct pt_regs结构。
2. 地址空间切换将进程自己的页全局目录的基地址ｐｇｄ保存在ttbr0_le1中，用于ｍｍｕ的页表遍历的起始点。
3. 硬件上下文切换的时候，将此时的调用保存寄存器和pc, sp保存到struct cpu_context结构中。做好了这几个保存工作，当进程再次被调度回来的时候，通过cpu_context中保存的pc回到了cpu_switch_to的下一条指令继续执行，而由于cpu_context中保存的sp导致当前进程回到自己的内核栈，经过一系列的内核栈的出栈处理，最后将原来保存在pt_regs中的通用寄存器的值恢复到了通用寄存器，这样进程回到用户空间就可以继续沿着被中断打断的下一条指令开始执行，用户栈也回到了被打断之前的位置，而进程访问的指令数据做地址转化（VA到PA）也都是从自己的pgd开始进行，一切对用户来说就好像没有发生一样。

**总结；**

　　进程切换有两大步骤：地址空间切换和处理器状态切换（硬件上下文切换）。前者保证了进程回到用户空间之后能够访问到自己的指令和数据（其中包括减小tlb清空的ASID机制），后者保证了进程内核栈和执行流的切换，会将当前进程的硬件上下文保存在进程所管理的一块内存，然后将即将执行的进程的硬件上下文从内存中恢复到寄存器，有了这两步的切换过程保证了进程运行的有条不紊，当然切换的过程是在内核空间完成，这对于进程来说是透明的。



#### 上下文切换为什么资源消耗会比较高？消耗在什么地方？

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![进程上下文切换](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg)

大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。



### 进程控制

#### 进程控制结构

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。



PCB 具体包含什么信息呢？

**进程描述信息：**

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

- 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
- 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

- 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。





每个 PCB 是如何组织的呢？

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
- 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

那么，就绪队列和阻塞队列链表的组织形式如下图：

![就绪队列和阻塞队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg)

除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。



#### 如何创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。

创建进程的过程如下：

- 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
- 为该进程分配运行时所必需的资源，比如内存资源；
- 将 PCB 插入到就绪队列，等待被调度运行；



#### 如何终止进程

进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

终止进程的过程如下：

- 查找需要终止的进程的 PCB；
- 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
- 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
- 将该进程所拥有的全部资源都归还给操作系统；
- 将其从 PCB 所在队列中删除；



1、main函数的自然返回，return 

2、调用exit函数，属于c的函数库

3、调用_exit函数，属于系统调用 

4、调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。

 5、接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)



exit和_exit的区别

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-39-1.png)

#### 如何阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：

- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
- 将该 PCB 插入到阻塞队列中去；



#### 如何唤醒进程

进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。

唤醒进程的过程如下：

- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插入到就绪队列中，等待调度程序调度；

进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。
