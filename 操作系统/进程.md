# 进程

## 问题

### 基本概念

* 什么是进程？进程与程序的区别？
* 什么是守护进程？如何创建守护进程？（手搓）
* 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免僵尸进程？
* 什么是控制终端、进程组、会话？它们之间是什么关系
* 终端退出，终端运行的进程会怎样？
* 如何让进程后台运行？



### 进程通信

* 进程间通信方式？
* 谈谈信号机制？
* 管道怎么实现的？
* 共享内存 API？
* 共享内存通过什么共同管理？（信号量）



### 进程调度

* 什么时候发生调度？
* 非抢占式调度和抢占式调度区别？
* 调度算法考虑哪些原则？
* 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？
* 谈谈比例份额调度？
	* 彩票机制
	* 步长调度
	* 谈谈Linux完全公平调度？

* 谈谈多级反馈队列？
  * 没有工作长度的先验知识，如何减少响应时间和周转时间？
  * 如何设置优先级的？
  * 多级反馈队列如何配置或调优？
* 多处理器调度？
* 时间片调度的时间片如何校准时间？
* 谈谈优先级反转以及解决思路？
* Linux 如何提升进程优先级？



### 进程状态

* 进程状态及其转换？



### 进程上下文切换

* 谈一下系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换？
* 进程在哪些场景会进行上下文切换？
* 进程上下文切换做了哪些事？流程是怎么样的？
* 上下文切换为什么资源消耗会比较高？消耗在什么地方？



### 进程控制

* 进程控制结构，包含哪些信息？
*  PCB 是如何组织？几种方式优缺点（要改）
* 如何创建进程？
* 如何终止进程？
* 如何阻塞进程？
* 如何唤醒进程？
* Linux 系统如何管理进程？
	* Linux 系统进程靠什么管理进程？
	* Linux 系统进程如何通过 task_struct 来找到虚拟内存？
	* Linux 系统进程如何通过 task_struct 中的信息访问地址的？


## 回答

## 基本概念

#### 什么是进程？进程与程序的区别？

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，**那么这个运行中的程序，就被称为「进程」（Process）**



* 程序是指令和数据的有序集合，是一个静态的概念。而进程是程序在处理机上的一次执行过程，它是一个 动态的概念。
*  程序可以作为一种软件资料长期存在，而进程是有一定生命期的。程序是永久的，进程是暂时的。
* 进程是由进程控制块、程序段、数据段三部分组成;
* 进程具有创建其他进程的功能，而程序没有。
* 同一程序同时运行于若干个数据集合上，它将属于若干个不同的进程，也就是说同一程序可以对应多个进 程。
* 在传统的操作系统中，程序并不能独立运行，作为资源分配和独立运行的基本单元都是进程。

#### 什么是控制终端、进程组、会话？它们之间是什么关系

**终端**

* 在 UNIX 系统中，用户通过终端登录系统后得到一个 shell 进程，这个终端成为 shell 进程的控制终端（Controlling Terminal），进程中，控制终端是保存在 PCB 中的信息，而 fork() 会复制 PCB 中的信息，因此由 shell 进程启动的其它进程的控制终端也是这个终端。
* 默认情况下（没有重定向），每个进程的标准输入、标准输出和标准错误输出都指向控制终端，进程从标准输入读也就是读用户的键盘输入，进程往标准输出或标准错误输出写也就是输出到显示器上。
* 在控制终端输入一些特殊的控制键可以给前台进程发信号，例如 Ctrl + C 会产生 SIGINT 信号，Ctrl + \ 会产生 SIGQUIT 信号。

**进程组**

每个进程都属于一个进程组。每个进程组都有一个组长进程，组长进程的进程号等于进程组ID。只要某个进程组中有一个进程存在，则该进程组就存在，与组长进程是否终止无关。从进程组创建开始到其中最后一个进程离开为止的时间区间成为进程组的生存期。进程组中最后一个进程可以终止或者转移到另一个进程组中。

* 进程组和会话在进程之间形成了一种两级层次关系：进程组是一组相关进程的集合，会话是一组相关进程组的集合。进程组和会话是为支持 shell 作业控制而定义的抽象概念，用户通过 shell 能够交互式地在前台或后台运行命令。
*  进行组由一个或多个共享同一进程组标识符（PGID）的进程组成。一个进程组拥有一个进程组首进程，该进程是创建该组的进程，其进程 ID 为该进程组的 ID，新进程会继承其父进程所属的进程组 ID。
* 进程组拥有一个生命周期，其开始时间为首进程创建组的时刻，结束时间为最后一个成员进程退出组的时刻。一个进程可能会因为终止而退出进程组，也可能会因为加入了另外一个进程组而退出进程组。进程组首进程无需是最后一个离开进程组的成员。

**会话**

* 会话是一组进程组的集合。会话首进程是创建该新会话的进程，其进程 ID 会成为会话 ID。新进程会继承其父进程的会话 ID。
*  一个会话中的所有进程共享单个控制终端。控制终端会在会话首进程首次打开一个终端设备时被建立。一个终端最多可能会成为一个会话的控制终端
* 在任一时刻，会话中的其中一个进程组会成为终端的前台进程组，其他进程组会成为后台进程组。只有前台进程组中的进程才能从控制终端中读取输入。当用户在控制终
	端中输入终端字符生成信号后，该信号会被发送到前台进程组中的所有成员。

* 当控制终端的连接建立起来之后，会话首进程会成为该终端的控制进程 

![在这里插入图片描述](https://img-blog.csdnimg.cn/8b9b94fd6e7b45399e962e60efb2d81f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6bG856u_6ZKT6bG85bmy,size_20,color_FFFFFF,t_70,g_se,x_16)



#### 什么是孤儿进程？什么是僵尸进程？有哪些危害？如何避免？

**unix提供了一种机制保证父进程知道子进程结束时的状态信息。**

这种机制是：在每个进程退出的时候，内核会释放所有的资源，包括打开的文件，占用的内存等。但是仍保留一部分信息(进程号PID，退出状态，运行时间等)。直到父进程通过wait或waitpid来取时才释放。

但是这样就会产生问题：如果父进程不调用wait或waitpid的话，那么保留的信息就不会被释放，其进程号就会被一直占用，**但是系统所能使用的进程号是有限的，如果大量产生僵死进程，将因没有可用的进程号而导致系统无法产生新的进程，这就是僵尸进程的危害**

孤儿进程是没有父进程的进程，它由init进程循环的wait()回收资源，init进程充当父进程。因此**孤儿进程并没有什么危害。**



补充：任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程的数据结构，等待父进程去处理。**如果父进程在子进程exit()之后，没有及时处理，出现僵尸进程，并可以用ps命令去查看，它的状态是“Z”。**



**孤儿进程：**父进程结束了，而它的一个或多个子进程还在运行，那么这些子进程就成为孤儿进程(father died)。子进程的资源由init进程(进程号PID = 1)回收。

**僵尸进程：**子进程退出了，但是父进程没有用wait或waitpid去获取子进程的状态信息，那么子进程的进程描述符(包括进程号 PID，退出状态 the termination status of the process，运行时间 the amount of CPU time taken by the process 等)仍然保存在系统中，这种进程称为僵尸进程



**解决方案**

1. kill杀死元凶父进程(一般不用)
	严格的说，僵尸进程并不是问题的根源，罪魁祸首是产生大量僵死进程的父进程。因此，我们可以直接除掉元凶，通过kill发送SIGTERM或者SIGKILL信号。元凶死后，僵尸进程进程变成孤儿进程，由init充当父进程，并回收资源。

	或者运行：kill -9 父进程的pid值、（僵尸进程无法用kill直接杀死）

2. 父进程用wait或waitpid去回收资源(方案不好)
	父进程通过wait或waitpid等函数去等待子进程结束，但是不好，会导致父进程一直等待被挂起，相当于一个进程在干活，没有起到多进程的作用。

3. 通过信号机制，在处理函数中调用wait，回收资源
	通过信号机制，子进程退出时向父进程发送SIGCHLD信号，父进程调用signal(SIGCHLD,sig_child)去处理SIGCHLD信号，在信号处理函数sig_child()中调用wait进行处理僵尸进程。什么时候得到子进程信号，什么时候进行信号处理，父进程可以继续干其他活，不用去阻塞等待。



#### 终端退出，终端运行的进程会怎样？

终端在退出时会发送SIGHUP给对应的bash进程，bash进程收到这个信号后首先将它发给session下面的进 程，如果程序没有对SIGHUP信号做特殊处理，那么进程就会随着终端关闭而退出



#### 如何让进程后台运行？

我们知道，当用户注销（logout）或者网络断开时，终端会收到 HUP（hangup）信号从而关闭其所有子进程。因此，我们的解决办法就有两种途径：要么让进程忽略 HUP 信号，要么让进程运行在新的会话里从而成为不属于此终端的子进程。



**1. nohup**

nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。

nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。一般我们可在结尾加上"&"来将命令同时放入后台运行，也可用">filename 2>&1"来更改缺省的重定向文件名。

1. 安装命令（默认没有，可在usr/bin下查看是否安装成功）：

	```java
	yum install coreutils
	1
	```

2. 使用示例：

	```bash
	[root@pythontab ~]# nohup ping www.baidu.com &
	[1] 3059
	nohup: appending output to `nohup.out'
	[root@pythontab ~]# ps -ef |grep 3059
	root      3059   984  0 15:06 pts/3    00:00:00 ping www.baidu.com
	root      3067   984  0 15:06 pts/3    00:00:00 grep 3059
	[root@pythontab ~]#
	1234567
	```

**2. setsid**

nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受 HUP 信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。

setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。

```bash
[root@pythontab ~]# setsid ping www.baidu.com
[root@pythontab ~]# ps -ef |grep www.baidu.com
root     31094     1  0 07:28 ?        00:00:00 ping www.baidu.com
root     31102 29217  0 07:29 pts/4    00:00:00 grep www.baidu.com
[root@pythontab ~]#
12345
```

值得注意的是，上例中我们的进程 ID(PID)为31094，**而它的父 ID（PPID）为1（即为 init 进程 ID），并不是当前终端的进程 ID。**

**3. screen**

我们已经知道了如何让进程免受 HUP 信号的影响，**但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？**

此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen 的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP 信号的影响。

使用 screen 很方便，有以下几个常用选项：

- 用screen -dmS session name来建立一个处于断开模式下的会话（并指定其会话名）。
- 用screen -list 来列出所有会话。
- 用screen -r session name来重新连接指定会话。
- 用快捷键CTRL-a d 来暂时断开当前会话。

screen 示例

```
[root@pvcent107 ~]# screen -dmS Urumchi
 
[root@pvcent107 ~]# screen -list
 
There is a screen on:
 
       12842.Urumchi   (Detached)
 
1 Socket in /tmp/screens/S-root.
 
  
 
[root@pvcent107 ~]# screen -r Urumchi
```

　　

当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。

1. 未使用 screen 时新进程的进程树

```
[root@pvcent107 ~]# ping www.google.com &
 
[1] 9499
 
[root@pvcent107 ~]# pstree -H 9499
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─2*[sendmail]
 
    ├─sshd─┬─sshd───bash───pstree
 
    │       └─sshd───bash───ping

```

我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP 信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。

2. 使用了 screen 后新进程的进程树

```
[root@pvcent107 ~]# screen -r Urumchi
 
[root@pvcent107 ~]# ping www.ibm.com &
 
[1] 9488
 
[root@pvcent107 ~]# pstree -H 9488
 
init─┬─Xvnc
 
    ├─acpid
 
    ├─atd
 
    ├─screen───bash───ping
 
    ├─2*[sendmail]
```

而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是 init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。



**4. Ctrl + Z 挂起进程，然后 jobs 查看序号，再使用 bg 后台运行进程**



其他

![img](https://img2020.cnblogs.com/blog/1657559/202108/1657559-20210813165932130-69616738.png)



#### 什么是守护进程？如何创建守护进程？（手搓）

守护进程，也就是通常说的Daemon进程，是Linux中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是脱离于终端并且在后台运行的进程。守护进程脱离于终端是为了避免进程在执行过程中的信息在任何终端上显示并且进程也不会被任何终端所产生的终端信息所打断。



1. **执行一个 fork()，之后父进程退出，子进程继续执行。**

	守护进程变成孤儿进程，这样就被init进程领养，init进程成为其父进程。由于子进程会继承父进程的会话，进程组，控制终端，文件描述符等，我们要让子进程和原来的这些信息脱离。

2. **子进程调用 setsid() 开启一个新会话。**

	脱离了原来会话组、进程组、控制终端，成为新的会话组组长。（新的会话是没有控制终端的）

	第一步创建子进程的原因是： 当进程是会话组长时setsid()调用失败，两个会话里会产生同样的ID,造成冲突。

	但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。

3. **清除进程的 umask 以确保当守护进程创建文件和目录时拥有所需的权限**

	设置文件掩码是为了不受父进程的 umask 的影响，能自由创建读写文件和目录

4. **修改进程的当前工作目录，通常会改为根目录（/）。**

	刚启动守护进程的时候默认使用当前位置作为工作目录，如果你用U盘之类的启动就很不合理了。

5. **关闭守护进程从其父进程继承而来的所有打开着的文件描述符。**

	子进程会从父进程继承文件描述符，这些文件描述符会占用资源，因此我们最好关闭它们。至少要关闭 0,1,2 这三个文件描述符，分别对应了 stdin, stdout, 和 stderr。不过通常用 sysconf(_SC_OPEN_MAX) 获取系统允许的最大文件描述符个数，然后全部 close 掉。

6. **在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null 并使用dup2() 使所有这些描述符指向这个设备。**

	同时为了防止有些操作使用0,1,2文件描述符出问题，所以重定向到/dev/null设备

	tip：/dev/null设备会把操作给丢弃到

7. **核心业务逻辑**



```c++
/*
    写一个守护进程，每隔2s获取一下系统时间，将这个时间写入到磁盘文件中。
*/

#include <stdio.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/time.h>
#include <signal.h>
#include <time.h>
#include <stdlib.h>
#include <string.h>

void work(int num) {
    // 捕捉到信号之后，获取系统时间，写入磁盘文件
    time_t tm = time(NULL);
    struct tm * loc = localtime(&tm);
    // char buf[1024];

    // sprintf(buf, "%d-%d-%d %d:%d:%d\n",loc->tm_year,loc->tm_mon
    // ,loc->tm_mday, loc->tm_hour, loc->tm_min, loc->tm_sec);

    // printf("%s\n", buf);

    char * str = asctime(loc);
    int fd = open("time.txt", O_RDWR | O_CREAT | O_APPEND, 0664);
    write(fd ,str, strlen(str));
    close(fd);
}

int main() {

    // 1.创建子进程，退出父进程
    pid_t pid = fork();

    if(pid > 0) {
        exit(0);
    }

    // 2.将子进程重新创建一个会话
    setsid();

    // 3.设置掩码
    umask(022);

    // 4.更改工作目录
    chdir("/home/nowcoder/");

    // 5. 关闭、重定向文件描述符
    int fd = open("/dev/null", O_RDWR);
    dup2(fd, STDIN_FILENO);
    dup2(fd, STDOUT_FILENO);
    dup2(fd, STDERR_FILENO);

    // 6.业务逻辑

    // 捕捉定时信号
    struct sigaction act;
    act.sa_flags = 0;
    act.sa_handler = work;
    sigemptyset(&act.sa_mask);
    sigaction(SIGALRM, &act, NULL);

    struct itimerval val;
    val.it_value.tv_sec = 2;
    val.it_value.tv_usec = 0;
    val.it_interval.tv_sec = 2;
    val.it_interval.tv_usec = 0;

    // 创建定时器
    setitimer(ITIMER_REAL, &val, NULL);

    // 不让进程结束
    while(1) {
        sleep(10);
    }

    return 0;
}
```




### 进程间通信方式

**管道**

分为匿名管道和命名管道

* 不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作
* **管道这种通信方式效率低，不适合进程间频繁地交换数据**
* 好处：简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了
* 另外，管道传输的数据是无格式的流且大小受限



匿名管道

* 没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中
* shell 命令中的「`|`」竖线就是匿名管道
* 通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道
* **匿名管道是只能用于存在父子关系的进程间通信**
* 匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

命名管道

* 突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，**那么毫无关系的进程就可以通过这个设备文件进行通信。**`mkfifo myPipe`

**消息队列**

* 消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。

* 优点
	* 可以频繁通信了
	* 可以独立于读写进程存在，避免了 FIFO 中同步管道打开和关闭可能产生的困难
	* 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法
	* 读进程可以根据消息消息类型有选择的接受消息，而不是像 FIFO 那样默认接受

* 缺点：
  * 通信不及时，**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**
  * 附件也有大小限制
  * **消息队列不适合比较大数据的传输**，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。
* 消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在

**共享内存**

* **共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中**。

* 可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。
* 但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

**信号量**

* 用来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。
* **信号量不仅可以实现访问的互斥性（1），还可以实现进程间的同步（0）**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

**信号**

* **对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**

* 信号是**异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件
* 信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）
* 一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。
* 有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。
* 常用信号：`kill -l` 查询
	* `Ctrl+C` 产生 `SIGINT`信号表示终止该进程
	* `Ctrl+Z`产生`SIGTSTP`信号，表示停止该进程但还没结束

**Socket**

```
int socket(int domain, int type, int protocal);
// domain:AF_INET,AF_LOCAL,AF_UNIX
// type:SOCK_STREAM,SOCK_DGRAM
// protocal:弃用填 0 即可
```

* 如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。
* Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信
* 可根据创建 Socket 的类型不同，分为三种常见的通信方式
	* 基于 TCP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_STREAM；
	* 基于 UDP 协议的通信方式：socket 类型是 AF_INET 和 SOCK_DGRAM；
	* 本地进程间通信方式：
		* 本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM
		* 本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM
		* 另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket
		* 实现效率比 IPv4，IPv6 大很多
		* 不需要绑定 IP地址和端口，而是绑定一个本地文件

### 进程调度

#### 什么时候发生调度？

1. 当进程从运行状态转到等待状态；（等待事件，资源不够）
2. 当进程从运行状态转到就绪状态；（时间片用完，抢占式调度）
3. 当进程从等待状态转到就绪状态；（高优先级进程等待变就绪，抢占正在运行的进程，抢占式调度）
4. 当进程从运行状态转到终止状态；（进程结束）

其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。

非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？**假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。**

那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。

**调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。**

#### 非抢占式调度和抢占式调度区别？

如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：

- **非抢占式调度算法**挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。
- **抢占式调度算法**挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生**时钟中断**，以便把 CPU 控制返回给调度程序进行调度，也就是常说的**时间片机制**。

#### 调度算法考虑哪些原则？

- **CPU 利用率**：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；
- **系统吞吐量**：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- **周转时间**：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；
- **等待时间**：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；
- **响应时间**：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。
- 确保每个工作获得一定比例的 CPU 时间（比例份额调度的特殊要求）



#### 单核CPU 常见进程调度算法有哪些？特点、优缺点、适用情况？

**先来先服务调度算法**

最简单的一个调度算法，就是非抢占式的**先来先服务（First Come First Severd, FCFS）算法**了。

![FCFS 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg)

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。



**最短作业优先调度算法**

**最短作业优先（Shortest Job First, SJF）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg)

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。



**高响应比优先调度算法**

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （Highest Response Ratio Next, HRRN）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；



**时间片轮转调度算法**

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（Round Robin, RR）调度算法**。

![RR 调度算法](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg)

**每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。**

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。


**最高优先级调度算法**

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 比例份额调度算法

**基本概念：票数代表份额**

* 每个进程持有一些彩票号，调度程序每一次调度时，进行抽奖，持有开奖号数的进程被调度
* 利用了随机性，可以避免很多最差的情况

**彩票机制**

* 彩票货币：每个用户可以有自己的货币，最后再转换成调度程序的货币
* 彩票转让：进程可以临时将自己的彩票交给另一个进程
* 彩票膨胀：一个进程可以临时提升或降低彩票数量。只有进程相互信任的环境才有意义。

**步长调度**

* 每个工作都有步长，步长等于一个大数除以它的票数
* 每个进程都有行程值，每次调度完一个进程后，行程值增加它的步长
* 每次调度选择拥有最小行程值的进程
* 与彩票机制调度不同的是，由于彩票机制使用了随机性，所以可能无法提供正确的比例，特别是在短时间内发生的调度行为，而步长调度则是能够确保这种比例
* 而步长调度的缺点则是，在新进程加入时，它的行程值为0，会使得它长时间独占CPU

**问题**
如何分配票数？这个问题非常难解决，因此比例份额调度只有在容易确定份额的场景下才适用。

**Linux完全公平调度（CFS）**
**基本操作**
尽管大多数调度程序都是基于固定时间片的概念，但CFS的操作有所不同。它的目标很简单：在所有竞争的进程之间平均分配CPU。它通过称为虚拟运行时（vruntime）的基于计数的简单技术来实现。
在每个进程运行时，它将积累vruntime。在最基本的情况下，每个进程的虚拟运行时以相同的速率增长，与物理（实时）时间成比例。当发生调度决策时，CFS将选择运行vruntime最低的进程。
这就引出了一个问题：调度程序应该何时停止当前正在运行的进程，然后运行下一个进程？这里的压力很明显：如果CFS切换得太频繁，公平性就会增加，因为CFS将确保每个进程即使在很小的时间窗口内也能获得其CPU的份额，但是会以性能为代价（上下文切换过多）；如果CFS切换的频率较低，则性能会提高（上下文切换减少），但会以近期的公平为代价。
CFS通过各种控制参数来管理这种压力。首先是调度延迟（sched_latency）。 CFS使用此值来确定在考虑切换之前一个进程应运行多长时间（以动态方式有效地确定其时间段）。典型的调度延迟时间值为48（毫秒）。 CFS将该值除以CPU上正在运行的进程数（n）来确定一个进程的时间片，从而确保在这段时间内CFS将完全公平。
例如，如果正在运行n = 4 n = 4n=4个进程，则CFS将调度延迟时间的值除以n，得出每个进程的时间片为12 ms。然后，CFS调度第一个任务并运行它，直到它使用了12毫秒的（虚拟）运行时为止，然后检查是否有一个具有较低vruntime的任务要运行。在这种情况下，CFS将切换到其他三个任务之一，依此类推。下图显示了一个示例，其中四个任务（A，B，C，D）以这种方式分别运行两个时间片。然后，其中两个（C，D）完成，仅剩下两个，然后以循环方式分别运行24 ms。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200917231054521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

但是，如果运行的进程“太多”怎么办？那会不会导致时间片太小，从而导致上下文切换过多？
为了解决此问题，CFS添加了另一个参数最小粒度，通常设置为6 ms之类的值。CFS永远不会将时间片设置小于该值，从而确保在调度开销方面不会花费太多时间。
例如，如果有十个进程在运行，我们的原始计算将调度的延迟除以十来确定时间片（结果：4.8毫秒）。但是，由于最小粒度，CFS会将每个进程的时间片设置为6ms。尽管CFS在48毫秒的目标调度延迟（调度延迟）上并不能（完全）公平，但在达到较高CPU效率的同时，它还是很接近的。
注意，CFS利用了周期性的计时中断，这意味着它只能以固定的时间间隔做出决定。该中断频繁关闭（例如，每1毫秒一次），使CFS有机会唤醒并确定当前任务是否已运行结束。如果任务的时间片不是计时中断间隔的完美倍数，则没问题； CFS精确跟踪vruntime，这意味着从长远来看，它将最终接近理想的CPU共享。

**加权（精细度）**
CFS还可以控制进程优先级，从而使用户或管理员可以为某些进程分配更高的CPU份额。它不使用票而是通过经典的UNIX机制（称为进程的nice级别）来完成的。可以将一个进程的nice参数设置为-20到+19之间的任意值，默认值为0。正的nice值表示优先级较低，而负的值表示优先级较高。
CFS将每个进程的nice值映射到权重，如下所示：

```
static const int prio_to_weight[40] = {
	/* -20 */ 88761, 71755, 56483, 46273, 36291,
	/* -15 */ 29154, 23254, 18705, 14949, 11916,
	/* -10 */ 9548, 7620, 6100, 4904, 3906,
	/* -5 */  3121, 2501, 1991, 1586, 1277,
	/* 0 */   1024, 820, 655, 526, 423,
	/* 5 */   335, 272, 215, 172, 137,
	/* 10 */  110, 87, 70, 56, 45,
	/* 15 */  36, 29, 23, 18, 15,
};
```

这些权重使我们能够计算每个进程的有效时间片（就像我们之前所做的一样），但是现在考虑了它们的优先级差异。这样做的公式如下：$\frac{weight_k}{\sum\limits^{n-1}_{i=0}weight_i}*sched\_latency$


让我们看一个例子，看看它是如何工作的。假设有两个任务，A和B。A，因为它是我们最宝贵的工作，被赋予了更高的优先级，所以分配给它的nice值-5；B，因为我们讨厌它，所以它具有默认优先级（nice值等于0）。这意味着 $weight_A$ 为3121，而$weight_B$ 为1024。然后，计算每个任务的时间片，A的时间片约为调度延迟的 $\frac{3}{4} $ （因此为36毫秒），而B的时间片约为$\frac{1}{4} $（因此为12毫秒）。
除了概括时间片计算之外，还必须调整CFS计算vruntime的方式。这是新的公式，它采用进程i ii累计的实际运行时间（$runtime_i$），并按进程的权重进行反比例缩放。在我们的运行示例中，A的vruntime将以B的速度的三分之一累积。$vruntime_i=vruntime_i+\frac{weight_0}{weight_i}*runtime_i$ 上面的权重表的构造的一个明智的方面是，当nice值的差异恒定时，该表保留CPU比例比率。例如，如果进程A的nice值为5（不是-5），而进程B的nice值为10（不是0），则CFS将以与以前完全相同的方式调度它们。

**使用红黑树**
如上所述，CFS的一个主要重点是效率。对于调度程序而言，效率有很多方面，但是其中一个方面是如此简单：当调度程序必须找到要运行的下一个任务时，它应该尽快完成。像列表这样的简单数据结构无法扩展：现代系统有时由数千个进程组成，因此每隔几毫秒搜索一个长列表是很浪费的。
CFS通过将进程保存在红黑树中来解决此问题。红黑树是许多平衡树中的一种。与简单的二叉树（在最坏情况下的插入操作性能可能退化为类似链表的性能）相比，平衡树做了一些额外的工作来保持较低的深度，从而确保操作在时间上是对数级别的（而不是线性的）。
CFS不会将所有进程都保留在此结构中，而是仅将运行（或可运行）的进程保留在其中。如果某个进程进入睡眠状态（例如，等待I / O完成，或者等待网络数据包到达），则将其从树中删除并跟踪其他位置。
让我们看一个例子。假设有十个任务，并且它们具有以下vruntime值：1、5、9、10、14、18、17、21、22和24。如果我们将这些任务保留在有序列表中，查找下一个要运行的任务很简单：只需删除第一个元素。但是，当将该任务放回列表中时（按顺序），我们要扫描列表，寻找正确的位置将其插入，这是一个O（n）的操作。任何查找的效率也很低，平均也要花费线性时间。
在红黑树中保持相同的值可以使大多数操作更高效，如图所示。进程按vruntime在树中排序，并且大多数操作（例如插入和删除）在时间上都是对数的，即O（log n）。当n上千时，对数的效率明显高于线性的效率。

![img](https://img-blog.csdnimg.cn/20200917235919529.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0luZ3N1aWZvbg==,size_16,color_FFFFFF,t_70#pic_center)

**处理I / O和睡眠进程**
选择最低vruntime的进程来运行导致的一个问题是长期处于休眠状态的任务。想象一下两个进程，A和B，其中一个（A）连续运行，另一个（B）长时间睡眠（例如10秒）。当B醒来时，其vruntime将比A的运行时间晚10秒，因此（如果我们不小心的话），B现在会在接下来的10秒钟内独占CPU，使A饥饿。
CFS通过在任务唤醒时更改其vruntime来处理这种情况。具体来说，CFS将该任务的vruntime设置为在树中找到的最小值（请记住，该树仅包含正在运行的任务）。这样，CFS避免了饥饿，但并非没有代价：短时间内频繁睡眠的任务经常无法获得应有的CPU份额。

**CFS其他有趣的功能**
CFS具有许多其他功能，它包括多种启发式方法，可以提高缓存性能，具有有效处理多CPU的策略，可以跨大组进程进行调度（而不是将每个进程视为一个独立的实体），以及许多其他有趣的功能。

**总结**
我们介绍了比例分配调度的概念，并简要讨论了三种方法：彩票调度，步长调度和Linux的完全公平调度（CFS）。彩票调度巧妙地利用随机性来实现比例分配。步长调度非常具有确定性。 CFS是本章中讨论的唯一“真正的”调度程序，有点像带有动态时间片的加权循环调度，但是可以在负载下扩展和运行良好。据说，它是当今最广泛使用的公平份额调度程序。
没有调度程序是万能的灵丹妙药，公平份额的调度程序也有很多问题。
一个问题是这种方法不能与I / O很好地融合在一起；如上所述，偶尔执行I / O的任务可能无法公平得到CPU。另一个问题是，它们没有解决票或优先级分配的难题，即如何知道应该分配浏览器程序多少票，或者如何设置文本编辑器的nice值？其他通用调度程序（例如前面讨论的MLFQ和其他类似的Linux调度程序）会自动处理这些问题，因此可能更易于部署。
好消息是，在许多领域中，这些问题并不是主要问题，并且比例份额调度程序可发挥巨大作用。例如，在虚拟数据中心（或云）中，你可能希望将四分之一的CPU周期分配给Windows VM，其余的分配给基本的Linux安装，比例份额可以变得简单而有效。这个想法也可以扩展到其他资源。

#### 多级反馈队列调度

**多级反馈队列调度算法**（无先验经验）

**多级反馈队列（Multilevel Feedback Queue）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)

来看看，它是如何工作的：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**



#### 多处理器调度？

**单队列**

![img](https://pic4.zhimg.com/v2-f424f5893cd3bbdd49ebb77c8c70c3bf_b.jpg)

这种形式不需要在单处理器的框架下做太多改动，**同样的是维护一个进程的全局就绪队列，为所有 CPU 共享。运行在 CPU 上的调度程序从这个队列中挑选合适的进程执行。**

**特点**：

- 实现较简单，对所有的 CPU 来说很公平。
- 这个队列是全局共享的，所以当一个 CPU 挑选进程时需要加锁，不然多个 CPU 就可能选取同一个进程。但是锁机制不可避免带来额外的开销使得性能降低，可扩展性降低。
- 处理器亲和性(Processor Affinity)不容易实现，处理器亲和性是系统提供给用户的一种选择，用户可以指定特定的处理器来执行进程。
- 每个处理器都有自己的缓存，处理器亲和性不好，一个进程可能在多个处理器之间来回运行，使得处理器的缓存无效，所以缓存亲和性也不好，性能较为低下。

**多队列**

![img](https://pic4.zhimg.com/v2-af9ad1b1877b020d9412a56a0ff72877_b.jpg)

如上图所示：**每个 CPU 都有自己单独的调度队列**。每个 CPU 只在自己本地的队列中挑选合适的进程，速度很快。

**队列之间的调度相互独立**，可不再使用锁机制，可扩展性增强，比如每个队列可使用不同的调度算法。

**所有的任务工作都能在固定的 CPU 上执行，能够很好的利用缓存数据**。

**但是也有明显缺点：各个 CPU 的负载不均衡**，从上图就可以看出 CPU2 负载较大，而 CPU3 负载较小

**解决负载均衡的办法叫做迁移(Migration)，从繁忙 CPU 的队列中迁移一些进程到空闲 CPU 中去**。



#### 时间片调度的时间片如何校准时间？



#### 谈谈优先级反转以及解决思路？

**什么是优先级反转**
优先级反转是指使用信号量时，出现的一种不合理的反常现象，既是一个 高优先级任务 试图通过信号量机制访问某个共享资源时，哎，发现这个资源已经被低优先级任务占有。

人家抢先了就只能等呗，但是这就导致了低优先级任务 阻塞高优先级任务的现象，导致 高优先级任务 被 低优先级任务 阻塞，影响了 高优先级任务 的实时性。

最坏的情况下在 高优先级任务 等待低优先级任务的时候，出现一个中优先级任务，中优先级任务卡住了低优先级任务，却在被 高优先级任务 卡住，这就出现了类似死锁的情况发生。

**解决方法 1 ：优先权极限**
在优先权极限方案中，系统把每一个临界资源与1个极限优先权相联系。这个极限优先权等于系统此时最高优先权加1。当1个任务进入临界区时，系统便把这个极限 优先权传递给这个任务，使得这个任务的优先权最高；
当这个任务退出临界区后，系统立即把它的优先权恢复正常，从而保证系统不会出现优先权反转的情况。如上例中，当 低优先权任务 进入临界区时，立即把它的优先权升高到极限优先权，保证低优先权任务 此时能尽快退出临界区，进而释放其占有的信号量。当 高优先级任务 执行的时候就不会出现其等待 低优先级任务 释放信号量而被阻塞的情况，从而保证不会出现上面所说的优先级反转。采用这种方案的另一个有利之处，是仅仅通过改变某个临界资源的优先级就可以使多个任务共享这个临界资源

**解决方法 2 ：优先级继承**
在优先级继承方案中，大致原理是让低优先级线程在获得同步资源的时候(如果有高优先级的线程也需要使用该同步资源时)，临时提升其优先级。以前其能更快的执行并释放同步资源。释放同步资源后再恢复其原来的优先级。

当 高优先级任务 想要进入临界区时，由于 低优先级任务 占有这个临界资源的信号量，导致 高优先级任务 被阻塞。这时候，系统把 低优先级任务 的优先权升到 高优先级任务 的优先级，此时优先级处于 低优先级任务 和 高优先级任务 之间的任务 中优先级任务，即使处于就绪状态也不可以被调度执行，因为此时低优先级任务 的优先权已经高于 中优先级任务，所以低优先级任务 此时被调度执行。当 低优先级任务 释放 高优先级任务 需要的信号量时，系统立即把 低优先级任务 的优先权降到原 来的高度，来保证task1和task2正常有序执行。
于是只有中优先级受伤的世界出现了



#### Linux 如何提升进程优先级？

Linux系统进程的优先级取值：-20 到 19，数越大优先级越低。


可以通过top命令来查看，NI那一列。

 

改变进程的优先级的方法有两种：

* top命令。输入r，然后根据提示输入进程ID，再输入优先级数值。
* renice命令。renice -n 2 -p 3432。-n，后面是优先级的值；-p，是进程号。

另外：

在嵌入式Linux系统中，大多都是跑一个核心的业务，在数据吞吐量大的时候，会大量占用CPU，导致数据处理不过来，常规办法是优化程序或者更换更高性能的平台来解决，但是如果程序已经优化到极限和平台无法更换的情况下，可以通过提高业务进程的优先级来提高业务数据的吞吐量,例如：

nice -n -20 ./bin 

nice为Linux环境下的改变进程优先级的命令，-n为进程优先级级别参数，-20为优先级级别，Linux一共有40个优先级，分别从-20到19，-20为最高优先级，19为最低优先级，一般程序默认优先级为0，只有root权限才能将进程优先级设为负数，如果程序已经在运行，可以使用renice，在不中断程序的情况下改变其优先级，程序处于哪个优先级可以通过top命令查看，NI字段则为对应该程序的优先级。在做网络数据分析的时候该方法非常管用，没有提高优先级时，数据吞吐量大概为800Mbps，再往上就开始处理不过来了，直到应用层buffer满了导致数据丢失，将进程提高到最高优先级，数据吞吐量可以提高到接近900Mbps，效果相当明显。



### 进程状态

在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。

它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，**在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。**

![进程的三种基本状态](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg)

上图中各个状态的意义：

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

当然，进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

于是，一个完整的进程状态的变迁如下图：

![进程五种状态的变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg)

再来详细说明一下进程的状态变迁：

- *NULL -> 创建状态*：一个新进程被创建时的第一个状态；
- *创建状态 -> 就绪状态*：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；
- *就绪态 -> 运行状态*：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；
- *运行状态 -> 结束状态*：当进程已经运行完成或出错时，会被操作系统作结束状态处理；
- *运行状态 -> 就绪状态*：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；
- *运行状态 -> 阻塞状态*：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
- *阻塞状态 -> 就绪状态*：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。

所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。

![虚拟内存管理-换入换出](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/9-%E6%8D%A2%E5%85%A5%E6%8D%A2%E5%87%BA.jpg)

那么，就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。

另外，挂起状态可以分为两种：

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

这两种挂起状态加上前面的五种状态，就变成了七种状态变迁（留给我的颜色不多了），见如下图：

![七种状态变迁](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg)

导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

- 通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。
- 用户希望挂起一个程序的执行，比如在 Linux 中用 `Ctrl+Z` 挂起进程；



### 进程上下文

#### 谈一下 系统调用、CPU 上下文切换、进程上下文切换、线程上下文切换、中断上下文切换

**CPU上下文切换**
进程在竞争 CPU 的时候并没有真正运行，为什么还会导致系统的负载升高呢？CPU 上下文切换就是罪魁祸首。

我们都知道，Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要**系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）**。

**CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。**



知道了什么是 CPU 上下文，我想你也很容易理解 CPU 上下文切换。CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

操作系统管理的这些“任务”到底是什么呢？

**所以，根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。**

**进程上下文切换**
Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中，CPU 特权等级的 Ring 0 和 Ring 3。

内核空间（Ring 0）具有最高权限，可以直接访问所有资源；

用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210630215953751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01pbmRfcHJvZ3JhbW1vbmtleQ==,size_16,color_FFFFFF,t_70#pic_center)

那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。

而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换。**



**那么，进程上下文切换跟系统调用又有什么区别呢？**

* 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，**进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态**。因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。
* 进程上下文切换，是指从一个进程切换到另一个进程运行。而系统调用过程中一直是同一个进程在运行。



**线程上下文切换**
线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位。

说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。

这么一来，线程的上下文切换其实就可以分为两种情况：

* 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
* 第二种，前后两个线程属于同一个进程。**此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

到这里你应该也发现了，虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

**中断上下文切换**
除了前面两种上下文切换，还有一个场景也会切换 CPU 上下文，那就是中断。

为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。**中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。**

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。



#### 进程在哪些场景会进行上下文切换？

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；
- 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；



#### 进程上下文切换做了哪些事？流程是怎么样的？

进程切换的视图：

![image.png](https://s2.loli.net/2022/10/06/QydSZ6VWICzGYL2.png)

 

 **关键点：**

1. 发生中断时的保存现场，将发生中断时的所有通用寄存器保存到进程的内核栈，使用struct pt_regs结构。
2. 地址空间切换将进程自己的页全局目录的基地址 pgd 保存在ttbr0_le1中，用于mmu 的页表遍历的起始点。
3. 硬件上下文切换的时候，将此时的调用保存寄存器和pc, sp保存到struct cpu_context结构中。做好了这几个保存工作，当进程再次被调度回来的时候，通过cpu_context中保存的pc回到了cpu_switch_to的下一条指令继续执行，而由于cpu_context中保存的sp导致当前进程回到自己的内核栈，经过一系列的内核栈的出栈处理，最后将原来保存在pt_regs中的通用寄存器的值恢复到了通用寄存器，这样进程回到用户空间就可以继续沿着被中断打断的下一条指令开始执行，用户栈也回到了被打断之前的位置，而进程访问的指令数据做地址转化（VA到PA）也都是从自己的pgd开始进行，一切对用户来说就好像没有发生一样。

**总结；**

　　进程切换有两大步骤：地址空间切换和处理器状态切换（硬件上下文切换）。前者保证了进程回到用户空间之后能够访问到自己的指令和数据（其中包括减小tlb清空的ASID机制），后者保证了进程内核栈和执行流的切换，会将当前进程的硬件上下文保存在进程所管理的一块内存，然后将即将执行的进程的硬件上下文从内存中恢复到寄存器，有了这两步的切换过程保证了进程运行的有条不紊，当然切换的过程是在内核空间完成，这对于进程来说是透明的。



#### 上下文切换为什么资源消耗会比较高？消耗在什么地方？

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：

![进程上下文切换](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg)

大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。



### 进程控制

#### 进程控制结构？包含哪些信息？

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。



PCB 具体包含什么信息呢？

**进程描述信息：**

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

- 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
- 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**

- 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。

**CPU 相关信息：**

- CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。





#### PCB 是如何组织？几种方式优缺点（要改）

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
- 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。

那么，就绪队列和阻塞队列链表的组织形式如下图：

![就绪队列和阻塞队列](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg)

除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。



#### 如何创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。

创建进程的过程如下：

- 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；
- 为该进程分配运行时所必需的资源，比如内存资源；
- 将 PCB 插入到就绪队列，等待被调度运行；



#### 如何终止进程

进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 `kill` 掉）。

当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。

终止进程的过程如下：

- 查找需要终止的进程的 PCB；
- 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；
- 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；
- 将该进程所拥有的全部资源都归还给操作系统；
- 将其从 PCB 所在队列中删除；



1、main函数的自然返回，return 

2、调用exit函数，属于c的函数库

3、调用_exit函数，属于系统调用 

4、调用abort函数，异常程序终止，同时发送SIGABRT信号给调用进程。

 5、接受能导致进程终止的信号：ctrl+c (^C)、SIGINT(SIGINT中断进程)



exit和_exit的区别

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage2@2.8/202104/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-39-1.png)

#### 如何阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。

阻塞进程的过程如下：

- 找到将要被阻塞进程标识号对应的 PCB；
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；
- 将该 PCB 插入到阻塞队列中去；



#### 如何唤醒进程

进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。

唤醒进程的过程如下：

- 在该事件的阻塞队列中找到相应进程的 PCB；
- 将其从阻塞队列中移出，并置其状态为就绪状态；
- 把该 PCB 插入到就绪队列中，等待调度程序调度；

进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。







